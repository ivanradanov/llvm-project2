// XFAIL: *
// RUN: mlir-opt %s --pass-pipeline="builtin.module(llvm-to-affine-access)" --split-input-file | FileCheck %s

#loc1 = loc(unknown)
#tbaa_root = #llvm.tbaa_root<id = "Simple C++ TBAA">
#tbaa_type_desc = #llvm.tbaa_type_desc<id = "omnipotent char", members = {<#tbaa_root, 0>}>
#tbaa_tag = #llvm.tbaa_tag<base_type = #tbaa_type_desc, access_type = #tbaa_type_desc, offset = 0>
#tbaa_type_desc1 = #llvm.tbaa_type_desc<id = "float", members = {<#tbaa_type_desc, 0>}>
#tbaa_type_desc2 = #llvm.tbaa_type_desc<id = "int", members = {<#tbaa_type_desc, 0>}>
#tbaa_type_desc3 = #llvm.tbaa_type_desc<id = "any pointer", members = {<#tbaa_type_desc, 0>}>
#tbaa_tag1 = #llvm.tbaa_tag<base_type = #tbaa_type_desc1, access_type = #tbaa_type_desc1, offset = 0>
#tbaa_tag2 = #llvm.tbaa_tag<base_type = #tbaa_type_desc3, access_type = #tbaa_type_desc3, offset = 0>
#tbaa_tag3 = #llvm.tbaa_tag<base_type = #tbaa_type_desc2, access_type = #tbaa_type_desc2, offset = 0>
#tbaa_type_desc4 = #llvm.tbaa_type_desc<id = "_ZTS4dim3", members = {<#tbaa_type_desc2, 0>, <#tbaa_type_desc2, 4>, <#tbaa_type_desc2, 8>}>
#tbaa_type_desc5 = #llvm.tbaa_type_desc<id = "_ZTSZ22_ConvertSMVer2ArchNameiiE13sSMtoArchName", members = {<#tbaa_type_desc2, 0>, <#tbaa_type_desc3, 8>}>
#tbaa_type_desc6 = #llvm.tbaa_type_desc<id = "_ZTSZ19_ConvertSMVer2CoresiiE10sSMtoCores", members = {<#tbaa_type_desc2, 0>, <#tbaa_type_desc2, 4>}>
#tbaa_tag4 = #llvm.tbaa_tag<base_type = #tbaa_type_desc4, access_type = #tbaa_type_desc2, offset = 0>
#tbaa_tag5 = #llvm.tbaa_tag<base_type = #tbaa_type_desc4, access_type = #tbaa_type_desc2, offset = 4>
#tbaa_tag6 = #llvm.tbaa_tag<base_type = #tbaa_type_desc4, access_type = #tbaa_type_desc2, offset = 8>
#tbaa_tag7 = #llvm.tbaa_tag<base_type = #tbaa_type_desc5, access_type = #tbaa_type_desc2, offset = 0>
#tbaa_tag8 = #llvm.tbaa_tag<base_type = #tbaa_type_desc5, access_type = #tbaa_type_desc3, offset = 8>
#tbaa_tag9 = #llvm.tbaa_tag<base_type = #tbaa_type_desc6, access_type = #tbaa_type_desc2, offset = 0>
#tbaa_tag10 = #llvm.tbaa_tag<base_type = #tbaa_type_desc6, access_type = #tbaa_type_desc2, offset = 4>
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi64>>, #dlti.dl_entry<i128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi64>>, #dlti.dl_entry<i64, dense<64> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f16, dense<16> : vector<2xi64>>, #dlti.dl_entry<f64, dense<64> : vector<2xi64>>, #dlti.dl_entry<i16, dense<16> : vector<2xi64>>, #dlti.dl_entry<i32, dense<32> : vector<2xi64>>, #dlti.dl_entry<i1, dense<8> : vector<2xi64>>, #dlti.dl_entry<i8, dense<8> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi64>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i64>, #dlti.dl_entry<"dlti.endianness", "little">>, gpu.container_module} {
  gpu.module @__mlir_gpu_module [#nvvm.target<chip = "sm_80">]  {
    llvm.comdat @__llvm_global_comdat {
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As any loc(#loc)
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs any loc(#loc)
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As any loc(#loc)
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs any loc(#loc)
      llvm.comdat_selector @_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii any loc(#loc)
      llvm.comdat_selector @_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii any loc(#loc)
    } loc(#loc)
    llvm.mlir.global linkonce_odr local_unnamed_addr @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As() comdat(@__llvm_global_comdat::@_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As) {addr_space = 3 : i32, alignment = 4 : i64, dso_local} : !llvm.array<16 x array<16 x f32>> {
      %0 = llvm.mlir.undef : !llvm.array<16 x array<16 x f32>> loc(#loc1)
      llvm.return %0 : !llvm.array<16 x array<16 x f32>> loc(#loc)
    } loc(#loc)
    llvm.mlir.global linkonce_odr local_unnamed_addr @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs() comdat(@__llvm_global_comdat::@_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs) {addr_space = 3 : i32, alignment = 4 : i64, dso_local} : !llvm.array<16 x array<16 x f32>> {
      %0 = llvm.mlir.undef : !llvm.array<16 x array<16 x f32>> loc(#loc1)
      llvm.return %0 : !llvm.array<16 x array<16 x f32>> loc(#loc)
    } loc(#loc)
    llvm.mlir.global linkonce_odr local_unnamed_addr @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As() comdat(@__llvm_global_comdat::@_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As) {addr_space = 3 : i32, alignment = 4 : i64, dso_local} : !llvm.array<32 x array<32 x f32>> {
      %0 = llvm.mlir.undef : !llvm.array<32 x array<32 x f32>> loc(#loc1)
      llvm.return %0 : !llvm.array<32 x array<32 x f32>> loc(#loc)
    } loc(#loc)
    llvm.mlir.global linkonce_odr local_unnamed_addr @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs() comdat(@__llvm_global_comdat::@_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs) {addr_space = 3 : i32, alignment = 4 : i64, dso_local} : !llvm.array<32 x array<32 x f32>> {
      %0 = llvm.mlir.undef : !llvm.array<32 x array<32 x f32>> loc(#loc1)
      llvm.return %0 : !llvm.array<32 x array<32 x f32>> loc(#loc)
    } loc(#loc)
    llvm.func local_unnamed_addr @_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii(%arg0: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly} loc(unknown), %arg1: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly} loc(unknown), %arg2: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly} loc(unknown), %arg3: i32 {llvm.noundef} loc(unknown), %arg4: i32 {llvm.noundef} loc(unknown)) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {} {
      %c1_i32 = arith.constant 1 : i32 loc(#loc1)
      %c0_i32 = arith.constant 0 : i32 loc(#loc1)
      %c16_i32 = arith.constant 16 : i32 loc(#loc1)
      %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
      %1 = llvm.mlir.addressof @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs : !llvm.ptr<3> loc(#loc1)
      %c4_i32 = arith.constant 4 : i32 loc(#loc1)
      %2 = llvm.mlir.addressof @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As : !llvm.ptr<3> loc(#loc1)
      %3 = llvm.addrspacecast %2 : !llvm.ptr<3> to !llvm.ptr loc(#loc1)
      %4 = llvm.addrspacecast %1 : !llvm.ptr<3> to !llvm.ptr loc(#loc1)
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32 loc(#loc1)
      %6 = nvvm.read.ptx.sreg.ctaid.y : i32 loc(#loc1)
      %7 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc1)
      %8 = nvvm.read.ptx.sreg.tid.y : i32 loc(#loc1)
      %9 = arith.shli %arg3, %c4_i32 : i32 loc(#loc1)
      %10 = arith.muli %9, %6 : i32 loc(#loc1)
      %11 = arith.addi %10, %arg3 : i32 loc(#loc1)
      %12 = arith.shli %5, %c4_i32 : i32 loc(#loc1)
      %13 = arith.shli %arg4, %c4_i32 : i32 loc(#loc1)
      %14 = arith.muli %8, %arg3 : i32 loc(#loc1)
      %15 = arith.addi %14, %7 : i32 loc(#loc1)
      %16 = arith.extui %8 : i32 to i64 loc(#loc1)
      %17 = arith.extui %7 : i32 to i64 loc(#loc1)
      %18 = llvm.getelementptr inbounds %3[0, %16, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>> loc(#loc1)
      %19 = arith.muli %8, %arg4 : i32 loc(#loc1)
      %20 = arith.addi %19, %7 : i32 loc(#loc1)
      %21 = llvm.getelementptr inbounds %4[0, %16, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>> loc(#loc1)
      %22:2 = scf.for %arg5 = %10 to %11 step %c16_i32 iter_args(%arg6 = %12, %arg7 = %0) -> (i32, f32)  : i32 {
        %29 = arith.addi %15, %arg5 : i32 loc(#loc1)
        %30 = arith.extsi %29 : i32 to i64 loc(#loc1)
        %31 = llvm.getelementptr inbounds %arg1[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
        %32 = llvm.load %31 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
        llvm.store %32, %18 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
        %33 = arith.addi %20, %arg6 : i32 loc(#loc1)
        %34 = arith.extsi %33 : i32 to i64 loc(#loc1)
        %35 = llvm.getelementptr inbounds %arg2[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
        %36 = llvm.load %35 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
        llvm.store %36, %21 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
        nvvm.barrier0 loc(#loc1)
        %37 = scf.for %arg8 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg9 = %arg7) -> (f32)  : i32 {
          %39 = arith.extui %arg8 : i32 to i64 loc(#loc1)
          %40 = llvm.getelementptr inbounds %3[0, %16, %39] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>> loc(#loc1)
          %41 = llvm.load %40 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
          %42 = llvm.getelementptr inbounds %4[0, %39, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>> loc(#loc1)
          %43 = llvm.load %42 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
          %44 = llvm.fmul %41, %43  {fastmathFlags = #llvm.fastmath<contract>} : f32 loc(#loc1)
          %45 = llvm.fadd %arg9, %44  {fastmathFlags = #llvm.fastmath<contract>} : f32 loc(#loc1)
          scf.yield %45 : f32 loc(#loc1)
        } loc(#loc1)
        nvvm.barrier0 loc(#loc1)
        %38 = arith.addi %arg6, %13 : i32 loc(#loc1)
        scf.yield %38, %37 : i32, f32 loc(#loc1)
      } loc(#loc1)
      %23 = arith.muli %13, %6 : i32 loc(#loc1)
      %24 = arith.addi %12, %7 : i32 loc(#loc1)
      %25 = arith.addi %24, %19 : i32 loc(#loc1)
      %26 = arith.addi %25, %23 : i32 loc(#loc1)
      %27 = arith.extsi %26 : i32 to i64 loc(#loc1)
      %28 = llvm.getelementptr inbounds %arg0[%27] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
      llvm.store %22#1, %28 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
      llvm.return loc(#loc1)
    } loc(#loc1)
    llvm.func local_unnamed_addr @_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii(%arg0: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly} loc(unknown), %arg1: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly} loc(unknown), %arg2: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly} loc(unknown), %arg3: i32 {llvm.noundef} loc(unknown), %arg4: i32 {llvm.noundef} loc(unknown)) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii) attributes {} {
      %c1_i32 = arith.constant 1 : i32 loc(#loc1)
      %c0_i32 = arith.constant 0 : i32 loc(#loc1)
      %c32_i32 = arith.constant 32 : i32 loc(#loc1)
      %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
      %1 = llvm.mlir.addressof @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs : !llvm.ptr<3> loc(#loc1)
      %c5_i32 = arith.constant 5 : i32 loc(#loc1)
      %2 = llvm.mlir.addressof @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As : !llvm.ptr<3> loc(#loc1)
      %3 = llvm.addrspacecast %2 : !llvm.ptr<3> to !llvm.ptr loc(#loc1)
      %4 = llvm.addrspacecast %1 : !llvm.ptr<3> to !llvm.ptr loc(#loc1)
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32 loc(#loc1)
      %6 = nvvm.read.ptx.sreg.ctaid.y : i32 loc(#loc1)
      %7 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc1)
      %8 = nvvm.read.ptx.sreg.tid.y : i32 loc(#loc1)
      %9 = arith.shli %arg3, %c5_i32 : i32 loc(#loc1)
      %10 = arith.muli %9, %6 : i32 loc(#loc1)
      %11 = arith.addi %10, %arg3 : i32 loc(#loc1)
      %12 = arith.shli %5, %c5_i32 : i32 loc(#loc1)
      %13 = arith.shli %arg4, %c5_i32 : i32 loc(#loc1)
      %14 = arith.muli %8, %arg3 : i32 loc(#loc1)
      %15 = arith.addi %14, %7 : i32 loc(#loc1)
      %16 = arith.extui %8 : i32 to i64 loc(#loc1)
      %17 = arith.extui %7 : i32 to i64 loc(#loc1)
      %18 = llvm.getelementptr inbounds %3[0, %16, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<32 x array<32 x f32>> loc(#loc1)
      %19 = arith.muli %8, %arg4 : i32 loc(#loc1)
      %20 = arith.addi %19, %7 : i32 loc(#loc1)
      %21 = llvm.getelementptr inbounds %4[0, %16, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<32 x array<32 x f32>> loc(#loc1)
      %22:2 = scf.for %arg5 = %10 to %11 step %c32_i32 iter_args(%arg6 = %12, %arg7 = %0) -> (i32, f32)  : i32 {
        %29 = arith.addi %15, %arg5 : i32 loc(#loc1)
        %30 = arith.extsi %29 : i32 to i64 loc(#loc1)
        %31 = llvm.getelementptr inbounds %arg1[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
        %32 = llvm.load %31 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
        llvm.store %32, %18 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
        %33 = arith.addi %20, %arg6 : i32 loc(#loc1)
        %34 = arith.extsi %33 : i32 to i64 loc(#loc1)
        %35 = llvm.getelementptr inbounds %arg2[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
        %36 = llvm.load %35 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
        llvm.store %36, %21 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
        nvvm.barrier0 loc(#loc1)
        %37 = scf.for %arg8 = %c0_i32 to %c32_i32 step %c1_i32 iter_args(%arg9 = %arg7) -> (f32)  : i32 {
          %39 = arith.extui %arg8 : i32 to i64 loc(#loc1)
          %40 = llvm.getelementptr inbounds %3[0, %16, %39] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<32 x array<32 x f32>> loc(#loc1)
          %41 = llvm.load %40 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
          %42 = llvm.getelementptr inbounds %4[0, %39, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<32 x array<32 x f32>> loc(#loc1)
          %43 = llvm.load %42 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
          %44 = llvm.fmul %41, %43  {fastmathFlags = #llvm.fastmath<contract>} : f32 loc(#loc1)
          %45 = llvm.fadd %arg9, %44  {fastmathFlags = #llvm.fastmath<contract>} : f32 loc(#loc1)
          scf.yield %45 : f32 loc(#loc1)
        } loc(#loc1)
        nvvm.barrier0 loc(#loc1)
        %38 = arith.addi %arg6, %13 : i32 loc(#loc1)
        scf.yield %38, %37 : i32, f32 loc(#loc1)
      } loc(#loc1)
      %23 = arith.muli %13, %6 : i32 loc(#loc1)
      %24 = arith.addi %12, %7 : i32 loc(#loc1)
      %25 = arith.addi %24, %19 : i32 loc(#loc1)
      %26 = arith.addi %25, %23 : i32 loc(#loc1)
      %27 = arith.extsi %26 : i32 to i64 loc(#loc1)
      %28 = llvm.getelementptr inbounds %arg0[%27] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
      llvm.store %22#1, %28 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
      llvm.return loc(#loc1)
    } loc(#loc1)
  } loc(#loc)
  llvm.comdat @__llvm_global_comdat {
    llvm.comdat_selector @_Z5checkI9cudaErrorEvT_PKcS3_i any loc(#loc)
    llvm.comdat_selector @_Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii any loc(#loc)
    llvm.comdat_selector @_Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii any loc(#loc)
    llvm.comdat_selector @_Z14findCudaDeviceiPPKc any loc(#loc)
    llvm.comdat_selector @_Z13gpuDeviceIniti any loc(#loc)
    llvm.comdat_selector @_Z23gpuGetMaxGflopsDeviceIdv any loc(#loc)
  } loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str"("cudaMallocHost(&h_A, mem_size_A)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.1"("matrixMul.cu\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.2"("cudaMallocHost(&h_B, mem_size_B)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.3"("cudaMallocHost(&h_C, mem_size_C)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global external local_unnamed_addr @stderr() {addr_space = 0 : i32, alignment = 8 : i64} : !llvm.ptr loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.4"("Failed to allocate host matrix C!\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.5"("cudaMalloc(reinterpret_cast<void **>(&d_A), mem_size_A)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.6"("cudaMalloc(reinterpret_cast<void **>(&d_B), mem_size_B)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.7"("cudaMalloc(reinterpret_cast<void **>(&d_C), mem_size_C)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.8"("cudaEventCreate(&start)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.9"("cudaEventCreate(&stop)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.10"("cudaStreamCreateWithFlags(&stream, cudaStreamNonBlocking)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.11"("cudaMemcpyAsync(d_A, h_A, mem_size_A, cudaMemcpyHostToDevice, stream)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.12"("cudaMemcpyAsync(d_B, h_B, mem_size_B, cudaMemcpyHostToDevice, stream)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.15"("cudaStreamSynchronize(stream)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.16"("cudaEventRecord(start, stream)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.17"("cudaEventRecord(stop, stream)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.18"("cudaEventSynchronize(stop)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.19"("cudaEventElapsedTime(&msecTotal, start, stop)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.20"("Performance= %.2f GFlop/s, Time= %.3f msec, Size= %.0f Ops, WorkgroupSize= %u threads/block\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.21"("cudaMemcpyAsync(h_C, d_C, mem_size_C, cudaMemcpyDeviceToHost, stream)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.22"("Checking computed result for correctness: \00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.23"("Error! Matrix[%05d]=%.8f, ref=%.8f error term is > %E\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.25"("Result = PASS\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.26"("Result = FAIL\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.27"("cudaFreeHost(h_A)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.28"("cudaFreeHost(h_B)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.29"("cudaFreeHost(h_C)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.30"("cudaFree(d_A)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.31"("cudaFree(d_B)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.32"("cudaFree(d_C)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.33"("cudaEventDestroy(start)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.34"("cudaEventDestroy(stop)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.37"("help\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.38"("?\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.43"("wA\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.44"("hA\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.45"("wB\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.46"("hB\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.47"("Error: outer matrix dimensions must be equal. (%d != %d)\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.48"("MatrixA(%d,%d), MatrixB(%d,%d)\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.49"("cudaProfilerStart()\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.50"("cudaProfilerStop()\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.51"("device\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.52"("device=\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.53"("Invalid command line parameter\0A \00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.55"("cudaSetDevice(devID)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.56"("../../../Common/helper_cuda.h\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.57"("cudaDeviceGetAttribute(&major, cudaDevAttrComputeCapabilityMajor, devID)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.58"("cudaDeviceGetAttribute(&minor, cudaDevAttrComputeCapabilityMinor, devID)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.59"("GPU Device %d: \22%s\22 with compute capability %d.%d\0A\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.60"("cudaGetDeviceCount(&device_count)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.61"("gpuDeviceInit() CUDA error: no devices supporting CUDA.\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.63"(">> %d CUDA capable GPU device(s) detected. <<\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.64"(">> gpuDeviceInit (-device=%d) is not a valid GPU device. <<\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.65"("cudaDeviceGetAttribute(&computeMode, cudaDevAttrComputeMode, devID)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.66"("Error: device is running in <Compute Mode Prohibited>, no threads can use cudaSetDevice().\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.67"("gpuDeviceInit(): GPU device does not support CUDA.\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.68"("gpuDeviceInit() CUDA Device [%d]: \22%s\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.69"("gpuGetMaxGflopsDeviceId() CUDA error: no devices supporting CUDA.\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.70"("cudaDeviceGetAttribute(&computeMode, cudaDevAttrComputeMode, current_device)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.71"("cudaDeviceGetAttribute(&major, cudaDevAttrComputeCapabilityMajor, current_device)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.72"("cudaDeviceGetAttribute(&minor, cudaDevAttrComputeCapabilityMinor, current_device)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.73"("cudaDeviceGetAttribute(&multiProcessorCount, cudaDevAttrMultiProcessorCount, current_device)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.74"("CUDA error at %s:%d code=%d(%s) \0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.75"("gpuGetMaxGflopsDeviceId() CUDA error: all devices have compute mode prohibited.\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @__const._Z19_ConvertSMVer2Coresii.nGpuArchCoresPerSM() {addr_space = 0 : i32, alignment = 16 : i64, dso_local} : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>> {
    %0 = llvm.mlir.undef : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>> loc(#loc1)
    %c48_i32 = arith.constant 48 : i32 loc(#loc1)
    %c50_i32 = arith.constant 50 : i32 loc(#loc1)
    %c53_i32 = arith.constant 53 : i32 loc(#loc1)
    %c55_i32 = arith.constant 55 : i32 loc(#loc1)
    %c192_i32 = arith.constant 192 : i32 loc(#loc1)
    %c80_i32 = arith.constant 80 : i32 loc(#loc1)
    %c82_i32 = arith.constant 82 : i32 loc(#loc1)
    %c83_i32 = arith.constant 83 : i32 loc(#loc1)
    %c96_i32 = arith.constant 96 : i32 loc(#loc1)
    %c97_i32 = arith.constant 97 : i32 loc(#loc1)
    %c98_i32 = arith.constant 98 : i32 loc(#loc1)
    %c112_i32 = arith.constant 112 : i32 loc(#loc1)
    %c114_i32 = arith.constant 114 : i32 loc(#loc1)
    %c117_i32 = arith.constant 117 : i32 loc(#loc1)
    %c64_i32 = arith.constant 64 : i32 loc(#loc1)
    %c134_i32 = arith.constant 134 : i32 loc(#loc1)
    %c135_i32 = arith.constant 135 : i32 loc(#loc1)
    %c137_i32 = arith.constant 137 : i32 loc(#loc1)
    %c144_i32 = arith.constant 144 : i32 loc(#loc1)
    %c128_i32 = arith.constant 128 : i32 loc(#loc1)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %1 = llvm.mlir.undef : !llvm.struct<"struct.sSMtoCores", (i32, i32)> loc(#loc1)
    %2 = llvm.insertvalue %c-1_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %3 = llvm.insertvalue %c-1_i32, %2[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %4 = llvm.insertvalue %c144_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %5 = llvm.insertvalue %c128_i32, %4[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %6 = llvm.insertvalue %c137_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %7 = llvm.insertvalue %c128_i32, %6[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %8 = llvm.insertvalue %c135_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %9 = llvm.insertvalue %c128_i32, %8[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %10 = llvm.insertvalue %c134_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %11 = llvm.insertvalue %c128_i32, %10[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %12 = llvm.insertvalue %c128_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %13 = llvm.insertvalue %c64_i32, %12[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %14 = llvm.insertvalue %c117_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %15 = llvm.insertvalue %c64_i32, %14[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %16 = llvm.insertvalue %c114_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %17 = llvm.insertvalue %c64_i32, %16[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %18 = llvm.insertvalue %c112_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %19 = llvm.insertvalue %c64_i32, %18[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %20 = llvm.insertvalue %c98_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %21 = llvm.insertvalue %c128_i32, %20[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %22 = llvm.insertvalue %c97_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %23 = llvm.insertvalue %c128_i32, %22[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %24 = llvm.insertvalue %c96_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %25 = llvm.insertvalue %c64_i32, %24[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %26 = llvm.insertvalue %c83_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %27 = llvm.insertvalue %c128_i32, %26[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %28 = llvm.insertvalue %c82_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %29 = llvm.insertvalue %c128_i32, %28[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %30 = llvm.insertvalue %c80_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %31 = llvm.insertvalue %c128_i32, %30[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %32 = llvm.insertvalue %c55_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %33 = llvm.insertvalue %c192_i32, %32[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %34 = llvm.insertvalue %c53_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %35 = llvm.insertvalue %c192_i32, %34[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %36 = llvm.insertvalue %c50_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %37 = llvm.insertvalue %c192_i32, %36[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %38 = llvm.insertvalue %c48_i32, %1[0] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %39 = llvm.insertvalue %c192_i32, %38[1] : !llvm.struct<"struct.sSMtoCores", (i32, i32)>  loc(#loc1)
    %40 = llvm.insertvalue %39, %0[0] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %41 = llvm.insertvalue %37, %40[1] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %42 = llvm.insertvalue %35, %41[2] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %43 = llvm.insertvalue %33, %42[3] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %44 = llvm.insertvalue %31, %43[4] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %45 = llvm.insertvalue %29, %44[5] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %46 = llvm.insertvalue %27, %45[6] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %47 = llvm.insertvalue %25, %46[7] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %48 = llvm.insertvalue %23, %47[8] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %49 = llvm.insertvalue %21, %48[9] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %50 = llvm.insertvalue %19, %49[10] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %51 = llvm.insertvalue %17, %50[11] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %52 = llvm.insertvalue %15, %51[12] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %53 = llvm.insertvalue %13, %52[13] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %54 = llvm.insertvalue %11, %53[14] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %55 = llvm.insertvalue %9, %54[15] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %56 = llvm.insertvalue %7, %55[16] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %57 = llvm.insertvalue %5, %56[17] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    %58 = llvm.insertvalue %3, %57[18] : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>>  loc(#loc1)
    llvm.return %58 : !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>> loc(#loc)
  } loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.76"("MapSMtoCores for SM %d.%d is undefined.  Default to use %d Cores/SM\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.77"("Kepler\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.78"("Maxwell\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.79"("Pascal\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.80"("Volta\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.81"("Xavier\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.82"("Turing\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.83"("Ampere\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.84"("Ada\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.85"("Hopper\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.86"("Graphics Device\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @__const._Z22_ConvertSMVer2ArchNameii.nGpuArchNameSM() {addr_space = 0 : i32, alignment = 16 : i64, dso_local} : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>> {
    %0 = llvm.mlir.undef : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>> loc(#loc1)
    %c48_i32 = arith.constant 48 : i32 loc(#loc1)
    %c50_i32 = arith.constant 50 : i32 loc(#loc1)
    %c53_i32 = arith.constant 53 : i32 loc(#loc1)
    %c55_i32 = arith.constant 55 : i32 loc(#loc1)
    %1 = llvm.mlir.addressof @".str.77" : !llvm.ptr loc(#loc1)
    %c80_i32 = arith.constant 80 : i32 loc(#loc1)
    %c82_i32 = arith.constant 82 : i32 loc(#loc1)
    %c83_i32 = arith.constant 83 : i32 loc(#loc1)
    %2 = llvm.mlir.addressof @".str.78" : !llvm.ptr loc(#loc1)
    %c96_i32 = arith.constant 96 : i32 loc(#loc1)
    %c97_i32 = arith.constant 97 : i32 loc(#loc1)
    %c98_i32 = arith.constant 98 : i32 loc(#loc1)
    %3 = llvm.mlir.addressof @".str.79" : !llvm.ptr loc(#loc1)
    %c112_i32 = arith.constant 112 : i32 loc(#loc1)
    %4 = llvm.mlir.addressof @".str.80" : !llvm.ptr loc(#loc1)
    %c114_i32 = arith.constant 114 : i32 loc(#loc1)
    %5 = llvm.mlir.addressof @".str.81" : !llvm.ptr loc(#loc1)
    %c117_i32 = arith.constant 117 : i32 loc(#loc1)
    %6 = llvm.mlir.addressof @".str.82" : !llvm.ptr loc(#loc1)
    %c128_i32 = arith.constant 128 : i32 loc(#loc1)
    %c134_i32 = arith.constant 134 : i32 loc(#loc1)
    %c135_i32 = arith.constant 135 : i32 loc(#loc1)
    %7 = llvm.mlir.addressof @".str.83" : !llvm.ptr loc(#loc1)
    %c137_i32 = arith.constant 137 : i32 loc(#loc1)
    %8 = llvm.mlir.addressof @".str.84" : !llvm.ptr loc(#loc1)
    %c144_i32 = arith.constant 144 : i32 loc(#loc1)
    %9 = llvm.mlir.addressof @".str.85" : !llvm.ptr loc(#loc1)
    %10 = llvm.mlir.addressof @".str.86" : !llvm.ptr loc(#loc1)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %11 = llvm.mlir.undef : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)> loc(#loc1)
    %12 = llvm.insertvalue %c-1_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %13 = llvm.insertvalue %10, %12[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %14 = llvm.insertvalue %c144_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %15 = llvm.insertvalue %9, %14[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %16 = llvm.insertvalue %c137_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %17 = llvm.insertvalue %8, %16[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %18 = llvm.insertvalue %c135_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %19 = llvm.insertvalue %7, %18[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %20 = llvm.insertvalue %c134_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %21 = llvm.insertvalue %7, %20[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %22 = llvm.insertvalue %c128_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %23 = llvm.insertvalue %7, %22[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %24 = llvm.insertvalue %c117_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %25 = llvm.insertvalue %6, %24[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %26 = llvm.insertvalue %c114_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %27 = llvm.insertvalue %5, %26[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %28 = llvm.insertvalue %c112_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %29 = llvm.insertvalue %4, %28[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %30 = llvm.insertvalue %c98_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %31 = llvm.insertvalue %3, %30[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %32 = llvm.insertvalue %c97_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %33 = llvm.insertvalue %3, %32[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %34 = llvm.insertvalue %c96_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %35 = llvm.insertvalue %3, %34[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %36 = llvm.insertvalue %c83_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %37 = llvm.insertvalue %2, %36[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %38 = llvm.insertvalue %c82_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %39 = llvm.insertvalue %2, %38[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %40 = llvm.insertvalue %c80_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %41 = llvm.insertvalue %2, %40[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %42 = llvm.insertvalue %c55_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %43 = llvm.insertvalue %1, %42[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %44 = llvm.insertvalue %c53_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %45 = llvm.insertvalue %1, %44[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %46 = llvm.insertvalue %c50_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %47 = llvm.insertvalue %1, %46[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %48 = llvm.insertvalue %c48_i32, %11[0] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %49 = llvm.insertvalue %1, %48[1] : !llvm.struct<"struct.sSMtoArchName", (i32, ptr)>  loc(#loc1)
    %50 = llvm.insertvalue %49, %0[0] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %51 = llvm.insertvalue %47, %50[1] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %52 = llvm.insertvalue %45, %51[2] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %53 = llvm.insertvalue %43, %52[3] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %54 = llvm.insertvalue %41, %53[4] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %55 = llvm.insertvalue %39, %54[5] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %56 = llvm.insertvalue %37, %55[6] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %57 = llvm.insertvalue %35, %56[7] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %58 = llvm.insertvalue %33, %57[8] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %59 = llvm.insertvalue %31, %58[9] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %60 = llvm.insertvalue %29, %59[10] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %61 = llvm.insertvalue %27, %60[11] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %62 = llvm.insertvalue %25, %61[12] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %63 = llvm.insertvalue %23, %62[13] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %64 = llvm.insertvalue %21, %63[14] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %65 = llvm.insertvalue %19, %64[15] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %66 = llvm.insertvalue %17, %65[16] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %67 = llvm.insertvalue %15, %66[17] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    %68 = llvm.insertvalue %13, %67[18] : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>>  loc(#loc1)
    llvm.return %68 : !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>> loc(#loc)
  } loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.87"("MapSMtoArchName for SM %d.%d is undefined.  Default to use %s\0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @".str.88"("CUDA error at %s:%d code=%d(%s) \22%s\22 \0A\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @mlir.llvm.nameless_global_0("_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @mlir.llvm.nameless_global_1("_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private constant @mlir.llvm.nameless_global_2("#loc1 = loc(unknown)\0A#tbaa_root = #llvm.tbaa_root<id = \22Simple C++ TBAA\22>\0A#tbaa_type_desc = #llvm.tbaa_type_desc<id = \22omnipotent char\22, members = {<#tbaa_root, 0>}>\0A#tbaa_type_desc1 = #llvm.tbaa_type_desc<id = \22float\22, members = {<#tbaa_type_desc, 0>}>\0A#tbaa_tag = #llvm.tbaa_tag<base_type = #tbaa_type_desc1, access_type = #tbaa_type_desc1, offset = 0>\0Amodule attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi64>>, #dlti.dl_entry<f64, dense<64> : vector<2xi64>>, #dlti.dl_entry<f16, dense<16> : vector<2xi64>>, #dlti.dl_entry<i16, dense<16> : vector<2xi64>>, #dlti.dl_entry<i8, dense<8> : vector<2xi64>>, #dlti.dl_entry<i32, dense<32> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi64>>, #dlti.dl_entry<i128, dense<128> : vector<2xi64>>, #dlti.dl_entry<i1, dense<8> : vector<2xi64>>, #dlti.dl_entry<i64, dense<64> : vector<2xi64>>, #dlti.dl_entry<\22dlti.endianness\22, \22little\22>>} {\0A  llvm.comdat @__llvm_global_comdat {\0A    llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As any loc(#loc)\0A    llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs any loc(#loc)\0A    llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As any loc(#loc)\0A    llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs any loc(#loc)\0A    llvm.comdat_selector @_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii any loc(#loc)\0A    llvm.comdat_selector @_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii any loc(#loc)\0A  } loc(#loc)\0A  llvm.mlir.global linkonce_odr local_unnamed_addr @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As() comdat(@__llvm_global_comdat::@_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As) {addr_space = 3 : i32, alignment = 4 : i64, dso_local} : !llvm.array<16 x array<16 x f32>> {\0A    %0 = llvm.mlir.undef : !llvm.array<16 x array<16 x f32>> loc(#loc1)\0A    llvm.return %0 : !llvm.array<16 x array<16 x f32>> loc(#loc)\0A  } loc(#loc)\0A  llvm.mlir.global linkonce_odr local_unnamed_addr @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs() comdat(@__llvm_global_comdat::@_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs) {addr_space = 3 : i32, alignment = 4 : i64, dso_local} : !llvm.array<16 x array<16 x f32>> {\0A    %0 = llvm.mlir.undef : !llvm.array<16 x array<16 x f32>> loc(#loc1)\0A    llvm.return %0 : !llvm.array<16 x array<16 x f32>> loc(#loc)\0A  } loc(#loc)\0A  llvm.mlir.global linkonce_odr local_unnamed_addr @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As() comdat(@__llvm_global_comdat::@_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As) {addr_space = 3 : i32, alignment = 4 : i64, dso_local} : !llvm.array<32 x array<32 x f32>> {\0A    %0 = llvm.mlir.undef : !llvm.array<32 x array<32 x f32>> loc(#loc1)\0A    llvm.return %0 : !llvm.array<32 x array<32 x f32>> loc(#loc)\0A  } loc(#loc)\0A  llvm.mlir.global linkonce_odr local_unnamed_addr @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs() comdat(@__llvm_global_comdat::@_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs) {addr_space = 3 : i32, alignment = 4 : i64, dso_local} : !llvm.array<32 x array<32 x f32>> {\0A    %0 = llvm.mlir.undef : !llvm.array<32 x array<32 x f32>> loc(#loc1)\0A    llvm.return %0 : !llvm.array<32 x array<32 x f32>> loc(#loc)\0A  } loc(#loc)\0A  llvm.func local_unnamed_addr @_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii(%arg0: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly} loc(unknown), %arg1: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly} loc(unknown), %arg2: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly} loc(unknown), %arg3: i32 {llvm.noundef} loc(unknown), %arg4: i32 {llvm.noundef} loc(unknown)) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {convergent, frame_pointer = #llvm.framePointerKind<all>, no_unwind, passthrough = [\22mustprogress\22, \22norecurse\22, [\22no-trapping-math\22, \22true\22], [\22stack-protector-buffer-size\22, \228\22], [\22target-cpu\22, \22sm_52\22], [\22uniform-work-group-size\22, \22true\22]], target_cpu = \22sm_52\22, target_features = #llvm.target_features<[\22+ptx84\22, \22+sm_52\22]>} {\0A    %c1_i32 = arith.constant 1 : i32 loc(#loc1)\0A    %c0_i32 = arith.constant 0 : i32 loc(#loc1)\0A    %c16_i32 = arith.constant 16 : i32 loc(#loc1)\0A    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)\0A    %1 = llvm.mlir.addressof @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs : !llvm.ptr<3> loc(#loc1)\0A    %c4_i32 = arith.constant 4 : i32 loc(#loc1)\0A    %2 = llvm.mlir.addressof @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As : !llvm.ptr<3> loc(#loc1)\0A    %3 = llvm.addrspacecast %2 : !llvm.ptr<3> to !llvm.ptr loc(#loc1)\0A    %4 = llvm.addrspacecast %1 : !llvm.ptr<3> to !llvm.ptr loc(#loc1)\0A    %5 = nvvm.read.ptx.sreg.ctaid.x : i32 loc(#loc1)\0A    %6 = nvvm.read.ptx.sreg.ctaid.y : i32 loc(#loc1)\0A    %7 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc1)\0A    %8 = nvvm.read.ptx.sreg.tid.y : i32 loc(#loc1)\0A    %9 = arith.shli %arg3, %c4_i32 : i32 loc(#loc1)\0A    %10 = arith.muli %9, %6 : i32 loc(#loc1)\0A    %11 = arith.addi %10, %arg3 : i32 loc(#loc1)\0A    %12 = arith.shli %5, %c4_i32 : i32 loc(#loc1)\0A    %13 = arith.shli %arg4, %c4_i32 : i32 loc(#loc1)\0A    %14 = arith.muli %8, %arg3 : i32 loc(#loc1)\0A    %15 = arith.addi %14, %7 : i32 loc(#loc1)\0A    %16 = arith.extui %8 : i32 to i64 loc(#loc1)\0A    %17 = arith.extui %7 : i32 to i64 loc(#loc1)\0A    %18 = llvm.getelementptr inbounds %3[0, %16, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>> loc(#loc1)\0A    %19 = arith.muli %8, %arg4 : i32 loc(#loc1)\0A    %20 = arith.addi %19, %7 : i32 loc(#loc1)\0A    %21 = llvm.getelementptr inbounds %4[0, %16, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>> loc(#loc1)\0A    %22:2 = scf.for %arg5 = %10 to %11 step %c16_i32 iter_args(%arg6 = %12, %arg7 = %0) -> (i32, f32)  : i32 {\0A      %29 = arith.addi %15, %arg5 : i32 loc(#loc1)\0A      %30 = arith.extsi %29 : i32 to i64 loc(#loc1)\0A      %31 = llvm.getelementptr inbounds %arg1[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)\0A      %32 = llvm.load %31 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> f32 loc(#loc1)\0A      llvm.store %32, %18 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : f32, !llvm.ptr loc(#loc1)\0A      %33 = arith.addi %20, %arg6 : i32 loc(#loc1)\0A      %34 = arith.extsi %33 : i32 to i64 loc(#loc1)\0A      %35 = llvm.getelementptr inbounds %arg2[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)\0A      %36 = llvm.load %35 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> f32 loc(#loc1)\0A      llvm.store %36, %21 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : f32, !llvm.ptr loc(#loc1)\0A      nvvm.barrier0 loc(#loc1)\0A      %37 = scf.for %arg8 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg9 = %arg7) -> (f32)  : i32 {\0A        %39 = arith.extui %arg8 : i32 to i64 loc(#loc1)\0A        %40 = llvm.getelementptr inbounds %3[0, %16, %39] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>> loc(#loc1)\0A        %41 = llvm.load %40 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> f32 loc(#loc1)\0A        %42 = llvm.getelementptr inbounds %4[0, %39, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>> loc(#loc1)\0A        %43 = llvm.load %42 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> f32 loc(#loc1)\0A        %44 = llvm.fmul %41, %43  {fastmathFlags = #llvm.fastmath<contract>} : f32 loc(#loc1)\0A        %45 = llvm.fadd %arg9, %44  {fastmathFlags = #llvm.fastmath<contract>} : f32 loc(#loc1)\0A        scf.yield %45 : f32 loc(#loc1)\0A      } loc(#loc1)\0A      nvvm.barrier0 loc(#loc1)\0A      %38 = arith.addi %arg6, %13 : i32 loc(#loc1)\0A      scf.yield %38, %37 : i32, f32 loc(#loc1)\0A    } loc(#loc1)\0A    %23 = arith.muli %13, %6 : i32 loc(#loc1)\0A    %24 = arith.addi %12, %7 : i32 loc(#loc1)\0A    %25 = arith.addi %24, %19 : i32 loc(#loc1)\0A    %26 = arith.addi %25, %23 : i32 loc(#loc1)\0A    %27 = arith.extsi %26 : i32 to i64 loc(#loc1)\0A    %28 = llvm.getelementptr inbounds %arg0[%27] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)\0A    llvm.store %22#1, %28 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : f32, !llvm.ptr loc(#loc1)\0A    llvm.return loc(#loc1)\0A  } loc(#loc1)\0A  llvm.func local_unnamed_addr @_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii(%arg0: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly} loc(unknown), %arg1: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly} loc(unknown), %arg2: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly} loc(unknown), %arg3: i32 {llvm.noundef} loc(unknown), %arg4: i32 {llvm.noundef} loc(unknown)) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii) attributes {convergent, frame_pointer = #llvm.framePointerKind<all>, no_unwind, passthrough = [\22mustprogress\22, \22norecurse\22, [\22no-trapping-math\22, \22true\22], [\22stack-protector-buffer-size\22, \228\22], [\22target-cpu\22, \22sm_52\22], [\22uniform-work-group-size\22, \22true\22]], target_cpu = \22sm_52\22, target_features = #llvm.target_features<[\22+ptx84\22, \22+sm_52\22]>} {\0A    %c1_i32 = arith.constant 1 : i32 loc(#loc1)\0A    %c0_i32 = arith.constant 0 : i32 loc(#loc1)\0A    %c32_i32 = arith.constant 32 : i32 loc(#loc1)\0A    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)\0A    %1 = llvm.mlir.addressof @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs : !llvm.ptr<3> loc(#loc1)\0A    %c5_i32 = arith.constant 5 : i32 loc(#loc1)\0A    %2 = llvm.mlir.addressof @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As : !llvm.ptr<3> loc(#loc1)\0A    %3 = llvm.addrspacecast %2 : !llvm.ptr<3> to !llvm.ptr loc(#loc1)\0A    %4 = llvm.addrspacecast %1 : !llvm.ptr<3> to !llvm.ptr loc(#loc1)\0A    %5 = nvvm.read.ptx.sreg.ctaid.x : i32 loc(#loc1)\0A    %6 = nvvm.read.ptx.sreg.ctaid.y : i32 loc(#loc1)\0A    %7 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc1)\0A    %8 = nvvm.read.ptx.sreg.tid.y : i32 loc(#loc1)\0A    %9 = arith.shli %arg3, %c5_i32 : i32 loc(#loc1)\0A    %10 = arith.muli %9, %6 : i32 loc(#loc1)\0A    %11 = arith.addi %10, %arg3 : i32 loc(#loc1)\0A    %12 = arith.shli %5, %c5_i32 : i32 loc(#loc1)\0A    %13 = arith.shli %arg4, %c5_i32 : i32 loc(#loc1)\0A    %14 = arith.muli %8, %arg3 : i32 loc(#loc1)\0A    %15 = arith.addi %14, %7 : i32 loc(#loc1)\0A    %16 = arith.extui %8 : i32 to i64 loc(#loc1)\0A    %17 = arith.extui %7 : i32 to i64 loc(#loc1)\0A    %18 = llvm.getelementptr inbounds %3[0, %16, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<32 x array<32 x f32>> loc(#loc1)\0A    %19 = arith.muli %8, %arg4 : i32 loc(#loc1)\0A    %20 = arith.addi %19, %7 : i32 loc(#loc1)\0A    %21 = llvm.getelementptr inbounds %4[0, %16, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<32 x array<32 x f32>> loc(#loc1)\0A    %22:2 = scf.for %arg5 = %10 to %11 step %c32_i32 iter_args(%arg6 = %12, %arg7 = %0) -> (i32, f32)  : i32 {\0A      %29 = arith.addi %15, %arg5 : i32 loc(#loc1)\0A      %30 = arith.extsi %29 : i32 to i64 loc(#loc1)\0A      %31 = llvm.getelementptr inbounds %arg1[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)\0A      %32 = llvm.load %31 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> f32 loc(#loc1)\0A      llvm.store %32, %18 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : f32, !llvm.ptr loc(#loc1)\0A      %33 = arith.addi %20, %arg6 : i32 loc(#loc1)\0A      %34 = arith.extsi %33 : i32 to i64 loc(#loc1)\0A      %35 = llvm.getelementptr inbounds %arg2[%34] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)\0A      %36 = llvm.load %35 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> f32 loc(#loc1)\0A      llvm.store %36, %21 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : f32, !llvm.ptr loc(#loc1)\0A      nvvm.barrier0 loc(#loc1)\0A      %37 = scf.for %arg8 = %c0_i32 to %c32_i32 step %c1_i32 iter_args(%arg9 = %arg7) -> (f32)  : i32 {\0A        %39 = arith.extui %arg8 : i32 to i64 loc(#loc1)\0A        %40 = llvm.getelementptr inbounds %3[0, %16, %39] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<32 x array<32 x f32>> loc(#loc1)\0A        %41 = llvm.load %40 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> f32 loc(#loc1)\0A        %42 = llvm.getelementptr inbounds %4[0, %39, %17] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<32 x array<32 x f32>> loc(#loc1)\0A        %43 = llvm.load %42 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> f32 loc(#loc1)\0A        %44 = llvm.fmul %41, %43  {fastmathFlags = #llvm.fastmath<contract>} : f32 loc(#loc1)\0A        %45 = llvm.fadd %arg9, %44  {fastmathFlags = #llvm.fastmath<contract>} : f32 loc(#loc1)\0A        scf.yield %45 : f32 loc(#loc1)\0A      } loc(#loc1)\0A      nvvm.barrier0 loc(#loc1)\0A      %38 = arith.addi %arg6, %13 : i32 loc(#loc1)\0A      scf.yield %38, %37 : i32, f32 loc(#loc1)\0A    } loc(#loc1)\0A    %23 = arith.muli %13, %6 : i32 loc(#loc1)\0A    %24 = arith.addi %12, %7 : i32 loc(#loc1)\0A    %25 = arith.addi %24, %19 : i32 loc(#loc1)\0A    %26 = arith.addi %25, %23 : i32 loc(#loc1)\0A    %27 = arith.extsi %26 : i32 to i64 loc(#loc1)\0A    %28 = llvm.getelementptr inbounds %arg0[%27] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)\0A    llvm.store %22#1, %28 {alignment = 4 : i64, tbaa = [#tbaa_tag]} : f32, !llvm.ptr loc(#loc1)\0A    llvm.return loc(#loc1)\0A  } loc(#loc1)\0A} loc(#loc)\0A#loc = loc(\22matrixMul.cu\22:0:0)\0A\00") {addr_space = 0 : i32, alignment = 8 : i64, dso_local, section = ".nv_fatbin"} loc(#loc)
  llvm.mlir.global internal constant @__cuda_fatbin_wrapper() {addr_space = 0 : i32, alignment = 8 : i64, dso_local, section = ".nvFatBinSegment"} : !llvm.struct<(i32, i32, ptr, ptr)> {
    %0 = llvm.mlir.zero : !llvm.ptr loc(#loc1)
    %1 = llvm.mlir.addressof @mlir.llvm.nameless_global_2 : !llvm.ptr loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c1180844977_i32 = arith.constant 1180844977 : i32 loc(#loc1)
    %2 = llvm.mlir.undef : !llvm.struct<(i32, i32, ptr, ptr)> loc(#loc1)
    %3 = llvm.insertvalue %c1180844977_i32, %2[0] : !llvm.struct<(i32, i32, ptr, ptr)>  loc(#loc1)
    %4 = llvm.insertvalue %c1_i32, %3[1] : !llvm.struct<(i32, i32, ptr, ptr)>  loc(#loc1)
    %5 = llvm.insertvalue %1, %4[2] : !llvm.struct<(i32, i32, ptr, ptr)>  loc(#loc1)
    %6 = llvm.insertvalue %0, %5[3] : !llvm.struct<(i32, i32, ptr, ptr)>  loc(#loc1)
    llvm.return %6 : !llvm.struct<(i32, i32, ptr, ptr)> loc(#loc)
  } loc(#loc)
  llvm.mlir.global internal unnamed_addr @__cuda_gpubin_handle() {addr_space = 0 : i32, alignment = 8 : i64, dso_local} : !llvm.ptr {
    %0 = llvm.mlir.zero : !llvm.ptr loc(#loc1)
    llvm.return %0 : !llvm.ptr loc(#loc)
  } loc(#loc)
  llvm.mlir.global_ctors {ctors = [@__cuda_module_ctor], priorities = [65535 : i32]} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str("Computing result using CUDA Kernel...\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str.91("done\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str.92("\0ANOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str.93("[Matrix Multiply Using CUDA] - Starting...\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str.94("Usage -device=n (n >= 0 for deviceID)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str.95("      -wA=WidthA -hA=HeightA (Width x Height of Matrix A)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str.96("      -wB=WidthB -hB=HeightB (Width x Height of Matrix B)\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str.97("  Note: Outer matrix dimensions of A & B matrices must be equal.\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.mlir.global private unnamed_addr constant @str.98("exiting...\00") {addr_space = 0 : i32, alignment = 1 : i64, dso_local} loc(#loc)
  llvm.func local_unnamed_addr @_Z12ConstantInitPfif(%arg0: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly} loc(unknown), %arg1: i32 {llvm.noundef} loc(unknown), %arg2: f32 {llvm.noundef} loc(unknown)) attributes {memory_effects = #llvm.memory_effects<other = none, argMem = write, inaccessibleMem = none>, no_unwind, passthrough = ["mustprogress", "nofree", "norecurse", "nosync", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c0_i64 = arith.constant 0 : i64 loc(#loc1)
    %c1_i64 = arith.constant 1 : i64 loc(#loc1)
    %0 = arith.maxsi %arg1, %c0_i32 : i32 loc(#loc1)
    %1 = arith.extui %0 : i32 to i64 loc(#loc1)
    scf.for %arg3 = %c0_i64 to %1 step %c1_i64  : i64 {
      %2 = llvm.getelementptr inbounds %arg0[%arg3] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
      llvm.store %arg2, %2 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
    } loc(#loc1)
    llvm.return loc(#loc1)
  } loc(#loc1)
  llvm.func local_unnamed_addr @_Z14MatrixMultiplyiPPciRK4dim3S3_(%arg0: i32 loc(unknown), %arg1: !llvm.ptr {llvm.nocapture, llvm.readnone} loc(unknown), %arg2: i32 {llvm.noundef} loc(unknown), %arg3: !llvm.ptr {llvm.align = 4 : i64, llvm.dereferenceable = 12 : i64, llvm.nocapture, llvm.nonnull, llvm.noundef, llvm.readonly} loc(unknown), %arg4: !llvm.ptr {llvm.align = 4 : i64, llvm.dereferenceable = 12 : i64, llvm.nocapture, llvm.nonnull, llvm.noundef, llvm.readonly} loc(unknown)) -> (i32 {llvm.noundef}) attributes {passthrough = ["mustprogress", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %c16_i64 = arith.constant 16 : i64 loc(#loc1)
    %c2_i32 = arith.constant 2 : i32 loc(#loc1)
    %0 = ub.poison : !llvm.ptr loc(#loc1)
    %1 = ub.poison : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %2 = llvm.mlir.addressof @stderr : !llvm.ptr loc(#loc1)
    %3 = llvm.mlir.addressof @".str.88" : !llvm.ptr loc(#loc1)
    %4 = llvm.mlir.addressof @".str.1" : !llvm.ptr loc(#loc1)
    %c147_i32 = arith.constant 147 : i32 loc(#loc1)
    %5 = llvm.mlir.addressof @".str" : !llvm.ptr loc(#loc1)
    %c151_i32 = arith.constant 151 : i32 loc(#loc1)
    %6 = llvm.mlir.addressof @".str.2" : !llvm.ptr loc(#loc1)
    %c0_i64 = arith.constant 0 : i64 loc(#loc1)
    %7 = llvm.mlir.constant(1.000000e+00 : f32) : f32 loc(#loc1)
    %c1_i64 = arith.constant 1 : i64 loc(#loc1)
    %8 = llvm.mlir.constant(0.00999999977 : f32) : f32 loc(#loc1)
    %c166_i32 = arith.constant 166 : i32 loc(#loc1)
    %9 = llvm.mlir.addressof @".str.3" : !llvm.ptr loc(#loc1)
    %10 = llvm.mlir.zero : !llvm.ptr loc(#loc1)
    %c173_i32 = arith.constant 173 : i32 loc(#loc1)
    %11 = llvm.mlir.addressof @".str.5" : !llvm.ptr loc(#loc1)
    %c174_i32 = arith.constant 174 : i32 loc(#loc1)
    %12 = llvm.mlir.addressof @".str.6" : !llvm.ptr loc(#loc1)
    %c175_i32 = arith.constant 175 : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @".str.7" : !llvm.ptr loc(#loc1)
    %c178_i32 = arith.constant 178 : i32 loc(#loc1)
    %14 = llvm.mlir.addressof @".str.8" : !llvm.ptr loc(#loc1)
    %c179_i32 = arith.constant 179 : i32 loc(#loc1)
    %15 = llvm.mlir.addressof @".str.9" : !llvm.ptr loc(#loc1)
    %c181_i32 = arith.constant 181 : i32 loc(#loc1)
    %16 = llvm.mlir.addressof @".str.10" : !llvm.ptr loc(#loc1)
    %c185_i32 = arith.constant 185 : i32 loc(#loc1)
    %17 = llvm.mlir.addressof @".str.11" : !llvm.ptr loc(#loc1)
    %c187_i32 = arith.constant 187 : i32 loc(#loc1)
    %18 = llvm.mlir.addressof @".str.12" : !llvm.ptr loc(#loc1)
    %19 = llvm.mlir.addressof @str : !llvm.ptr loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %20 = llvm.mlir.addressof @str.91 : !llvm.ptr loc(#loc1)
    %c206_i32 = arith.constant 206 : i32 loc(#loc1)
    %21 = llvm.mlir.addressof @".str.15" : !llvm.ptr loc(#loc1)
    %c209_i32 = arith.constant 209 : i32 loc(#loc1)
    %22 = llvm.mlir.addressof @".str.16" : !llvm.ptr loc(#loc1)
    %c300_i32 = arith.constant 300 : i32 loc(#loc1)
    %c225_i32 = arith.constant 225 : i32 loc(#loc1)
    %23 = llvm.mlir.addressof @".str.17" : !llvm.ptr loc(#loc1)
    %c228_i32 = arith.constant 228 : i32 loc(#loc1)
    %24 = llvm.mlir.addressof @".str.18" : !llvm.ptr loc(#loc1)
    %25 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %c231_i32 = arith.constant 231 : i32 loc(#loc1)
    %26 = llvm.mlir.addressof @".str.19" : !llvm.ptr loc(#loc1)
    %27 = llvm.mlir.constant(3.000000e+02 : f32) : f32 loc(#loc1)
    %28 = llvm.mlir.constant(2.000000e+00 : f64) : f64 loc(#loc1)
    %29 = llvm.mlir.constant(9.9999997171806853E-10 : f64) : f64 loc(#loc1)
    %30 = llvm.mlir.constant(1.000000e+03 : f32) : f32 loc(#loc1)
    %31 = llvm.mlir.addressof @".str.20" : !llvm.ptr loc(#loc1)
    %c247_i32 = arith.constant 247 : i32 loc(#loc1)
    %32 = llvm.mlir.addressof @".str.21" : !llvm.ptr loc(#loc1)
    %c248_i32 = arith.constant 248 : i32 loc(#loc1)
    %33 = llvm.mlir.addressof @".str.22" : !llvm.ptr loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %34 = llvm.mlir.constant(9.9999999999999995E-7 : f64) : f64 loc(#loc1)
    %35 = llvm.mlir.addressof @".str.23" : !llvm.ptr loc(#loc1)
    %false = arith.constant false loc(#loc1)
    %36 = llvm.mlir.addressof @".str.25" : !llvm.ptr loc(#loc1)
    %37 = llvm.mlir.addressof @".str.26" : !llvm.ptr loc(#loc1)
    %c273_i32 = arith.constant 273 : i32 loc(#loc1)
    %38 = llvm.mlir.addressof @".str.27" : !llvm.ptr loc(#loc1)
    %c274_i32 = arith.constant 274 : i32 loc(#loc1)
    %39 = llvm.mlir.addressof @".str.28" : !llvm.ptr loc(#loc1)
    %c275_i32 = arith.constant 275 : i32 loc(#loc1)
    %40 = llvm.mlir.addressof @".str.29" : !llvm.ptr loc(#loc1)
    %c276_i32 = arith.constant 276 : i32 loc(#loc1)
    %41 = llvm.mlir.addressof @".str.30" : !llvm.ptr loc(#loc1)
    %c277_i32 = arith.constant 277 : i32 loc(#loc1)
    %42 = llvm.mlir.addressof @".str.31" : !llvm.ptr loc(#loc1)
    %c278_i32 = arith.constant 278 : i32 loc(#loc1)
    %43 = llvm.mlir.addressof @".str.32" : !llvm.ptr loc(#loc1)
    %c279_i32 = arith.constant 279 : i32 loc(#loc1)
    %44 = llvm.mlir.addressof @".str.33" : !llvm.ptr loc(#loc1)
    %c280_i32 = arith.constant 280 : i32 loc(#loc1)
    %45 = llvm.mlir.addressof @".str.34" : !llvm.ptr loc(#loc1)
    %46 = llvm.mlir.addressof @str.92 : !llvm.ptr loc(#loc1)
    %47 = llvm.mlir.addressof @".str.4" : !llvm.ptr loc(#loc1)
    %c34_i64 = arith.constant 34 : i64 loc(#loc1)
    %48 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %49 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %50 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %51 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %52 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %53 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %54 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %55 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %56 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %57 = llvm.alloca %c1_i32 x f32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %58 = llvm.load %arg3 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
    %59 = llvm.getelementptr inbounds %arg3[4] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
    %60 = llvm.load %59 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : !llvm.ptr -> i32 loc(#loc1)
    %61 = arith.muli %60, %58 : i32 loc(#loc1)
    %62 = arith.shli %61, %c2_i32 : i32 loc(#loc1)
    llvm.intr.lifetime.start 8, %48 : !llvm.ptr loc(#loc1)
    %63 = arith.extui %62 : i32 to i64 loc(#loc1)
    %64 = llvm.call @cudaHostAlloc(%48, %63, %c0_i32) : (!llvm.ptr, i64, i32) -> i32 loc(#loc1)
    %65 = arith.cmpi eq, %64, %c0_i32 : i32 loc(#loc1)
    %66:6 = scf.if %65 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
      %70 = llvm.load %arg4 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
      %71 = llvm.getelementptr inbounds %arg4[4] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
      %72 = llvm.load %71 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : !llvm.ptr -> i32 loc(#loc1)
      %73 = arith.muli %72, %70 : i32 loc(#loc1)
      %74 = arith.shli %73, %c2_i32 : i32 loc(#loc1)
      llvm.intr.lifetime.start 8, %49 : !llvm.ptr loc(#loc1)
      %75 = arith.extui %74 : i32 to i64 loc(#loc1)
      %76 = llvm.call @cudaHostAlloc(%49, %75, %c0_i32) : (!llvm.ptr, i64, i32) -> i32 loc(#loc1)
      %77 = arith.cmpi eq, %76, %c0_i32 : i32 loc(#loc1)
      %78:6 = scf.if %77 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
        llvm.intr.lifetime.start 8, %50 : !llvm.ptr loc(#loc1)
        %79 = llvm.load %48 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
        %80 = arith.maxsi %61, %c0_i32 : i32 loc(#loc1)
        %81 = arith.extui %80 : i32 to i64 loc(#loc1)
        scf.for %arg5 = %c0_i64 to %81 step %c1_i64  : i64 {
          %93 = llvm.getelementptr inbounds %79[%arg5] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
          llvm.store %7, %93 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
        } loc(#loc1)
        %82 = llvm.load %49 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
        %83 = arith.maxsi %73, %c0_i32 : i32 loc(#loc1)
        %84 = arith.extui %83 : i32 to i64 loc(#loc1)
        scf.for %arg5 = %c0_i64 to %84 step %c1_i64  : i64 {
          %93 = llvm.getelementptr inbounds %82[%arg5] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
          llvm.store %8, %93 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
        } loc(#loc1)
        llvm.intr.lifetime.start 8, %51 : !llvm.ptr loc(#loc1)
        llvm.intr.lifetime.start 8, %52 : !llvm.ptr loc(#loc1)
        llvm.intr.lifetime.start 8, %53 : !llvm.ptr loc(#loc1)
        %85 = llvm.load %arg4 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
        %86 = llvm.load %59 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : !llvm.ptr -> i32 loc(#loc1)
        %87 = arith.muli %86, %85 : i32 loc(#loc1)
        %88 = arith.shli %87, %c2_i32 : i32 loc(#loc1)
        llvm.intr.lifetime.start 8, %54 : !llvm.ptr loc(#loc1)
        %89 = arith.extui %88 : i32 to i64 loc(#loc1)
        %90 = llvm.call @cudaHostAlloc(%54, %89, %c0_i32) : (!llvm.ptr, i64, i32) -> i32 loc(#loc1)
        %91 = arith.cmpi eq, %90, %c0_i32 : i32 loc(#loc1)
        %92:6 = scf.if %91 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
          %93 = llvm.load %54 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %94 = llvm.ptrtoint %93 : !llvm.ptr to i64 loc(#loc1)
          %95 = llvm.ptrtoint %10 : !llvm.ptr to i64 loc(#loc1)
          %96 = arith.cmpi eq, %94, %95 : i64 loc(#loc1)
          %97:6 = scf.if %96 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
            %98 = llvm.load %2 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
            %99 = llvm.call @fwrite(%47, %c34_i64, %c1_i64, %98) {no_unwind} : (!llvm.ptr, i64, i64, !llvm.ptr) -> i64 loc(#loc1)
            llvm.call @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
            scf.yield %1, %1, %1, %0, %1, %c1_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
          } else {
            %98 = llvm.call @cudaMalloc(%51, %63) : (!llvm.ptr, i64) -> i32 loc(#loc1)
            %99 = arith.cmpi eq, %98, %c0_i32 : i32 loc(#loc1)
            %100:6 = scf.if %99 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
              %101 = llvm.call @cudaMalloc(%52, %75) : (!llvm.ptr, i64) -> i32 loc(#loc1)
              %102 = arith.cmpi eq, %101, %c0_i32 : i32 loc(#loc1)
              %103:6 = scf.if %102 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                %104 = llvm.call @cudaMalloc(%53, %89) : (!llvm.ptr, i64) -> i32 loc(#loc1)
                %105 = arith.cmpi eq, %104, %c0_i32 : i32 loc(#loc1)
                %106:6 = scf.if %105 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                  llvm.intr.lifetime.start 8, %55 : !llvm.ptr loc(#loc1)
                  llvm.intr.lifetime.start 8, %56 : !llvm.ptr loc(#loc1)
                  %107 = llvm.call @cudaEventCreate(%55) : (!llvm.ptr) -> i32 loc(#loc1)
                  %108 = arith.cmpi eq, %107, %c0_i32 : i32 loc(#loc1)
                  %109:6 = scf.if %108 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                    %110 = llvm.call @cudaEventCreate(%56) : (!llvm.ptr) -> i32 loc(#loc1)
                    %111 = arith.cmpi eq, %110, %c0_i32 : i32 loc(#loc1)
                    %112:6 = scf.if %111 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                      %113 = llvm.call @cudaStreamCreateWithFlags(%50, %c1_i32) : (!llvm.ptr, i32) -> i32 loc(#loc1)
                      %114 = arith.cmpi eq, %113, %c0_i32 : i32 loc(#loc1)
                      %115:6 = scf.if %114 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                        %116 = llvm.load %51 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                        %117 = llvm.load %48 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                        %118 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                        %119 = llvm.call @cudaMemcpyAsync(%116, %117, %63, %c1_i32, %118) : (!llvm.ptr, !llvm.ptr, i64, i32, !llvm.ptr) -> i32 loc(#loc1)
                        %120 = arith.cmpi eq, %119, %c0_i32 : i32 loc(#loc1)
                        %121:6 = scf.if %120 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                          %122 = llvm.load %52 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                          %123 = llvm.load %49 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                          %124 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                          %125 = llvm.call @cudaMemcpyAsync(%122, %123, %75, %c1_i32, %124) : (!llvm.ptr, !llvm.ptr, i64, i32, !llvm.ptr) -> i32 loc(#loc1)
                          %126 = arith.cmpi eq, %125, %c0_i32 : i32 loc(#loc1)
                          %127:6 = scf.if %126 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                            %128 = llvm.load %arg4 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
                            %129 = arith.divui %128, %arg2 : i32 loc(#loc1)
                            %130 = llvm.load %59 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : !llvm.ptr -> i32 loc(#loc1)
                            %131 = arith.divui %130, %arg2 : i32 loc(#loc1)
                            %132 = llvm.call @puts(%19) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
                            %133 = arith.cmpi eq, %arg2, %c16_i32 : i32 loc(#loc1)
                            %134 = llvm.load %53 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                            %135 = llvm.load %51 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                            %136 = llvm.load %52 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                            %137 = llvm.load %arg3 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
                            %138 = llvm.load %arg4 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
                            scf.if %133 {
                              %144 = arith.extsi %129 : i32 to i64 loc(#loc1)
                              %145 = arith.extsi %131 : i32 to i64 loc(#loc1)
                              gpu.launch_func  @__mlir_gpu_module::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii blocks in (%144, %145, %c1_i64) threads in (%c16_i64, %c16_i64, %c1_i64) : i64 dynamic_shared_memory_size %c0_i32 args(%134 : !llvm.ptr, %135 : !llvm.ptr, %136 : !llvm.ptr, %137 : i32, %138 : i32) loc(#loc1)
                            } else {
                              %144 = arith.extsi %129 : i32 to i64 loc(#loc1)
                              %145 = arith.extsi %131 : i32 to i64 loc(#loc1)
                              %146 = arith.extsi %arg2 : i32 to i64 loc(#loc1)
                              %147 = arith.extsi %arg2 : i32 to i64 loc(#loc1)
                              gpu.launch_func  @__mlir_gpu_module::@_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii blocks in (%144, %145, %c1_i64) threads in (%146, %147, %c1_i64) : i64 dynamic_shared_memory_size %c0_i32 args(%134 : !llvm.ptr, %135 : !llvm.ptr, %136 : !llvm.ptr, %137 : i32, %138 : i32) loc(#loc1)
                            } loc(#loc1)
                            %139 = llvm.call @puts(%20) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
                            %140 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                            %141 = llvm.call @cudaStreamSynchronize(%140) : (!llvm.ptr) -> i32 loc(#loc1)
                            %142 = arith.cmpi eq, %141, %c0_i32 : i32 loc(#loc1)
                            %143:6 = scf.if %142 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                              %144 = llvm.load %55 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                              %145 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                              %146 = llvm.call @cudaEventRecord(%144, %145) : (!llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
                              %147 = arith.cmpi eq, %146, %c0_i32 : i32 loc(#loc1)
                              %148:6 = scf.if %147 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                scf.for %arg5 = %c0_i32 to %c300_i32 step %c1_i32  : i32 {
                                  %154 = llvm.load %53 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                  %155 = llvm.load %51 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                  %156 = llvm.load %52 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                  %157 = llvm.load %arg3 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
                                  %158 = llvm.load %arg4 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
                                  scf.if %133 {
                                    %159 = arith.extsi %129 : i32 to i64 loc(#loc1)
                                    %160 = arith.extsi %131 : i32 to i64 loc(#loc1)
                                    gpu.launch_func  @__mlir_gpu_module::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii blocks in (%159, %160, %c1_i64) threads in (%c16_i64, %c16_i64, %c1_i64) : i64 dynamic_shared_memory_size %c0_i32 args(%154 : !llvm.ptr, %155 : !llvm.ptr, %156 : !llvm.ptr, %157 : i32, %158 : i32) loc(#loc1)
                                  } else {
                                    %159 = arith.extsi %129 : i32 to i64 loc(#loc1)
                                    %160 = arith.extsi %131 : i32 to i64 loc(#loc1)
                                    %161 = arith.extsi %arg2 : i32 to i64 loc(#loc1)
                                    %162 = arith.extsi %arg2 : i32 to i64 loc(#loc1)
                                    gpu.launch_func  @__mlir_gpu_module::@_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii blocks in (%159, %160, %c1_i64) threads in (%161, %162, %c1_i64) : i64 dynamic_shared_memory_size %c0_i32 args(%154 : !llvm.ptr, %155 : !llvm.ptr, %156 : !llvm.ptr, %157 : i32, %158 : i32) loc(#loc1)
                                  } loc(#loc1)
                                } loc(#loc1)
                                %149 = llvm.load %56 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                %150 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                %151 = llvm.call @cudaEventRecord(%149, %150) : (!llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
                                %152 = arith.cmpi eq, %151, %c0_i32 : i32 loc(#loc1)
                                %153:6 = scf.if %152 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                  %154 = llvm.load %56 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                  %155 = llvm.call @cudaEventSynchronize(%154) : (!llvm.ptr) -> i32 loc(#loc1)
                                  %156 = arith.cmpi eq, %155, %c0_i32 : i32 loc(#loc1)
                                  %157:6 = scf.if %156 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                    llvm.intr.lifetime.start 4, %57 : !llvm.ptr loc(#loc1)
                                    llvm.store %25, %57 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : f32, !llvm.ptr loc(#loc1)
                                    %158 = llvm.load %55 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                    %159 = llvm.load %56 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                    %160 = llvm.call @cudaEventElapsedTime(%57, %158, %159) : (!llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
                                    %161 = arith.cmpi eq, %160, %c0_i32 : i32 loc(#loc1)
                                    %162:6 = scf.if %161 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                      %163 = llvm.load %57 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
                                      %164 = llvm.fdiv %163, %27  : f32 loc(#loc1)
                                      %165 = llvm.load %arg3 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
                                      %166 = llvm.uitofp %165 : i32 to f64 loc(#loc1)
                                      %167 = llvm.fmul %166, %28  : f64 loc(#loc1)
                                      %168 = llvm.load %59 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : !llvm.ptr -> i32 loc(#loc1)
                                      %169 = llvm.uitofp %168 : i32 to f64 loc(#loc1)
                                      %170 = llvm.fmul %167, %169  : f64 loc(#loc1)
                                      %171 = llvm.load %arg4 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
                                      %172 = llvm.uitofp %171 : i32 to f64 loc(#loc1)
                                      %173 = llvm.fmul %170, %172  : f64 loc(#loc1)
                                      %174 = llvm.fmul %173, %29  : f64 loc(#loc1)
                                      %175 = llvm.fdiv %164, %30  : f32 loc(#loc1)
                                      %176 = llvm.fpext %175 : f32 to f64 loc(#loc1)
                                      %177 = llvm.fdiv %174, %176  : f64 loc(#loc1)
                                      %178 = llvm.fpext %164 : f32 to f64 loc(#loc1)
                                      %179 = arith.muli %arg2, %arg2 : i32 loc(#loc1)
                                      %180 = llvm.call @printf(%31, %177, %178, %173, %179) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, f64, f64, f64, i32) -> i32 loc(#loc1)
                                      %181 = llvm.load %54 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                      %182 = llvm.load %53 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                      %183 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                      %184 = llvm.call @cudaMemcpyAsync(%181, %182, %89, %c2_i32, %183) : (!llvm.ptr, !llvm.ptr, i64, i32, !llvm.ptr) -> i32 loc(#loc1)
                                      %185 = arith.cmpi eq, %184, %c0_i32 : i32 loc(#loc1)
                                      %186:6 = scf.if %185 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                        %187 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                        %188 = llvm.call @cudaStreamSynchronize(%187) : (!llvm.ptr) -> i32 loc(#loc1)
                                        %189 = arith.cmpi eq, %188, %c0_i32 : i32 loc(#loc1)
                                        %190:6 = scf.if %189 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                          %191 = llvm.call @printf(%33) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
                                          %192 = arith.maxsi %87, %c0_i32 : i32 loc(#loc1)
                                          %193 = arith.extui %192 : i32 to i64 loc(#loc1)
                                          %194 = scf.for %arg5 = %c0_i64 to %193 step %c1_i64 iter_args(%arg6 = %true) -> (i1)  : i64 {
                                            %201 = llvm.load %54 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                            %202 = llvm.getelementptr inbounds %201[%arg5] : (!llvm.ptr, i64) -> !llvm.ptr, f32 loc(#loc1)
                                            %203 = llvm.load %202 {alignment = 4 : i64, tbaa = [#tbaa_tag1]} : !llvm.ptr -> f32 loc(#loc1)
                                            %204 = llvm.load %arg3 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : !llvm.ptr -> i32 loc(#loc1)
                                            %205 = llvm.uitofp %204 : i32 to f32 loc(#loc1)
                                            %206 = llvm.fneg %205  : f32 loc(#loc1)
                                            %207 = llvm.intr.fmuladd(%206, %8, %203)  : (f32, f32, f32) -> f32 loc(#loc1)
                                            %208 = llvm.intr.fabs(%207)  : (f32) -> f32 loc(#loc1)
                                            %209 = llvm.fpext %208 : f32 to f64 loc(#loc1)
                                            %210 = llvm.uitofp %204 : i32 to f64 loc(#loc1)
                                            %211 = llvm.intr.fabs(%203)  : (f32) -> f32 loc(#loc1)
                                            %212 = llvm.fpext %211 : f32 to f64 loc(#loc1)
                                            %213 = llvm.fdiv %209, %212  : f64 loc(#loc1)
                                            %214 = llvm.fdiv %213, %210  : f64 loc(#loc1)
                                            %215 = llvm.fcmp "ogt" %214, %34 : f64 loc(#loc1)
                                            %216 = arith.select %215, %false, %arg6 : i1 loc(#loc1)
                                            scf.if %215 {
                                              %217 = llvm.fpext %203 : f32 to f64 loc(#loc1)
                                              %218 = llvm.fmul %205, %8  : f32 loc(#loc1)
                                              %219 = llvm.fpext %218 : f32 to f64 loc(#loc1)
                                              %220 = arith.trunci %arg5 : i64 to i32 loc(#loc1)
                                              %221 = llvm.call @printf(%35, %220, %217, %219, %34) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, i32, f64, f64, f64) -> i32 loc(#loc1)
                                            } loc(#loc1)
                                            scf.yield %216 : i1 loc(#loc1)
                                          } loc(#loc1)
                                          %195 = arith.select %194, %36, %37 {fastmathFlags = #llvm.fastmath<none>} : !llvm.ptr loc(#loc1)
                                          %196 = llvm.call @puts(%195) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
                                          %197 = llvm.load %48 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                          %198 = llvm.call @cudaFreeHost(%197) : (!llvm.ptr) -> i32 loc(#loc1)
                                          %199 = arith.cmpi eq, %198, %c0_i32 : i32 loc(#loc1)
                                          %200:6 = scf.if %199 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                            %201 = llvm.load %49 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                            %202 = llvm.call @cudaFreeHost(%201) : (!llvm.ptr) -> i32 loc(#loc1)
                                            %203 = arith.cmpi eq, %202, %c0_i32 : i32 loc(#loc1)
                                            %204:6 = scf.if %203 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                              %205 = llvm.load %54 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                              %206 = llvm.call @cudaFreeHost(%205) : (!llvm.ptr) -> i32 loc(#loc1)
                                              %207 = arith.cmpi eq, %206, %c0_i32 : i32 loc(#loc1)
                                              %208:6 = scf.if %207 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                                %209 = llvm.load %51 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                                %210 = llvm.call @cudaFree(%209) : (!llvm.ptr) -> i32 loc(#loc1)
                                                %211 = arith.cmpi eq, %210, %c0_i32 : i32 loc(#loc1)
                                                %212:6 = scf.if %211 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                                  %213 = llvm.load %52 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                                  %214 = llvm.call @cudaFree(%213) : (!llvm.ptr) -> i32 loc(#loc1)
                                                  %215 = arith.cmpi eq, %214, %c0_i32 : i32 loc(#loc1)
                                                  %216:6 = scf.if %215 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                                    %217 = llvm.load %53 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                                    %218 = llvm.call @cudaFree(%217) : (!llvm.ptr) -> i32 loc(#loc1)
                                                    %219 = arith.cmpi eq, %218, %c0_i32 : i32 loc(#loc1)
                                                    %220:6 = scf.if %219 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
                                                      %221 = llvm.load %55 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                                      %222 = llvm.call @cudaEventDestroy(%221) : (!llvm.ptr) -> i32 loc(#loc1)
                                                      %223 = arith.cmpi eq, %222, %c0_i32 : i32 loc(#loc1)
                                                      %224 = arith.select %223, %c280_i32, %c279_i32 : i32 loc(#loc1)
                                                      %225 = arith.select %223, %45, %44 : !llvm.ptr loc(#loc1)
                                                      %226:4 = scf.if %223 -> (i32, i32, i32, i32) {
                                                        %227 = llvm.load %56 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                                                        %228 = llvm.call @cudaEventDestroy(%227) : (!llvm.ptr) -> i32 loc(#loc1)
                                                        %229 = arith.cmpi eq, %228, %c0_i32 : i32 loc(#loc1)
                                                        %230 = arith.select %229, %c2_i32, %c0_i32 : i32 loc(#loc1)
                                                        %231 = scf.if %229 -> (i32) {
                                                          %232 = llvm.call @puts(%46) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
                                                          %233 = arith.xori %194, %true : i1 loc(#loc1)
                                                          %234 = arith.extui %233 : i1 to i32 loc(#loc1)
                                                          llvm.intr.lifetime.end 4, %57 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %56 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %55 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %54 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %53 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %52 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %51 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %50 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %49 : !llvm.ptr loc(#loc1)
                                                          llvm.intr.lifetime.end 8, %48 : !llvm.ptr loc(#loc1)
                                                          scf.yield %234 : i32 loc(#loc1)
                                                        } else {
                                                          scf.yield %1 : i32 loc(#loc1)
                                                        } loc(#loc1)
                                                        scf.yield %228, %228, %231, %230 : i32, i32, i32, i32 loc(#loc1)
                                                      } else {
                                                        scf.yield %222, %222, %1, %c0_i32 : i32, i32, i32, i32 loc(#loc1)
                                                      } loc(#loc1)
                                                      scf.yield %226#0, %224, %226#1, %225, %226#2, %226#3 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                                    } else {
                                                      scf.yield %218, %c278_i32, %218, %43, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                                    } loc(#loc1)
                                                    scf.yield %220#0, %220#1, %220#2, %220#3, %220#4, %220#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                                  } else {
                                                    scf.yield %214, %c277_i32, %214, %42, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                                  } loc(#loc1)
                                                  scf.yield %216#0, %216#1, %216#2, %216#3, %216#4, %216#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                                } else {
                                                  scf.yield %210, %c276_i32, %210, %41, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                                } loc(#loc1)
                                                scf.yield %212#0, %212#1, %212#2, %212#3, %212#4, %212#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                              } else {
                                                scf.yield %206, %c275_i32, %206, %40, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                              } loc(#loc1)
                                              scf.yield %208#0, %208#1, %208#2, %208#3, %208#4, %208#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                            } else {
                                              scf.yield %202, %c274_i32, %202, %39, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                            } loc(#loc1)
                                            scf.yield %204#0, %204#1, %204#2, %204#3, %204#4, %204#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                          } else {
                                            scf.yield %198, %c273_i32, %198, %38, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                          } loc(#loc1)
                                          scf.yield %200#0, %200#1, %200#2, %200#3, %200#4, %200#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                        } else {
                                          scf.yield %188, %c248_i32, %188, %21, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                        } loc(#loc1)
                                        scf.yield %190#0, %190#1, %190#2, %190#3, %190#4, %190#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                      } else {
                                        scf.yield %184, %c247_i32, %184, %32, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                      } loc(#loc1)
                                      scf.yield %186#0, %186#1, %186#2, %186#3, %186#4, %186#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                    } else {
                                      scf.yield %160, %c231_i32, %160, %26, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                    } loc(#loc1)
                                    scf.yield %162#0, %162#1, %162#2, %162#3, %162#4, %162#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                  } else {
                                    scf.yield %155, %c228_i32, %155, %24, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                  } loc(#loc1)
                                  scf.yield %157#0, %157#1, %157#2, %157#3, %157#4, %157#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                } else {
                                  scf.yield %151, %c225_i32, %151, %23, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                                } loc(#loc1)
                                scf.yield %153#0, %153#1, %153#2, %153#3, %153#4, %153#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                              } else {
                                scf.yield %146, %c209_i32, %146, %22, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                              } loc(#loc1)
                              scf.yield %148#0, %148#1, %148#2, %148#3, %148#4, %148#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                            } else {
                              scf.yield %141, %c206_i32, %141, %21, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                            } loc(#loc1)
                            scf.yield %143#0, %143#1, %143#2, %143#3, %143#4, %143#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                          } else {
                            scf.yield %125, %c187_i32, %125, %18, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                          } loc(#loc1)
                          scf.yield %127#0, %127#1, %127#2, %127#3, %127#4, %127#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                        } else {
                          scf.yield %119, %c185_i32, %119, %17, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                        } loc(#loc1)
                        scf.yield %121#0, %121#1, %121#2, %121#3, %121#4, %121#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                      } else {
                        scf.yield %113, %c181_i32, %113, %16, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                      } loc(#loc1)
                      scf.yield %115#0, %115#1, %115#2, %115#3, %115#4, %115#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                    } else {
                      scf.yield %110, %c179_i32, %110, %15, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                    } loc(#loc1)
                    scf.yield %112#0, %112#1, %112#2, %112#3, %112#4, %112#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                  } else {
                    scf.yield %107, %c178_i32, %107, %14, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                  } loc(#loc1)
                  scf.yield %109#0, %109#1, %109#2, %109#3, %109#4, %109#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                } else {
                  scf.yield %104, %c175_i32, %104, %13, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
                } loc(#loc1)
                scf.yield %106#0, %106#1, %106#2, %106#3, %106#4, %106#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
              } else {
                scf.yield %101, %c174_i32, %101, %12, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
              } loc(#loc1)
              scf.yield %103#0, %103#1, %103#2, %103#3, %103#4, %103#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
            } else {
              scf.yield %98, %c173_i32, %98, %11, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
            } loc(#loc1)
            scf.yield %100#0, %100#1, %100#2, %100#3, %100#4, %100#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
          } loc(#loc1)
          scf.yield %97#0, %97#1, %97#2, %97#3, %97#4, %97#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
        } else {
          scf.yield %90, %c166_i32, %90, %9, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
        } loc(#loc1)
        scf.yield %92#0, %92#1, %92#2, %92#3, %92#4, %92#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
      } else {
        scf.yield %76, %c151_i32, %76, %6, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
      } loc(#loc1)
      scf.yield %78#0, %78#1, %78#2, %78#3, %78#4, %78#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
    } else {
      scf.yield %64, %c147_i32, %64, %5, %1, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
    } loc(#loc1)
    %67 = arith.index_castui %66#5 : i32 to index loc(#loc1)
    %68:2 = scf.index_switch %67 -> i32, i32 
    case 0 {
      %70 = llvm.load %2 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
      %71 = llvm.call fastcc @_ZL17_cudaGetErrorEnum9cudaError(%66#0) : (i32) -> !llvm.ptr loc(#loc1)
      %72 = llvm.call @fprintf(%70, %3, %4, %66#1, %66#2, %71, %66#3) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
      llvm.call @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
      scf.yield %1, %c1_i32 : i32, i32 loc(#loc1)
    }
    case 1 {
      scf.yield %1, %c1_i32 : i32, i32 loc(#loc1)
    }
    default {
      scf.yield %66#4, %c0_i32 : i32, i32 loc(#loc1)
    } loc(#loc1)
    cf.switch %68#1 : i32, [
      default: ^bb1,
      0: ^bb2(%68#0 : i32)
    ] loc(#loc1)
  ^bb1:  // pred: ^bb0
    llvm.unreachable loc(#loc1)
  ^bb2(%69: i32 loc(unknown)):  // pred: ^bb0
    llvm.return %69 : i32 loc(#loc1)
  } loc(#loc1)
  llvm.func linkonce_odr local_unnamed_addr @_Z5checkI9cudaErrorEvT_PKcS3_i(%arg0: i32 {llvm.noundef} loc(unknown), %arg1: !llvm.ptr {llvm.noundef} loc(unknown), %arg2: !llvm.ptr {llvm.noundef} loc(unknown), %arg3: i32 {llvm.noundef} loc(unknown)) comdat(@__llvm_global_comdat::@_Z5checkI9cudaErrorEvT_PKcS3_i) attributes {passthrough = ["mustprogress", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %0 = llvm.mlir.addressof @stderr : !llvm.ptr loc(#loc1)
    %1 = llvm.mlir.addressof @".str.88" : !llvm.ptr loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %2 = arith.cmpi eq, %arg0, %c0_i32 : i32 loc(#loc1)
    cf.cond_br %2, ^bb2, ^bb1 loc(#loc1)
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
    %4 = llvm.call fastcc tail @_ZL17_cudaGetErrorEnum9cudaError(%arg0) : (i32) -> !llvm.ptr loc(#loc1)
    %5 = llvm.call tail @fprintf(%3, %1, %arg2, %arg3, %arg0, %4, %arg1) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
    llvm.call tail @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
    llvm.unreachable loc(#loc1)
  ^bb2:  // pred: ^bb0
    llvm.return loc(#loc1)
  } loc(#loc1)
  llvm.func local_unnamed_addr @fprintf(!llvm.ptr {llvm.nocapture, llvm.noundef}, !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, ...) -> (i32 {llvm.noundef}) attributes {no_unwind, passthrough = ["nofree", ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @exit(i32 {llvm.noundef}) attributes {no_unwind, passthrough = ["nofree", "noreturn", ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaMalloc(!llvm.ptr {llvm.noundef}, i64 {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaEventCreate(!llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaStreamCreateWithFlags(!llvm.ptr {llvm.noundef}, i32 {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaMemcpyAsync(!llvm.ptr {llvm.noundef}, !llvm.ptr {llvm.noundef}, i64 {llvm.noundef}, i32 {llvm.noundef}, !llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @printf(!llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, ...) -> (i32 {llvm.noundef}) attributes {no_unwind, passthrough = ["nofree", ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func linkonce_odr @_Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii(%arg0: !llvm.ptr {llvm.noundef} loc(unknown), %arg1: !llvm.ptr {llvm.noundef} loc(unknown), %arg2: !llvm.ptr {llvm.noundef} loc(unknown), %arg3: i32 {llvm.noundef} loc(unknown), %arg4: i32 {llvm.noundef} loc(unknown)) comdat(@__llvm_global_comdat::@_Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {passthrough = ["mustprogress", "norecurse", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"], ["uniform-work-group-size", "true"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %0 = llvm.mlir.addressof @_Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii : !llvm.ptr loc(#loc1)
    %1 = llvm.alloca %c1_i32 x !llvm.struct<"struct.dim3", (i32, i32, i32)> {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %2 = llvm.alloca %c1_i32 x !llvm.struct<"struct.dim3", (i32, i32, i32)> {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %3 = llvm.alloca %c1_i32 x i64 {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %4 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %5 = llvm.call @__cudaPopCallConfiguration(%1, %2, %3, %4) : (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
    %6 = llvm.load %3 {alignment = 8 : i64} : !llvm.ptr -> i64 loc(#loc1)
    %7 = llvm.load %4 {alignment = 8 : i64} : !llvm.ptr -> !llvm.ptr loc(#loc1)
    %8 = llvm.load %1 {alignment = 8 : i64} : !llvm.ptr -> i64 loc(#loc1)
    %9 = llvm.getelementptr inbounds %1[8] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
    %10 = llvm.load %9 {alignment = 8 : i64} : !llvm.ptr -> i32 loc(#loc1)
    %11 = llvm.load %2 {alignment = 8 : i64} : !llvm.ptr -> i64 loc(#loc1)
    %12 = llvm.getelementptr inbounds %2[8] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
    %13 = llvm.load %12 {alignment = 8 : i64} : !llvm.ptr -> i32 loc(#loc1)
    llvm.call @__mlir_launch_coerced_kernel__Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii(%0, %8, %10, %11, %13, %6, %7, %arg0, %arg1, %arg2, %arg3, %arg4) : (!llvm.ptr, i64, i32, i64, i32, i64, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32) -> () loc(#loc1)
    llvm.return loc(#loc1)
  } loc(#loc1)
  llvm.func linkonce_odr @_Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii(%arg0: !llvm.ptr {llvm.noundef} loc(unknown), %arg1: !llvm.ptr {llvm.noundef} loc(unknown), %arg2: !llvm.ptr {llvm.noundef} loc(unknown), %arg3: i32 {llvm.noundef} loc(unknown), %arg4: i32 {llvm.noundef} loc(unknown)) comdat(@__llvm_global_comdat::@_Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii) attributes {passthrough = ["mustprogress", "norecurse", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"], ["uniform-work-group-size", "true"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %0 = llvm.mlir.addressof @_Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii : !llvm.ptr loc(#loc1)
    %1 = llvm.alloca %c1_i32 x !llvm.struct<"struct.dim3", (i32, i32, i32)> {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %2 = llvm.alloca %c1_i32 x !llvm.struct<"struct.dim3", (i32, i32, i32)> {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %3 = llvm.alloca %c1_i32 x i64 {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %4 = llvm.alloca %c1_i32 x !llvm.ptr {alignment = 8 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %5 = llvm.call @__cudaPopCallConfiguration(%1, %2, %3, %4) : (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
    %6 = llvm.load %3 {alignment = 8 : i64} : !llvm.ptr -> i64 loc(#loc1)
    %7 = llvm.load %4 {alignment = 8 : i64} : !llvm.ptr -> !llvm.ptr loc(#loc1)
    %8 = llvm.load %1 {alignment = 8 : i64} : !llvm.ptr -> i64 loc(#loc1)
    %9 = llvm.getelementptr inbounds %1[8] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
    %10 = llvm.load %9 {alignment = 8 : i64} : !llvm.ptr -> i32 loc(#loc1)
    %11 = llvm.load %2 {alignment = 8 : i64} : !llvm.ptr -> i64 loc(#loc1)
    %12 = llvm.getelementptr inbounds %2[8] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
    %13 = llvm.load %12 {alignment = 8 : i64} : !llvm.ptr -> i32 loc(#loc1)
    llvm.call @__mlir_launch_coerced_kernel__Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii(%0, %8, %10, %11, %13, %6, %7, %arg0, %arg1, %arg2, %arg3, %arg4) : (!llvm.ptr, i64, i32, i64, i32, i64, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32) -> () loc(#loc1)
    llvm.return loc(#loc1)
  } loc(#loc1)
  llvm.func local_unnamed_addr @cudaStreamSynchronize(!llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaEventRecord(!llvm.ptr {llvm.noundef}, !llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaEventSynchronize(!llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaEventElapsedTime(!llvm.ptr {llvm.noundef}, !llvm.ptr {llvm.noundef}, !llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaFreeHost(!llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaFree(!llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaEventDestroy(!llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @main(%arg0: i32 {llvm.noundef} loc(unknown), %arg1: !llvm.ptr {llvm.noundef} loc(unknown)) -> (i32 {llvm.noundef}) attributes {passthrough = ["mustprogress", "norecurse", "noreturn", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %0 = llvm.mlir.addressof @str.93 : !llvm.ptr loc(#loc1)
    %c1_i64 = arith.constant 1 : i64 loc(#loc1)
    %false = arith.constant false loc(#loc1)
    %c0_i64 = arith.constant 0 : i64 loc(#loc1)
    %c45_i8 = arith.constant 45 : i8 loc(#loc1)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %c32_i64 = arith.constant 32 : i64 loc(#loc1)
    %c61_i32 = arith.constant 61 : i32 loc(#loc1)
    %1 = llvm.mlir.zero : !llvm.ptr loc(#loc1)
    %c4294967295_i64 = arith.constant 4294967295 : i64 loc(#loc1)
    %c4_i64 = arith.constant 4 : i64 loc(#loc1)
    %2 = llvm.mlir.addressof @".str.37" : !llvm.ptr loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %3 = llvm.mlir.addressof @".str.38" : !llvm.ptr loc(#loc1)
    %c320_i32 = arith.constant 320 : i32 loc(#loc1)
    %c640_i32 = arith.constant 640 : i32 loc(#loc1)
    %c2_i64 = arith.constant 2 : i64 loc(#loc1)
    %4 = llvm.mlir.addressof @".str.43" : !llvm.ptr loc(#loc1)
    %c2_i32 = arith.constant 2 : i32 loc(#loc1)
    %c61_i8 = arith.constant 61 : i8 loc(#loc1)
    %c3_i64 = arith.constant 3 : i64 loc(#loc1)
    %c10_i32 = arith.constant 10 : i32 loc(#loc1)
    %5 = llvm.mlir.addressof @".str.44" : !llvm.ptr loc(#loc1)
    %6 = llvm.mlir.addressof @".str.45" : !llvm.ptr loc(#loc1)
    %7 = llvm.mlir.addressof @".str.46" : !llvm.ptr loc(#loc1)
    %8 = llvm.mlir.addressof @".str.47" : !llvm.ptr loc(#loc1)
    %9 = llvm.mlir.addressof @".str.48" : !llvm.ptr loc(#loc1)
    %10 = llvm.mlir.addressof @".str.49" : !llvm.ptr loc(#loc1)
    %11 = llvm.mlir.addressof @".str.1" : !llvm.ptr loc(#loc1)
    %c348_i32 = arith.constant 348 : i32 loc(#loc1)
    %12 = llvm.mlir.poison : i32 loc(#loc1)
    %13 = llvm.mlir.poison : !llvm.ptr loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %14 = llvm.mlir.addressof @".str.50" : !llvm.ptr loc(#loc1)
    %c350_i32 = arith.constant 350 : i32 loc(#loc1)
    %15 = llvm.mlir.addressof @str.94 : !llvm.ptr loc(#loc1)
    %16 = llvm.mlir.addressof @str.95 : !llvm.ptr loc(#loc1)
    %17 = llvm.mlir.addressof @str.96 : !llvm.ptr loc(#loc1)
    %18 = llvm.mlir.addressof @str.97 : !llvm.ptr loc(#loc1)
    %19 = llvm.alloca %c1_i32 x !llvm.struct<"struct.dim3", (i32, i32, i32)> {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %20 = llvm.alloca %c1_i32 x !llvm.struct<"struct.dim3", (i32, i32, i32)> {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %21 = llvm.call tail @puts(%0) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
    %22 = arith.cmpi sgt, %arg0, %c0_i32 : i32 loc(#loc1)
    %23 = scf.if %22 -> (i32) {
      %25 = arith.extui %arg0 : i32 to i64 loc(#loc1)
      %26 = llvm.ptrtoint %1 : !llvm.ptr to i64 loc(#loc1)
      %27 = scf.for %arg2 = %c1_i64 to %25 step %c1_i64 iter_args(%arg3 = %false) -> (i1)  : i64 {
        %31 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
        %32 = llvm.load %31 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
        %33 = scf.while (%arg4 = %c0_i64) : (i64) -> i64 {
          %50 = llvm.getelementptr inbounds %32[%arg4] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
          %51 = llvm.load %50 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
          %52 = arith.cmpi eq, %51, %c45_i8 : i8 loc(#loc1)
          scf.condition(%52) %arg4 : i64 loc(#loc1)
        } do {
        ^bb0(%arg4: i64 loc(unknown)):
          %50 = arith.addi %arg4, %c1_i64 : i64 loc(#loc1)
          scf.yield %50 : i64 loc(#loc1)
        } loc(#loc1)
        %34 = arith.trunci %33 : i64 to i32 loc(#loc1)
        %35 = llvm.call tail @strlen(%32) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
        %36 = arith.trunci %35 : i64 to i32 loc(#loc1)
        %37 = arith.addi %36, %c-1_i32 : i32 loc(#loc1)
        %38 = arith.cmpi sgt, %37, %34 : i32 loc(#loc1)
        %39 = arith.shli %33, %c32_i64 : i64 loc(#loc1)
        %40 = arith.shrsi %39, %c32_i64 : i64 loc(#loc1)
        %41 = arith.select %38, %40, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
        %42 = llvm.getelementptr inbounds %32[%41] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
        %43 = llvm.call tail @strchr(%42, %c61_i32) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr, i32) -> !llvm.ptr loc(#loc1)
        %44 = llvm.ptrtoint %43 : !llvm.ptr to i64 loc(#loc1)
        %45 = arith.cmpi eq, %44, %26 : i64 loc(#loc1)
        %46 = scf.if %45 -> (i64) {
          %50 = llvm.call tail @strlen(%42) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
          scf.yield %50 : i64 loc(#loc1)
        } else {
          %50 = llvm.ptrtoint %43 : !llvm.ptr to i64 loc(#loc1)
          %51 = llvm.ptrtoint %42 : !llvm.ptr to i64 loc(#loc1)
          %52 = arith.subi %50, %51 : i64 loc(#loc1)
          scf.yield %52 : i64 loc(#loc1)
        } loc(#loc1)
        %47 = arith.andi %46, %c4294967295_i64 : i64 loc(#loc1)
        %48 = arith.cmpi eq, %47, %c4_i64 : i64 loc(#loc1)
        %49 = scf.if %48 -> (i1) {
          %50 = llvm.call tail @strncasecmp(%42, %2, %c4_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
          %51 = arith.cmpi eq, %50, %c0_i32 : i32 loc(#loc1)
          %52 = arith.select %51, %true, %arg3 : i1 loc(#loc1)
          scf.yield %52 : i1 loc(#loc1)
        } else {
          scf.yield %arg3 : i1 loc(#loc1)
        } loc(#loc1)
        scf.yield %49 : i1 loc(#loc1)
      } loc(#loc1)
      %28 = scf.if %27 -> (i32) {
        scf.yield %c0_i32 : i32 loc(#loc1)
      } else {
        %31 = llvm.ptrtoint %1 : !llvm.ptr to i64 loc(#loc1)
        %32 = scf.for %arg2 = %c1_i64 to %25 step %c1_i64 iter_args(%arg3 = %false) -> (i1)  : i64 {
          %35 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
          %36 = llvm.load %35 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %37 = scf.while (%arg4 = %c0_i64) : (i64) -> i64 {
            %54 = llvm.getelementptr inbounds %36[%arg4] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %55 = llvm.load %54 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
            %56 = arith.cmpi eq, %55, %c45_i8 : i8 loc(#loc1)
            scf.condition(%56) %arg4 : i64 loc(#loc1)
          } do {
          ^bb0(%arg4: i64 loc(unknown)):
            %54 = arith.addi %arg4, %c1_i64 : i64 loc(#loc1)
            scf.yield %54 : i64 loc(#loc1)
          } loc(#loc1)
          %38 = arith.trunci %37 : i64 to i32 loc(#loc1)
          %39 = llvm.call tail @strlen(%36) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
          %40 = arith.trunci %39 : i64 to i32 loc(#loc1)
          %41 = arith.addi %40, %c-1_i32 : i32 loc(#loc1)
          %42 = arith.cmpi sgt, %41, %38 : i32 loc(#loc1)
          %43 = arith.shli %37, %c32_i64 : i64 loc(#loc1)
          %44 = arith.shrsi %43, %c32_i64 : i64 loc(#loc1)
          %45 = arith.select %42, %44, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
          %46 = llvm.getelementptr inbounds %36[%45] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
          %47 = llvm.call tail @strchr(%46, %c61_i32) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr, i32) -> !llvm.ptr loc(#loc1)
          %48 = llvm.ptrtoint %47 : !llvm.ptr to i64 loc(#loc1)
          %49 = arith.cmpi eq, %48, %31 : i64 loc(#loc1)
          %50 = scf.if %49 -> (i64) {
            %54 = llvm.call tail @strlen(%46) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            scf.yield %54 : i64 loc(#loc1)
          } else {
            %54 = llvm.ptrtoint %47 : !llvm.ptr to i64 loc(#loc1)
            %55 = llvm.ptrtoint %46 : !llvm.ptr to i64 loc(#loc1)
            %56 = arith.subi %54, %55 : i64 loc(#loc1)
            scf.yield %56 : i64 loc(#loc1)
          } loc(#loc1)
          %51 = arith.andi %50, %c4294967295_i64 : i64 loc(#loc1)
          %52 = arith.cmpi eq, %51, %c1_i64 : i64 loc(#loc1)
          %53 = scf.if %52 -> (i1) {
            %54 = llvm.call tail @strncasecmp(%46, %3, %c1_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %55 = arith.cmpi eq, %54, %c0_i32 : i32 loc(#loc1)
            %56 = arith.select %55, %true, %arg3 : i1 loc(#loc1)
            scf.yield %56 : i1 loc(#loc1)
          } else {
            scf.yield %arg3 : i1 loc(#loc1)
          } loc(#loc1)
          scf.yield %53 : i1 loc(#loc1)
        } loc(#loc1)
        %33 = arith.xori %32, %true : i1 loc(#loc1)
        %34 = arith.extui %33 : i1 to i32 loc(#loc1)
        scf.yield %34 : i32 loc(#loc1)
      } loc(#loc1)
      %29 = arith.index_castui %28 : i32 to index loc(#loc1)
      %30 = scf.index_switch %29 -> i32 
      case 0 {
        %31 = llvm.call tail @puts(%15) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
        %32 = llvm.call tail @puts(%16) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
        %33 = llvm.call tail @puts(%17) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
        %34 = llvm.call tail @puts(%18) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
        llvm.call tail @exit(%c0_i32) {no_unwind} : (i32) -> () loc(#loc1)
        scf.yield %c0_i32 : i32 loc(#loc1)
      }
      default {
        scf.yield %c1_i32 : i32 loc(#loc1)
      } loc(#loc1)
      scf.yield %30 : i32 loc(#loc1)
    } else {
      scf.yield %c1_i32 : i32 loc(#loc1)
    } loc(#loc1)
    %24 = arith.index_castui %23 : i32 to index loc(#loc1)
    scf.index_switch %24 
    case 0 {
      scf.yield loc(#loc1)
    }
    default {
      %25 = llvm.call tail @_Z14findCudaDeviceiPPKc(%arg0, %arg1) : (i32, !llvm.ptr) -> i32 loc(#loc1)
      llvm.intr.lifetime.start 12, %19 : !llvm.ptr loc(#loc1)
      llvm.store %c320_i32, %19 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : i32, !llvm.ptr loc(#loc1)
      %26 = llvm.getelementptr inbounds %19[4] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
      llvm.store %c320_i32, %26 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : i32, !llvm.ptr loc(#loc1)
      %27 = llvm.getelementptr inbounds %19[8] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
      llvm.store %c1_i32, %27 {alignment = 4 : i64, tbaa = [#tbaa_tag6]} : i32, !llvm.ptr loc(#loc1)
      llvm.intr.lifetime.start 12, %20 : !llvm.ptr loc(#loc1)
      llvm.store %c640_i32, %20 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : i32, !llvm.ptr loc(#loc1)
      %28 = llvm.getelementptr inbounds %20[4] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
      llvm.store %c320_i32, %28 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : i32, !llvm.ptr loc(#loc1)
      %29 = llvm.getelementptr inbounds %20[8] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
      llvm.store %c1_i32, %29 {alignment = 4 : i64, tbaa = [#tbaa_tag6]} : i32, !llvm.ptr loc(#loc1)
      %30:4 = scf.if %22 -> (i32, i32, i32, i32) {
        %32 = arith.extui %arg0 : i32 to i64 loc(#loc1)
        %33 = llvm.ptrtoint %1 : !llvm.ptr to i64 loc(#loc1)
        %34 = scf.for %arg2 = %c1_i64 to %32 step %c1_i64 iter_args(%arg3 = %false) -> (i1)  : i64 {
          %48 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
          %49 = llvm.load %48 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %50 = scf.while (%arg4 = %c0_i64) : (i64) -> i64 {
            %67 = llvm.getelementptr inbounds %49[%arg4] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %68 = llvm.load %67 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
            %69 = arith.cmpi eq, %68, %c45_i8 : i8 loc(#loc1)
            scf.condition(%69) %arg4 : i64 loc(#loc1)
          } do {
          ^bb0(%arg4: i64 loc(unknown)):
            %67 = arith.addi %arg4, %c1_i64 : i64 loc(#loc1)
            scf.yield %67 : i64 loc(#loc1)
          } loc(#loc1)
          %51 = arith.trunci %50 : i64 to i32 loc(#loc1)
          %52 = llvm.call tail @strlen(%49) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
          %53 = arith.trunci %52 : i64 to i32 loc(#loc1)
          %54 = arith.addi %53, %c-1_i32 : i32 loc(#loc1)
          %55 = arith.cmpi sgt, %54, %51 : i32 loc(#loc1)
          %56 = arith.shli %50, %c32_i64 : i64 loc(#loc1)
          %57 = arith.shrsi %56, %c32_i64 : i64 loc(#loc1)
          %58 = arith.select %55, %57, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
          %59 = llvm.getelementptr inbounds %49[%58] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
          %60 = llvm.call tail @strchr(%59, %c61_i32) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr, i32) -> !llvm.ptr loc(#loc1)
          %61 = llvm.ptrtoint %60 : !llvm.ptr to i64 loc(#loc1)
          %62 = arith.cmpi eq, %61, %33 : i64 loc(#loc1)
          %63 = scf.if %62 -> (i64) {
            %67 = llvm.call tail @strlen(%59) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            scf.yield %67 : i64 loc(#loc1)
          } else {
            %67 = llvm.ptrtoint %60 : !llvm.ptr to i64 loc(#loc1)
            %68 = llvm.ptrtoint %59 : !llvm.ptr to i64 loc(#loc1)
            %69 = arith.subi %67, %68 : i64 loc(#loc1)
            scf.yield %69 : i64 loc(#loc1)
          } loc(#loc1)
          %64 = arith.andi %63, %c4294967295_i64 : i64 loc(#loc1)
          %65 = arith.cmpi eq, %64, %c2_i64 : i64 loc(#loc1)
          %66 = scf.if %65 -> (i1) {
            %67 = llvm.call tail @strncasecmp(%59, %4, %c2_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %68 = arith.cmpi eq, %67, %c0_i32 : i32 loc(#loc1)
            %69 = arith.select %68, %true, %arg3 : i1 loc(#loc1)
            scf.yield %69 : i1 loc(#loc1)
          } else {
            scf.yield %arg3 : i1 loc(#loc1)
          } loc(#loc1)
          scf.yield %66 : i1 loc(#loc1)
        } loc(#loc1)
        %35 = scf.if %34 -> (i32) {
          %48:2 = scf.for %arg2 = %c1_i64 to %32 step %c1_i64 iter_args(%arg3 = %c-1_i32, %arg4 = %false) -> (i32, i1)  : i64 {
            %50 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
            %51 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
            %52 = scf.while (%arg5 = %c0_i64) : (i64) -> i64 {
              %66 = llvm.getelementptr inbounds %51[%arg5] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
              %67 = llvm.load %66 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
              %68 = arith.cmpi eq, %67, %c45_i8 : i8 loc(#loc1)
              scf.condition(%68) %arg5 : i64 loc(#loc1)
            } do {
            ^bb0(%arg5: i64 loc(unknown)):
              %66 = arith.addi %arg5, %c1_i64 : i64 loc(#loc1)
              scf.yield %66 : i64 loc(#loc1)
            } loc(#loc1)
            %53 = arith.trunci %52 : i64 to i32 loc(#loc1)
            %54 = llvm.call tail @strlen(%51) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            %55 = arith.trunci %54 : i64 to i32 loc(#loc1)
            %56 = arith.addi %55, %c-1_i32 : i32 loc(#loc1)
            %57 = arith.cmpi sgt, %56, %53 : i32 loc(#loc1)
            %58 = arith.shli %52, %c32_i64 : i64 loc(#loc1)
            %59 = arith.shrsi %58, %c32_i64 : i64 loc(#loc1)
            %60 = arith.select %57, %59, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
            %61 = llvm.getelementptr inbounds %51[%60] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %62 = llvm.call tail @strncasecmp(%61, %4, %c2_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %63 = arith.cmpi eq, %62, %c0_i32 : i32 loc(#loc1)
            %64 = arith.select %63, %true, %arg4 : i1 loc(#loc1)
            %65 = scf.if %63 -> (i32) {
              %66 = llvm.call tail @strlen(%61) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
              %67 = arith.trunci %66 : i64 to i32 loc(#loc1)
              %68 = arith.cmpi sgt, %67, %c2_i32 : i32 loc(#loc1)
              %69 = scf.if %68 -> (i32) {
                %70 = llvm.getelementptr inbounds %61[2] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
                %71 = llvm.load %70 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
                %72 = arith.cmpi eq, %71, %c61_i8 : i8 loc(#loc1)
                %73 = arith.select %72, %c3_i64, %c2_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
                %74 = llvm.getelementptr inbounds %61[%73] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
                %75 = llvm.call tail @__isoc23_strtol(%74, %1, %c10_i32) {no_unwind} : (!llvm.ptr, !llvm.ptr, i32) -> i64 loc(#loc1)
                %76 = arith.trunci %75 : i64 to i32 loc(#loc1)
                scf.yield %76 : i32 loc(#loc1)
              } else {
                scf.yield %c0_i32 : i32 loc(#loc1)
              } loc(#loc1)
              scf.yield %69 : i32 loc(#loc1)
            } else {
              scf.yield %arg3 : i32 loc(#loc1)
            } loc(#loc1)
            scf.yield %65, %64 : i32, i1 loc(#loc1)
          } loc(#loc1)
          %49 = arith.select %48#1, %48#0, %c0_i32 {fastmathFlags = #llvm.fastmath<none>} : i32 loc(#loc1)
          llvm.store %49, %19 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : i32, !llvm.ptr loc(#loc1)
          scf.yield %49 : i32 loc(#loc1)
        } else {
          scf.yield %c320_i32 : i32 loc(#loc1)
        } loc(#loc1)
        %36 = llvm.ptrtoint %1 : !llvm.ptr to i64 loc(#loc1)
        %37 = scf.for %arg2 = %c1_i64 to %32 step %c1_i64 iter_args(%arg3 = %false) -> (i1)  : i64 {
          %48 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
          %49 = llvm.load %48 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %50 = scf.while (%arg4 = %c0_i64) : (i64) -> i64 {
            %67 = llvm.getelementptr inbounds %49[%arg4] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %68 = llvm.load %67 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
            %69 = arith.cmpi eq, %68, %c45_i8 : i8 loc(#loc1)
            scf.condition(%69) %arg4 : i64 loc(#loc1)
          } do {
          ^bb0(%arg4: i64 loc(unknown)):
            %67 = arith.addi %arg4, %c1_i64 : i64 loc(#loc1)
            scf.yield %67 : i64 loc(#loc1)
          } loc(#loc1)
          %51 = arith.trunci %50 : i64 to i32 loc(#loc1)
          %52 = llvm.call tail @strlen(%49) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
          %53 = arith.trunci %52 : i64 to i32 loc(#loc1)
          %54 = arith.addi %53, %c-1_i32 : i32 loc(#loc1)
          %55 = arith.cmpi sgt, %54, %51 : i32 loc(#loc1)
          %56 = arith.shli %50, %c32_i64 : i64 loc(#loc1)
          %57 = arith.shrsi %56, %c32_i64 : i64 loc(#loc1)
          %58 = arith.select %55, %57, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
          %59 = llvm.getelementptr inbounds %49[%58] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
          %60 = llvm.call tail @strchr(%59, %c61_i32) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr, i32) -> !llvm.ptr loc(#loc1)
          %61 = llvm.ptrtoint %60 : !llvm.ptr to i64 loc(#loc1)
          %62 = arith.cmpi eq, %61, %36 : i64 loc(#loc1)
          %63 = scf.if %62 -> (i64) {
            %67 = llvm.call tail @strlen(%59) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            scf.yield %67 : i64 loc(#loc1)
          } else {
            %67 = llvm.ptrtoint %60 : !llvm.ptr to i64 loc(#loc1)
            %68 = llvm.ptrtoint %59 : !llvm.ptr to i64 loc(#loc1)
            %69 = arith.subi %67, %68 : i64 loc(#loc1)
            scf.yield %69 : i64 loc(#loc1)
          } loc(#loc1)
          %64 = arith.andi %63, %c4294967295_i64 : i64 loc(#loc1)
          %65 = arith.cmpi eq, %64, %c2_i64 : i64 loc(#loc1)
          %66 = scf.if %65 -> (i1) {
            %67 = llvm.call tail @strncasecmp(%59, %5, %c2_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %68 = arith.cmpi eq, %67, %c0_i32 : i32 loc(#loc1)
            %69 = arith.select %68, %true, %arg3 : i1 loc(#loc1)
            scf.yield %69 : i1 loc(#loc1)
          } else {
            scf.yield %arg3 : i1 loc(#loc1)
          } loc(#loc1)
          scf.yield %66 : i1 loc(#loc1)
        } loc(#loc1)
        %38 = scf.if %37 -> (i32) {
          %48:2 = scf.for %arg2 = %c1_i64 to %32 step %c1_i64 iter_args(%arg3 = %c-1_i32, %arg4 = %false) -> (i32, i1)  : i64 {
            %50 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
            %51 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
            %52 = scf.while (%arg5 = %c0_i64) : (i64) -> i64 {
              %66 = llvm.getelementptr inbounds %51[%arg5] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
              %67 = llvm.load %66 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
              %68 = arith.cmpi eq, %67, %c45_i8 : i8 loc(#loc1)
              scf.condition(%68) %arg5 : i64 loc(#loc1)
            } do {
            ^bb0(%arg5: i64 loc(unknown)):
              %66 = arith.addi %arg5, %c1_i64 : i64 loc(#loc1)
              scf.yield %66 : i64 loc(#loc1)
            } loc(#loc1)
            %53 = arith.trunci %52 : i64 to i32 loc(#loc1)
            %54 = llvm.call tail @strlen(%51) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            %55 = arith.trunci %54 : i64 to i32 loc(#loc1)
            %56 = arith.addi %55, %c-1_i32 : i32 loc(#loc1)
            %57 = arith.cmpi sgt, %56, %53 : i32 loc(#loc1)
            %58 = arith.shli %52, %c32_i64 : i64 loc(#loc1)
            %59 = arith.shrsi %58, %c32_i64 : i64 loc(#loc1)
            %60 = arith.select %57, %59, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
            %61 = llvm.getelementptr inbounds %51[%60] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %62 = llvm.call tail @strncasecmp(%61, %5, %c2_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %63 = arith.cmpi eq, %62, %c0_i32 : i32 loc(#loc1)
            %64 = arith.select %63, %true, %arg4 : i1 loc(#loc1)
            %65 = scf.if %63 -> (i32) {
              %66 = llvm.call tail @strlen(%61) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
              %67 = arith.trunci %66 : i64 to i32 loc(#loc1)
              %68 = arith.cmpi sgt, %67, %c2_i32 : i32 loc(#loc1)
              %69 = scf.if %68 -> (i32) {
                %70 = llvm.getelementptr inbounds %61[2] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
                %71 = llvm.load %70 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
                %72 = arith.cmpi eq, %71, %c61_i8 : i8 loc(#loc1)
                %73 = arith.select %72, %c3_i64, %c2_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
                %74 = llvm.getelementptr inbounds %61[%73] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
                %75 = llvm.call tail @__isoc23_strtol(%74, %1, %c10_i32) {no_unwind} : (!llvm.ptr, !llvm.ptr, i32) -> i64 loc(#loc1)
                %76 = arith.trunci %75 : i64 to i32 loc(#loc1)
                scf.yield %76 : i32 loc(#loc1)
              } else {
                scf.yield %c0_i32 : i32 loc(#loc1)
              } loc(#loc1)
              scf.yield %69 : i32 loc(#loc1)
            } else {
              scf.yield %arg3 : i32 loc(#loc1)
            } loc(#loc1)
            scf.yield %65, %64 : i32, i1 loc(#loc1)
          } loc(#loc1)
          %49 = arith.select %48#1, %48#0, %c0_i32 {fastmathFlags = #llvm.fastmath<none>} : i32 loc(#loc1)
          llvm.store %49, %26 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : i32, !llvm.ptr loc(#loc1)
          scf.yield %49 : i32 loc(#loc1)
        } else {
          scf.yield %c320_i32 : i32 loc(#loc1)
        } loc(#loc1)
        %39 = llvm.ptrtoint %1 : !llvm.ptr to i64 loc(#loc1)
        %40 = scf.for %arg2 = %c1_i64 to %32 step %c1_i64 iter_args(%arg3 = %false) -> (i1)  : i64 {
          %48 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
          %49 = llvm.load %48 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %50 = scf.while (%arg4 = %c0_i64) : (i64) -> i64 {
            %67 = llvm.getelementptr inbounds %49[%arg4] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %68 = llvm.load %67 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
            %69 = arith.cmpi eq, %68, %c45_i8 : i8 loc(#loc1)
            scf.condition(%69) %arg4 : i64 loc(#loc1)
          } do {
          ^bb0(%arg4: i64 loc(unknown)):
            %67 = arith.addi %arg4, %c1_i64 : i64 loc(#loc1)
            scf.yield %67 : i64 loc(#loc1)
          } loc(#loc1)
          %51 = arith.trunci %50 : i64 to i32 loc(#loc1)
          %52 = llvm.call tail @strlen(%49) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
          %53 = arith.trunci %52 : i64 to i32 loc(#loc1)
          %54 = arith.addi %53, %c-1_i32 : i32 loc(#loc1)
          %55 = arith.cmpi sgt, %54, %51 : i32 loc(#loc1)
          %56 = arith.shli %50, %c32_i64 : i64 loc(#loc1)
          %57 = arith.shrsi %56, %c32_i64 : i64 loc(#loc1)
          %58 = arith.select %55, %57, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
          %59 = llvm.getelementptr inbounds %49[%58] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
          %60 = llvm.call tail @strchr(%59, %c61_i32) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr, i32) -> !llvm.ptr loc(#loc1)
          %61 = llvm.ptrtoint %60 : !llvm.ptr to i64 loc(#loc1)
          %62 = arith.cmpi eq, %61, %39 : i64 loc(#loc1)
          %63 = scf.if %62 -> (i64) {
            %67 = llvm.call tail @strlen(%59) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            scf.yield %67 : i64 loc(#loc1)
          } else {
            %67 = llvm.ptrtoint %60 : !llvm.ptr to i64 loc(#loc1)
            %68 = llvm.ptrtoint %59 : !llvm.ptr to i64 loc(#loc1)
            %69 = arith.subi %67, %68 : i64 loc(#loc1)
            scf.yield %69 : i64 loc(#loc1)
          } loc(#loc1)
          %64 = arith.andi %63, %c4294967295_i64 : i64 loc(#loc1)
          %65 = arith.cmpi eq, %64, %c2_i64 : i64 loc(#loc1)
          %66 = scf.if %65 -> (i1) {
            %67 = llvm.call tail @strncasecmp(%59, %6, %c2_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %68 = arith.cmpi eq, %67, %c0_i32 : i32 loc(#loc1)
            %69 = arith.select %68, %true, %arg3 : i1 loc(#loc1)
            scf.yield %69 : i1 loc(#loc1)
          } else {
            scf.yield %arg3 : i1 loc(#loc1)
          } loc(#loc1)
          scf.yield %66 : i1 loc(#loc1)
        } loc(#loc1)
        %41 = scf.if %40 -> (i32) {
          %48:2 = scf.for %arg2 = %c1_i64 to %32 step %c1_i64 iter_args(%arg3 = %c-1_i32, %arg4 = %false) -> (i32, i1)  : i64 {
            %50 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
            %51 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
            %52 = scf.while (%arg5 = %c0_i64) : (i64) -> i64 {
              %66 = llvm.getelementptr inbounds %51[%arg5] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
              %67 = llvm.load %66 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
              %68 = arith.cmpi eq, %67, %c45_i8 : i8 loc(#loc1)
              scf.condition(%68) %arg5 : i64 loc(#loc1)
            } do {
            ^bb0(%arg5: i64 loc(unknown)):
              %66 = arith.addi %arg5, %c1_i64 : i64 loc(#loc1)
              scf.yield %66 : i64 loc(#loc1)
            } loc(#loc1)
            %53 = arith.trunci %52 : i64 to i32 loc(#loc1)
            %54 = llvm.call tail @strlen(%51) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            %55 = arith.trunci %54 : i64 to i32 loc(#loc1)
            %56 = arith.addi %55, %c-1_i32 : i32 loc(#loc1)
            %57 = arith.cmpi sgt, %56, %53 : i32 loc(#loc1)
            %58 = arith.shli %52, %c32_i64 : i64 loc(#loc1)
            %59 = arith.shrsi %58, %c32_i64 : i64 loc(#loc1)
            %60 = arith.select %57, %59, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
            %61 = llvm.getelementptr inbounds %51[%60] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %62 = llvm.call tail @strncasecmp(%61, %6, %c2_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %63 = arith.cmpi eq, %62, %c0_i32 : i32 loc(#loc1)
            %64 = arith.select %63, %true, %arg4 : i1 loc(#loc1)
            %65 = scf.if %63 -> (i32) {
              %66 = llvm.call tail @strlen(%61) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
              %67 = arith.trunci %66 : i64 to i32 loc(#loc1)
              %68 = arith.cmpi sgt, %67, %c2_i32 : i32 loc(#loc1)
              %69 = scf.if %68 -> (i32) {
                %70 = llvm.getelementptr inbounds %61[2] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
                %71 = llvm.load %70 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
                %72 = arith.cmpi eq, %71, %c61_i8 : i8 loc(#loc1)
                %73 = arith.select %72, %c3_i64, %c2_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
                %74 = llvm.getelementptr inbounds %61[%73] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
                %75 = llvm.call tail @__isoc23_strtol(%74, %1, %c10_i32) {no_unwind} : (!llvm.ptr, !llvm.ptr, i32) -> i64 loc(#loc1)
                %76 = arith.trunci %75 : i64 to i32 loc(#loc1)
                scf.yield %76 : i32 loc(#loc1)
              } else {
                scf.yield %c0_i32 : i32 loc(#loc1)
              } loc(#loc1)
              scf.yield %69 : i32 loc(#loc1)
            } else {
              scf.yield %arg3 : i32 loc(#loc1)
            } loc(#loc1)
            scf.yield %65, %64 : i32, i1 loc(#loc1)
          } loc(#loc1)
          %49 = arith.select %48#1, %48#0, %c0_i32 {fastmathFlags = #llvm.fastmath<none>} : i32 loc(#loc1)
          llvm.store %49, %20 {alignment = 4 : i64, tbaa = [#tbaa_tag4]} : i32, !llvm.ptr loc(#loc1)
          scf.yield %49 : i32 loc(#loc1)
        } else {
          scf.yield %c640_i32 : i32 loc(#loc1)
        } loc(#loc1)
        %42 = llvm.ptrtoint %1 : !llvm.ptr to i64 loc(#loc1)
        %43 = scf.for %arg2 = %c1_i64 to %32 step %c1_i64 iter_args(%arg3 = %false) -> (i1)  : i64 {
          %48 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
          %49 = llvm.load %48 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %50 = scf.while (%arg4 = %c0_i64) : (i64) -> i64 {
            %67 = llvm.getelementptr inbounds %49[%arg4] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %68 = llvm.load %67 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
            %69 = arith.cmpi eq, %68, %c45_i8 : i8 loc(#loc1)
            scf.condition(%69) %arg4 : i64 loc(#loc1)
          } do {
          ^bb0(%arg4: i64 loc(unknown)):
            %67 = arith.addi %arg4, %c1_i64 : i64 loc(#loc1)
            scf.yield %67 : i64 loc(#loc1)
          } loc(#loc1)
          %51 = arith.trunci %50 : i64 to i32 loc(#loc1)
          %52 = llvm.call tail @strlen(%49) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
          %53 = arith.trunci %52 : i64 to i32 loc(#loc1)
          %54 = arith.addi %53, %c-1_i32 : i32 loc(#loc1)
          %55 = arith.cmpi sgt, %54, %51 : i32 loc(#loc1)
          %56 = arith.shli %50, %c32_i64 : i64 loc(#loc1)
          %57 = arith.shrsi %56, %c32_i64 : i64 loc(#loc1)
          %58 = arith.select %55, %57, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
          %59 = llvm.getelementptr inbounds %49[%58] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
          %60 = llvm.call tail @strchr(%59, %c61_i32) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr, i32) -> !llvm.ptr loc(#loc1)
          %61 = llvm.ptrtoint %60 : !llvm.ptr to i64 loc(#loc1)
          %62 = arith.cmpi eq, %61, %42 : i64 loc(#loc1)
          %63 = scf.if %62 -> (i64) {
            %67 = llvm.call tail @strlen(%59) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            scf.yield %67 : i64 loc(#loc1)
          } else {
            %67 = llvm.ptrtoint %60 : !llvm.ptr to i64 loc(#loc1)
            %68 = llvm.ptrtoint %59 : !llvm.ptr to i64 loc(#loc1)
            %69 = arith.subi %67, %68 : i64 loc(#loc1)
            scf.yield %69 : i64 loc(#loc1)
          } loc(#loc1)
          %64 = arith.andi %63, %c4294967295_i64 : i64 loc(#loc1)
          %65 = arith.cmpi eq, %64, %c2_i64 : i64 loc(#loc1)
          %66 = scf.if %65 -> (i1) {
            %67 = llvm.call tail @strncasecmp(%59, %7, %c2_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %68 = arith.cmpi eq, %67, %c0_i32 : i32 loc(#loc1)
            %69 = arith.select %68, %true, %arg3 : i1 loc(#loc1)
            scf.yield %69 : i1 loc(#loc1)
          } else {
            scf.yield %arg3 : i1 loc(#loc1)
          } loc(#loc1)
          scf.yield %66 : i1 loc(#loc1)
        } loc(#loc1)
        %44 = scf.if %43 -> (i32) {
          %48:2 = scf.for %arg2 = %c1_i64 to %32 step %c1_i64 iter_args(%arg3 = %c-1_i32, %arg4 = %false) -> (i32, i1)  : i64 {
            %50 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
            %51 = llvm.load %50 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
            %52 = scf.while (%arg5 = %c0_i64) : (i64) -> i64 {
              %66 = llvm.getelementptr inbounds %51[%arg5] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
              %67 = llvm.load %66 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
              %68 = arith.cmpi eq, %67, %c45_i8 : i8 loc(#loc1)
              scf.condition(%68) %arg5 : i64 loc(#loc1)
            } do {
            ^bb0(%arg5: i64 loc(unknown)):
              %66 = arith.addi %arg5, %c1_i64 : i64 loc(#loc1)
              scf.yield %66 : i64 loc(#loc1)
            } loc(#loc1)
            %53 = arith.trunci %52 : i64 to i32 loc(#loc1)
            %54 = llvm.call tail @strlen(%51) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            %55 = arith.trunci %54 : i64 to i32 loc(#loc1)
            %56 = arith.addi %55, %c-1_i32 : i32 loc(#loc1)
            %57 = arith.cmpi sgt, %56, %53 : i32 loc(#loc1)
            %58 = arith.shli %52, %c32_i64 : i64 loc(#loc1)
            %59 = arith.shrsi %58, %c32_i64 : i64 loc(#loc1)
            %60 = arith.select %57, %59, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
            %61 = llvm.getelementptr inbounds %51[%60] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %62 = llvm.call tail @strncasecmp(%61, %7, %c2_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
            %63 = arith.cmpi eq, %62, %c0_i32 : i32 loc(#loc1)
            %64 = arith.select %63, %true, %arg4 : i1 loc(#loc1)
            %65 = scf.if %63 -> (i32) {
              %66 = llvm.call tail @strlen(%61) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
              %67 = arith.trunci %66 : i64 to i32 loc(#loc1)
              %68 = arith.cmpi sgt, %67, %c2_i32 : i32 loc(#loc1)
              %69 = scf.if %68 -> (i32) {
                %70 = llvm.getelementptr inbounds %61[2] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
                %71 = llvm.load %70 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
                %72 = arith.cmpi eq, %71, %c61_i8 : i8 loc(#loc1)
                %73 = arith.select %72, %c3_i64, %c2_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
                %74 = llvm.getelementptr inbounds %61[%73] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
                %75 = llvm.call tail @__isoc23_strtol(%74, %1, %c10_i32) {no_unwind} : (!llvm.ptr, !llvm.ptr, i32) -> i64 loc(#loc1)
                %76 = arith.trunci %75 : i64 to i32 loc(#loc1)
                scf.yield %76 : i32 loc(#loc1)
              } else {
                scf.yield %c0_i32 : i32 loc(#loc1)
              } loc(#loc1)
              scf.yield %69 : i32 loc(#loc1)
            } else {
              scf.yield %arg3 : i32 loc(#loc1)
            } loc(#loc1)
            scf.yield %65, %64 : i32, i1 loc(#loc1)
          } loc(#loc1)
          %49 = arith.select %48#1, %48#0, %c0_i32 {fastmathFlags = #llvm.fastmath<none>} : i32 loc(#loc1)
          llvm.store %49, %28 {alignment = 4 : i64, tbaa = [#tbaa_tag5]} : i32, !llvm.ptr loc(#loc1)
          scf.yield %49 : i32 loc(#loc1)
        } else {
          scf.yield %c320_i32 : i32 loc(#loc1)
        } loc(#loc1)
        %45 = arith.cmpi eq, %35, %44 : i32 loc(#loc1)
        %46 = arith.cmpi ne, %35, %44 : i32 loc(#loc1)
        %47 = arith.extui %46 : i1 to i32 loc(#loc1)
        scf.if %45 {
        } else {
          %48 = llvm.call tail @printf(%8, %35, %44) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
          llvm.call tail @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
        } loc(#loc1)
        scf.yield %44, %38, %41, %47 : i32, i32, i32, i32 loc(#loc1)
      } else {
        scf.yield %c320_i32, %c320_i32, %c640_i32, %c0_i32 : i32, i32, i32, i32 loc(#loc1)
      } loc(#loc1)
      %31 = arith.index_castui %30#3 : i32 to index loc(#loc1)
      scf.index_switch %31 
      case 0 {
        %32 = llvm.call tail @printf(%9, %30#0, %30#1, %30#2, %30#0) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, i32, i32, i32, i32) -> i32 loc(#loc1)
        %33 = llvm.call tail @cudaProfilerStart() : () -> i32 loc(#loc1)
        llvm.call tail @_Z5checkI9cudaErrorEvT_PKcS3_i(%33, %10, %11, %c348_i32) : (i32, !llvm.ptr, !llvm.ptr, i32) -> () loc(#loc1)
        %34 = llvm.call @_Z14MatrixMultiplyiPPciRK4dim3S3_(%12, %13, %c32_i32, %19, %20) : (i32, !llvm.ptr, i32, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
        %35 = llvm.call tail @cudaProfilerStop() : () -> i32 loc(#loc1)
        llvm.call tail @_Z5checkI9cudaErrorEvT_PKcS3_i(%35, %14, %11, %c350_i32) : (i32, !llvm.ptr, !llvm.ptr, i32) -> () loc(#loc1)
        llvm.call tail @exit(%34) {no_unwind} : (i32) -> () loc(#loc1)
        scf.yield loc(#loc1)
      }
      default {
      } loc(#loc1)
    } loc(#loc1)
    llvm.unreachable loc(#loc1)
  } loc(#loc1)
  llvm.func linkonce_odr local_unnamed_addr @_Z14findCudaDeviceiPPKc(%arg0: i32 {llvm.noundef} loc(unknown), %arg1: !llvm.ptr {llvm.noundef} loc(unknown)) -> (i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z14findCudaDeviceiPPKc) attributes {passthrough = ["inlinehint", "mustprogress", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %0 = ub.poison : !llvm.ptr loc(#loc1)
    %c2_i32 = arith.constant 2 : i32 loc(#loc1)
    %1 = ub.poison : i32 loc(#loc1)
    %2 = ub.poison : i64 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %3 = llvm.mlir.addressof @".str.53" : !llvm.ptr loc(#loc1)
    %4 = llvm.mlir.addressof @str.98 : !llvm.ptr loc(#loc1)
    %c10_i32 = arith.constant 10 : i32 loc(#loc1)
    %c61_i8 = arith.constant 61 : i8 loc(#loc1)
    %c7_i32 = arith.constant 7 : i32 loc(#loc1)
    %c7_i64 = arith.constant 7 : i64 loc(#loc1)
    %5 = llvm.mlir.addressof @".str.52" : !llvm.ptr loc(#loc1)
    %6 = llvm.mlir.addressof @".str.59" : !llvm.ptr loc(#loc1)
    %7 = llvm.mlir.addressof @".str.87" : !llvm.ptr loc(#loc1)
    %c8_i64 = arith.constant 8 : i64 loc(#loc1)
    %8 = llvm.mlir.addressof @__const._Z22_ConvertSMVer2ArchNameii.nGpuArchNameSM : !llvm.ptr loc(#loc1)
    %9 = llvm.mlir.addressof @".str.85" : !llvm.ptr loc(#loc1)
    %c1_i64 = arith.constant 1 : i64 loc(#loc1)
    %false = arith.constant false loc(#loc1)
    %c0_i64 = arith.constant 0 : i64 loc(#loc1)
    %c45_i8 = arith.constant 45 : i8 loc(#loc1)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %c32_i64 = arith.constant 32 : i64 loc(#loc1)
    %c61_i32 = arith.constant 61 : i32 loc(#loc1)
    %10 = llvm.mlir.zero : !llvm.ptr loc(#loc1)
    %c4294967295_i64 = arith.constant 4294967295 : i64 loc(#loc1)
    %c6_i64 = arith.constant 6 : i64 loc(#loc1)
    %11 = llvm.mlir.addressof @".str.51" : !llvm.ptr loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %12 = llvm.mlir.addressof @stderr : !llvm.ptr loc(#loc1)
    %13 = llvm.mlir.addressof @".str.88" : !llvm.ptr loc(#loc1)
    %14 = llvm.mlir.addressof @".str.56" : !llvm.ptr loc(#loc1)
    %c888_i32 = arith.constant 888 : i32 loc(#loc1)
    %15 = llvm.mlir.addressof @".str.55" : !llvm.ptr loc(#loc1)
    %c75_i32 = arith.constant 75 : i32 loc(#loc1)
    %c890_i32 = arith.constant 890 : i32 loc(#loc1)
    %16 = llvm.mlir.addressof @".str.57" : !llvm.ptr loc(#loc1)
    %c76_i32 = arith.constant 76 : i32 loc(#loc1)
    %c891_i32 = arith.constant 891 : i32 loc(#loc1)
    %17 = llvm.mlir.addressof @".str.58" : !llvm.ptr loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c18_i64 = arith.constant 18 : i64 loc(#loc1)
    %18 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %19 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %20 = arith.cmpi sgt, %arg0, %c0_i32 : i32 loc(#loc1)
    %21:2 = scf.if %20 -> (i32, i32) {
      %25 = arith.extui %arg0 : i32 to i64 loc(#loc1)
      %26 = llvm.ptrtoint %10 : !llvm.ptr to i64 loc(#loc1)
      %27 = scf.for %arg2 = %c1_i64 to %25 step %c1_i64 iter_args(%arg3 = %false) -> (i1)  : i64 {
        %29 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
        %30 = llvm.load %29 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
        %31 = scf.while (%arg4 = %c0_i64) : (i64) -> i64 {
          %48 = llvm.getelementptr inbounds %30[%arg4] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
          %49 = llvm.load %48 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
          %50 = arith.cmpi eq, %49, %c45_i8 : i8 loc(#loc1)
          scf.condition(%50) %arg4 : i64 loc(#loc1)
        } do {
        ^bb0(%arg4: i64 loc(unknown)):
          %48 = arith.addi %arg4, %c1_i64 : i64 loc(#loc1)
          scf.yield %48 : i64 loc(#loc1)
        } loc(#loc1)
        %32 = arith.trunci %31 : i64 to i32 loc(#loc1)
        %33 = llvm.call tail @strlen(%30) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
        %34 = arith.trunci %33 : i64 to i32 loc(#loc1)
        %35 = arith.addi %34, %c-1_i32 : i32 loc(#loc1)
        %36 = arith.cmpi sgt, %35, %32 : i32 loc(#loc1)
        %37 = arith.shli %31, %c32_i64 : i64 loc(#loc1)
        %38 = arith.shrsi %37, %c32_i64 : i64 loc(#loc1)
        %39 = arith.select %36, %38, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
        %40 = llvm.getelementptr inbounds %30[%39] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
        %41 = llvm.call tail @strchr(%40, %c61_i32) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr, i32) -> !llvm.ptr loc(#loc1)
        %42 = llvm.ptrtoint %41 : !llvm.ptr to i64 loc(#loc1)
        %43 = arith.cmpi eq, %42, %26 : i64 loc(#loc1)
        %44 = scf.if %43 -> (i64) {
          %48 = llvm.call tail @strlen(%40) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
          scf.yield %48 : i64 loc(#loc1)
        } else {
          %48 = llvm.ptrtoint %41 : !llvm.ptr to i64 loc(#loc1)
          %49 = llvm.ptrtoint %40 : !llvm.ptr to i64 loc(#loc1)
          %50 = arith.subi %48, %49 : i64 loc(#loc1)
          scf.yield %50 : i64 loc(#loc1)
        } loc(#loc1)
        %45 = arith.andi %44, %c4294967295_i64 : i64 loc(#loc1)
        %46 = arith.cmpi eq, %45, %c6_i64 : i64 loc(#loc1)
        %47 = scf.if %46 -> (i1) {
          %48 = llvm.call tail @strncasecmp(%40, %11, %c6_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
          %49 = arith.cmpi eq, %48, %c0_i32 : i32 loc(#loc1)
          %50 = arith.select %49, %true, %arg3 : i1 loc(#loc1)
          scf.yield %50 : i1 loc(#loc1)
        } else {
          scf.yield %arg3 : i1 loc(#loc1)
        } loc(#loc1)
        scf.yield %47 : i1 loc(#loc1)
      } loc(#loc1)
      %28:2 = scf.if %27 -> (i32, i32) {
        %29:2 = scf.for %arg2 = %c1_i64 to %25 step %c1_i64 iter_args(%arg3 = %c-1_i32, %arg4 = %false) -> (i32, i1)  : i64 {
          %34 = llvm.getelementptr inbounds %arg1[%arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.ptr loc(#loc1)
          %35 = llvm.load %34 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %36 = scf.while (%arg5 = %c0_i64) : (i64) -> i64 {
            %50 = llvm.getelementptr inbounds %35[%arg5] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
            %51 = llvm.load %50 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
            %52 = arith.cmpi eq, %51, %c45_i8 : i8 loc(#loc1)
            scf.condition(%52) %arg5 : i64 loc(#loc1)
          } do {
          ^bb0(%arg5: i64 loc(unknown)):
            %50 = arith.addi %arg5, %c1_i64 : i64 loc(#loc1)
            scf.yield %50 : i64 loc(#loc1)
          } loc(#loc1)
          %37 = arith.trunci %36 : i64 to i32 loc(#loc1)
          %38 = llvm.call tail @strlen(%35) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
          %39 = arith.trunci %38 : i64 to i32 loc(#loc1)
          %40 = arith.addi %39, %c-1_i32 : i32 loc(#loc1)
          %41 = arith.cmpi sgt, %40, %37 : i32 loc(#loc1)
          %42 = arith.shli %36, %c32_i64 : i64 loc(#loc1)
          %43 = arith.shrsi %42, %c32_i64 : i64 loc(#loc1)
          %44 = arith.select %41, %43, %c0_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
          %45 = llvm.getelementptr inbounds %35[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
          %46 = llvm.call tail @strncasecmp(%45, %5, %c7_i64) {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, will_return} : (!llvm.ptr, !llvm.ptr, i64) -> i32 loc(#loc1)
          %47 = arith.cmpi eq, %46, %c0_i32 : i32 loc(#loc1)
          %48 = arith.select %47, %true, %arg4 : i1 loc(#loc1)
          %49 = scf.if %47 -> (i32) {
            %50 = llvm.call tail @strlen(%45) {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, will_return} : (!llvm.ptr) -> i64 loc(#loc1)
            %51 = arith.trunci %50 : i64 to i32 loc(#loc1)
            %52 = arith.cmpi sgt, %51, %c7_i32 : i32 loc(#loc1)
            %53 = scf.if %52 -> (i32) {
              %54 = llvm.getelementptr inbounds %45[7] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
              %55 = llvm.load %54 {alignment = 1 : i64, tbaa = [#tbaa_tag]} : !llvm.ptr -> i8 loc(#loc1)
              %56 = arith.cmpi eq, %55, %c61_i8 : i8 loc(#loc1)
              %57 = arith.select %56, %c8_i64, %c7_i64 {fastmathFlags = #llvm.fastmath<none>} : i64 loc(#loc1)
              %58 = llvm.getelementptr inbounds %45[%57] : (!llvm.ptr, i64) -> !llvm.ptr, i8 loc(#loc1)
              %59 = llvm.call tail @__isoc23_strtol(%58, %10, %c10_i32) {no_unwind} : (!llvm.ptr, !llvm.ptr, i32) -> i64 loc(#loc1)
              %60 = arith.trunci %59 : i64 to i32 loc(#loc1)
              scf.yield %60 : i32 loc(#loc1)
            } else {
              scf.yield %c0_i32 : i32 loc(#loc1)
            } loc(#loc1)
            scf.yield %53 : i32 loc(#loc1)
          } else {
            scf.yield %arg3 : i32 loc(#loc1)
          } loc(#loc1)
          scf.yield %49, %48 : i32, i1 loc(#loc1)
        } loc(#loc1)
        %30 = arith.select %29#1, %29#0, %c0_i32 : i32 loc(#loc1)
        %31 = scf.if %29#1 -> (i32) {
          %34 = arith.cmpi slt, %29#0, %c0_i32 : i32 loc(#loc1)
          %35 = arith.extui %34 : i1 to i32 loc(#loc1)
          scf.if %34 {
            %36 = llvm.call tail @printf(%3) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
            llvm.call tail @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
          } loc(#loc1)
          scf.yield %35 : i32 loc(#loc1)
        } else {
          scf.yield %c0_i32 : i32 loc(#loc1)
        } loc(#loc1)
        %32 = arith.index_castui %31 : i32 to index loc(#loc1)
        %33:2 = scf.index_switch %32 -> i32, i32 
        case 0 {
          %34 = llvm.call tail @_Z13gpuDeviceIniti(%30) : (i32) -> i32 loc(#loc1)
          %35 = arith.cmpi slt, %34, %c0_i32 : i32 loc(#loc1)
          %36 = arith.select %35, %c1_i32, %c2_i32 : i32 loc(#loc1)
          scf.if %35 {
            %37 = llvm.call tail @puts(%4) {no_unwind} : (!llvm.ptr) -> i32 loc(#loc1)
            llvm.call tail @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
          } loc(#loc1)
          scf.yield %34, %36 : i32, i32 loc(#loc1)
        }
        default {
          scf.yield %1, %c1_i32 : i32, i32 loc(#loc1)
        } loc(#loc1)
        scf.yield %33#0, %33#1 : i32, i32 loc(#loc1)
      } else {
        scf.yield %1, %c0_i32 : i32, i32 loc(#loc1)
      } loc(#loc1)
      scf.yield %28#0, %28#1 : i32, i32 loc(#loc1)
    } else {
      scf.yield %1, %c0_i32 : i32, i32 loc(#loc1)
    } loc(#loc1)
    %22 = arith.index_castui %21#1 : i32 to index loc(#loc1)
    %23:2 = scf.index_switch %22 -> i32, i32 
    case 0 {
      %25 = llvm.call tail @_Z23gpuGetMaxGflopsDeviceIdv() : () -> i32 loc(#loc1)
      %26 = llvm.call tail @cudaSetDevice(%25) : (i32) -> i32 loc(#loc1)
      %27 = arith.cmpi eq, %26, %c0_i32 : i32 loc(#loc1)
      %28:2 = scf.if %27 -> (i32, i32) {
        llvm.intr.lifetime.start 4, %18 : !llvm.ptr loc(#loc1)
        llvm.store %c0_i32, %18 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
        llvm.intr.lifetime.start 4, %19 : !llvm.ptr loc(#loc1)
        llvm.store %c0_i32, %19 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
        %29 = llvm.call @cudaDeviceGetAttribute(%18, %c75_i32, %25) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
        %30 = arith.cmpi eq, %29, %c0_i32 : i32 loc(#loc1)
        %31 = arith.select %30, %c891_i32, %c890_i32 : i32 loc(#loc1)
        %32 = arith.select %30, %17, %16 : !llvm.ptr loc(#loc1)
        %33:3 = scf.if %30 -> (i32, i32, i32) {
          %36 = llvm.call @cudaDeviceGetAttribute(%19, %c76_i32, %25) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
          %37 = arith.cmpi eq, %36, %c0_i32 : i32 loc(#loc1)
          %38 = arith.extui %37 : i1 to i32 loc(#loc1)
          scf.if %37 {
            %39 = llvm.load %18 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
            %40 = llvm.load %19 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
            %41 = arith.shli %39, %c4_i32 : i32 loc(#loc1)
            %42 = arith.addi %41, %40 : i32 loc(#loc1)
            %43:3 = scf.while (%arg2 = %c0_i64) : (i64) -> (i64, !llvm.ptr, i32) {
              %47 = arith.cmpi eq, %arg2, %c18_i64 : i64 loc(#loc1)
              %48:4 = scf.if %47 -> (i64, i32, i32, !llvm.ptr) {
                scf.yield %2, %c2_i32, %c0_i32, %0 : i64, i32, i32, !llvm.ptr loc(#loc1)
              } else {
                %50 = llvm.getelementptr inbounds %8[0, %arg2] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>> loc(#loc1)
                %51 = llvm.load %50 {alignment = 16 : i64, tbaa = [#tbaa_tag7]} : !llvm.ptr -> i32 loc(#loc1)
                %52 = arith.cmpi eq, %51, %42 : i32 loc(#loc1)
                %53 = arith.extui %52 : i1 to i32 loc(#loc1)
                %54 = arith.cmpi ne, %51, %42 : i32 loc(#loc1)
                %55 = arith.extui %54 : i1 to i32 loc(#loc1)
                %56 = scf.if %52 -> (i64) {
                  scf.yield %2 : i64 loc(#loc1)
                } else {
                  %57 = arith.addi %arg2, %c1_i64 : i64 loc(#loc1)
                  scf.yield %57 : i64 loc(#loc1)
                } loc(#loc1)
                scf.yield %56, %53, %55, %50 : i64, i32, i32, !llvm.ptr loc(#loc1)
              } loc(#loc1)
              %49 = arith.trunci %48#2 : i32 to i1 loc(#loc1)
              scf.condition(%49) %48#0, %48#3, %48#1 : i64, !llvm.ptr, i32 loc(#loc1)
            } do {
            ^bb0(%arg2: i64 loc(unknown), %arg3: !llvm.ptr loc(unknown), %arg4: i32 loc(unknown)):
              scf.yield %arg2 : i64 loc(#loc1)
            } loc(#loc1)
            %44 = arith.index_castui %43#2 : i32 to index loc(#loc1)
            %45:3 = scf.index_switch %44 -> i32, i32, !llvm.ptr 
            case 1 {
              %47 = llvm.getelementptr inbounds %43#1[8] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
              %48 = llvm.load %47 {alignment = 8 : i64, tbaa = [#tbaa_tag8]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
              scf.yield %40, %39, %48 : i32, i32, !llvm.ptr loc(#loc1)
            }
            default {
              %47 = llvm.call @printf(%7, %39, %40, %9) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, i32, i32, !llvm.ptr) -> i32 loc(#loc1)
              %48 = llvm.load %18 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
              %49 = llvm.load %19 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
              scf.yield %49, %48, %9 : i32, i32, !llvm.ptr loc(#loc1)
            } loc(#loc1)
            %46 = llvm.call @printf(%6, %25, %45#2, %45#1, %45#0) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, i32, !llvm.ptr, i32, i32) -> i32 loc(#loc1)
            llvm.intr.lifetime.end 4, %19 : !llvm.ptr loc(#loc1)
            llvm.intr.lifetime.end 4, %18 : !llvm.ptr loc(#loc1)
          } loc(#loc1)
          scf.yield %36, %36, %38 : i32, i32, i32 loc(#loc1)
        } else {
          scf.yield %29, %29, %c0_i32 : i32, i32, i32 loc(#loc1)
        } loc(#loc1)
        %34 = arith.index_castui %33#2 : i32 to index loc(#loc1)
        %35:2 = scf.index_switch %34 -> i32, i32 
        case 0 {
          %36 = llvm.load %12 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %37 = llvm.call fastcc @_ZL17_cudaGetErrorEnum9cudaError(%33#0) : (i32) -> !llvm.ptr loc(#loc1)
          %38 = llvm.call @fprintf(%36, %13, %14, %31, %33#1, %37, %32) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
          llvm.call @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
          scf.yield %1, %c1_i32 : i32, i32 loc(#loc1)
        }
        default {
          scf.yield %25, %c0_i32 : i32, i32 loc(#loc1)
        } loc(#loc1)
        scf.yield %35#0, %35#1 : i32, i32 loc(#loc1)
      } else {
        %29 = llvm.load %12 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
        %30 = llvm.call fastcc tail @_ZL17_cudaGetErrorEnum9cudaError(%26) : (i32) -> !llvm.ptr loc(#loc1)
        %31 = llvm.call tail @fprintf(%29, %13, %14, %c888_i32, %26, %30, %15) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
        llvm.call tail @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
        scf.yield %1, %c1_i32 : i32, i32 loc(#loc1)
      } loc(#loc1)
      scf.yield %28#0, %28#1 : i32, i32 loc(#loc1)
    }
    case 1 {
      scf.yield %1, %c1_i32 : i32, i32 loc(#loc1)
    }
    default {
      scf.yield %21#0, %c0_i32 : i32, i32 loc(#loc1)
    } loc(#loc1)
    cf.switch %23#1 : i32, [
      default: ^bb2,
      0: ^bb1(%23#0 : i32)
    ] loc(#loc1)
  ^bb1(%24: i32 loc(unknown)):  // pred: ^bb0
    llvm.return %24 : i32 loc(#loc1)
  ^bb2:  // pred: ^bb0
    llvm.unreachable loc(#loc1)
  } loc(#loc1)
  llvm.func local_unnamed_addr @cudaProfilerStart() -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaProfilerStop() -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @strchr(!llvm.ptr {llvm.noundef}, i32 {llvm.noundef}) -> (!llvm.ptr {llvm.noundef}) attributes {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, passthrough = ["mustprogress", "nofree", ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic", will_return} loc(#loc1)
  llvm.func local_unnamed_addr @strlen(!llvm.ptr {llvm.nocapture, llvm.noundef}) -> i64 attributes {memory_effects = #llvm.memory_effects<other = none, argMem = read, inaccessibleMem = none>, no_unwind, passthrough = ["mustprogress", "nofree", ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic", will_return} loc(#loc1)
  llvm.func local_unnamed_addr @strncasecmp(!llvm.ptr {llvm.nocapture, llvm.noundef}, !llvm.ptr {llvm.nocapture, llvm.noundef}, i64 {llvm.noundef}) -> i32 attributes {memory_effects = #llvm.memory_effects<other = read, argMem = read, inaccessibleMem = read>, no_unwind, passthrough = ["mustprogress", "nofree", ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic", will_return} loc(#loc1)
  llvm.func linkonce_odr local_unnamed_addr @_Z13gpuDeviceIniti(%arg0: i32 {llvm.noundef} loc(unknown)) -> (i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13gpuDeviceIniti) attributes {passthrough = ["inlinehint", "mustprogress", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %0 = ub.poison : i32 loc(#loc1)
    %1 = ub.poison : !llvm.ptr loc(#loc1)
    %c2_i32 = arith.constant 2 : i32 loc(#loc1)
    %2 = ub.poison : i64 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c56_i64 = arith.constant 56 : i64 loc(#loc1)
    %3 = llvm.mlir.addressof @".str.61" : !llvm.ptr loc(#loc1)
    %c91_i64 = arith.constant 91 : i64 loc(#loc1)
    %4 = llvm.mlir.addressof @".str.66" : !llvm.ptr loc(#loc1)
    %c51_i64 = arith.constant 51 : i64 loc(#loc1)
    %5 = llvm.mlir.addressof @".str.67" : !llvm.ptr loc(#loc1)
    %6 = llvm.mlir.addressof @".str.68" : !llvm.ptr loc(#loc1)
    %7 = llvm.mlir.addressof @".str.87" : !llvm.ptr loc(#loc1)
    %c1_i64 = arith.constant 1 : i64 loc(#loc1)
    %8 = llvm.mlir.addressof @__const._Z22_ConvertSMVer2ArchNameii.nGpuArchNameSM : !llvm.ptr loc(#loc1)
    %9 = llvm.mlir.addressof @".str.85" : !llvm.ptr loc(#loc1)
    %10 = llvm.mlir.addressof @stderr : !llvm.ptr loc(#loc1)
    %11 = llvm.mlir.addressof @".str.88" : !llvm.ptr loc(#loc1)
    %12 = llvm.mlir.addressof @".str.56" : !llvm.ptr loc(#loc1)
    %c746_i32 = arith.constant 746 : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @".str.60" : !llvm.ptr loc(#loc1)
    %c10_i32 = arith.constant 10 : i32 loc(#loc1)
    %14 = llvm.mlir.addressof @".str.63" : !llvm.ptr loc(#loc1)
    %15 = llvm.mlir.addressof @".str.64" : !llvm.ptr loc(#loc1)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %c20_i32 = arith.constant 20 : i32 loc(#loc1)
    %c772_i32 = arith.constant 772 : i32 loc(#loc1)
    %16 = llvm.mlir.addressof @".str.65" : !llvm.ptr loc(#loc1)
    %c75_i32 = arith.constant 75 : i32 loc(#loc1)
    %c773_i32 = arith.constant 773 : i32 loc(#loc1)
    %17 = llvm.mlir.addressof @".str.57" : !llvm.ptr loc(#loc1)
    %c76_i32 = arith.constant 76 : i32 loc(#loc1)
    %c774_i32 = arith.constant 774 : i32 loc(#loc1)
    %18 = llvm.mlir.addressof @".str.58" : !llvm.ptr loc(#loc1)
    %c787_i32 = arith.constant 787 : i32 loc(#loc1)
    %19 = llvm.mlir.addressof @".str.55" : !llvm.ptr loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i64 = arith.constant 0 : i64 loc(#loc1)
    %c18_i64 = arith.constant 18 : i64 loc(#loc1)
    %20 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %21 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %22 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %23 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    llvm.intr.lifetime.start 4, %20 : !llvm.ptr loc(#loc1)
    %24 = llvm.call @cudaGetDeviceCount(%20) : (!llvm.ptr) -> i32 loc(#loc1)
    %25 = arith.cmpi eq, %24, %c0_i32 : i32 loc(#loc1)
    %26:6 = scf.if %25 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
      %30 = llvm.load %20 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
      %31 = arith.cmpi eq, %30, %c0_i32 : i32 loc(#loc1)
      %32:9 = scf.if %31 -> (!llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32) {
        scf.yield %3, %c56_i64, %0, %0, %0, %1, %0, %0, %c0_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
      } else {
        %35 = arith.maxsi %arg0, %c0_i32 : i32 loc(#loc1)
        %36 = arith.cmpi slt, %35, %30 : i32 loc(#loc1)
        %37:11 = scf.if %36 -> (!llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32) {
          llvm.intr.lifetime.start 4, %21 : !llvm.ptr loc(#loc1)
          llvm.store %c-1_i32, %21 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
          llvm.intr.lifetime.start 4, %22 : !llvm.ptr loc(#loc1)
          llvm.store %c0_i32, %22 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
          llvm.intr.lifetime.start 4, %23 : !llvm.ptr loc(#loc1)
          llvm.store %c0_i32, %23 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
          %40 = llvm.call @cudaDeviceGetAttribute(%21, %c20_i32, %35) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
          %41 = arith.cmpi eq, %40, %c0_i32 : i32 loc(#loc1)
          %42:11 = scf.if %41 -> (!llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32) {
            %43 = llvm.call @cudaDeviceGetAttribute(%22, %c75_i32, %35) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
            %44 = arith.cmpi eq, %43, %c0_i32 : i32 loc(#loc1)
            %45:11 = scf.if %44 -> (!llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32) {
              %46 = llvm.call @cudaDeviceGetAttribute(%23, %c76_i32, %35) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
              %47 = arith.cmpi eq, %46, %c0_i32 : i32 loc(#loc1)
              %48:11 = scf.if %47 -> (!llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32) {
                %49 = llvm.load %21 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                %50 = arith.cmpi eq, %49, %c2_i32 : i32 loc(#loc1)
                %51 = arith.select %50, %c-1_i32, %35 : i32 loc(#loc1)
                %52:4 = scf.if %50 -> (i32, i32, i32, i32) {
                  %55 = llvm.load %10 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                  %56 = llvm.call @fwrite(%4, %c91_i64, %c1_i64, %55) {no_unwind} : (!llvm.ptr, i64, i64, !llvm.ptr) -> i64 loc(#loc1)
                  scf.yield %0, %0, %0, %c0_i32 : i32, i32, i32, i32 loc(#loc1)
                } else {
                  %55 = llvm.load %22 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                  %56 = arith.cmpi slt, %55, %c1_i32 : i32 loc(#loc1)
                  %57 = arith.cmpi sge, %55, %c1_i32 : i32 loc(#loc1)
                  %58 = arith.extui %57 : i1 to i32 loc(#loc1)
                  %59:3 = scf.if %56 -> (i32, i32, i32) {
                    scf.yield %0, %0, %c1_i32 : i32, i32, i32 loc(#loc1)
                  } else {
                    %60 = llvm.call @cudaSetDevice(%35) : (i32) -> i32 loc(#loc1)
                    %61 = arith.cmpi eq, %60, %c0_i32 : i32 loc(#loc1)
                    %62 = arith.cmpi ne, %60, %c0_i32 : i32 loc(#loc1)
                    %63 = arith.extui %62 : i1 to i32 loc(#loc1)
                    scf.if %61 {
                      %64 = llvm.load %22 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                      %65 = llvm.load %23 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                      %66 = arith.shli %64, %c4_i32 : i32 loc(#loc1)
                      %67 = arith.addi %66, %65 : i32 loc(#loc1)
                      %68:3 = scf.while (%arg1 = %c0_i64) : (i64) -> (i64, !llvm.ptr, i32) {
                        %72 = arith.cmpi eq, %arg1, %c18_i64 : i64 loc(#loc1)
                        %73:4 = scf.if %72 -> (i64, i32, i32, !llvm.ptr) {
                          scf.yield %2, %c2_i32, %c0_i32, %1 : i64, i32, i32, !llvm.ptr loc(#loc1)
                        } else {
                          %75 = llvm.getelementptr inbounds %8[0, %arg1] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.array<19 x struct<"struct.sSMtoArchName", (i32, ptr)>> loc(#loc1)
                          %76 = llvm.load %75 {alignment = 16 : i64, tbaa = [#tbaa_tag7]} : !llvm.ptr -> i32 loc(#loc1)
                          %77 = arith.cmpi eq, %76, %67 : i32 loc(#loc1)
                          %78 = arith.extui %77 : i1 to i32 loc(#loc1)
                          %79 = arith.cmpi ne, %76, %67 : i32 loc(#loc1)
                          %80 = arith.extui %79 : i1 to i32 loc(#loc1)
                          %81 = scf.if %77 -> (i64) {
                            scf.yield %2 : i64 loc(#loc1)
                          } else {
                            %82 = arith.addi %arg1, %c1_i64 : i64 loc(#loc1)
                            scf.yield %82 : i64 loc(#loc1)
                          } loc(#loc1)
                          scf.yield %81, %78, %80, %75 : i64, i32, i32, !llvm.ptr loc(#loc1)
                        } loc(#loc1)
                        %74 = arith.trunci %73#2 : i32 to i1 loc(#loc1)
                        scf.condition(%74) %73#0, %73#3, %73#1 : i64, !llvm.ptr, i32 loc(#loc1)
                      } do {
                      ^bb0(%arg1: i64 loc(unknown), %arg2: !llvm.ptr loc(unknown), %arg3: i32 loc(unknown)):
                        scf.yield %arg1 : i64 loc(#loc1)
                      } loc(#loc1)
                      %69 = arith.index_castui %68#2 : i32 to index loc(#loc1)
                      %70 = scf.index_switch %69 -> !llvm.ptr 
                      case 1 {
                        %72 = llvm.getelementptr inbounds %68#1[8] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
                        %73 = llvm.load %72 {alignment = 8 : i64, tbaa = [#tbaa_tag8]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
                        scf.yield %73 : !llvm.ptr loc(#loc1)
                      }
                      default {
                        %72 = llvm.call @printf(%7, %64, %65, %9) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, i32, i32, !llvm.ptr) -> i32 loc(#loc1)
                        scf.yield %9 : !llvm.ptr loc(#loc1)
                      } loc(#loc1)
                      %71 = llvm.call @printf(%6, %35, %70) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, i32, !llvm.ptr) -> i32 loc(#loc1)
                    } loc(#loc1)
                    scf.yield %60, %60, %63 : i32, i32, i32 loc(#loc1)
                  } loc(#loc1)
                  scf.yield %59#0, %59#1, %58, %59#2 : i32, i32, i32, i32 loc(#loc1)
                } loc(#loc1)
                %53 = arith.index_castui %52#3 : i32 to index loc(#loc1)
                %54:11 = scf.index_switch %53 -> !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 
                case 0 {
                  llvm.intr.lifetime.end 4, %23 : !llvm.ptr loc(#loc1)
                  llvm.intr.lifetime.end 4, %22 : !llvm.ptr loc(#loc1)
                  llvm.intr.lifetime.end 4, %21 : !llvm.ptr loc(#loc1)
                  scf.yield %1, %2, %0, %0, %0, %1, %0, %0, %0, %51, %c1_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
                }
                default {
                  scf.yield %5, %c51_i64, %52#0, %c787_i32, %52#1, %19, %0, %c1_i32, %52#2, %0, %c0_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
                } loc(#loc1)
                scf.yield %54#0, %54#1, %54#2, %54#3, %54#4, %54#5, %54#6, %54#7, %54#8, %54#9, %54#10 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
              } else {
                scf.yield %1, %2, %46, %c774_i32, %46, %18, %0, %c1_i32, %c1_i32, %0, %c0_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
              } loc(#loc1)
              scf.yield %48#0, %48#1, %48#2, %48#3, %48#4, %48#5, %48#6, %48#7, %48#8, %48#9, %48#10 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
            } else {
              scf.yield %1, %2, %43, %c773_i32, %43, %17, %0, %c1_i32, %c1_i32, %0, %c0_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
            } loc(#loc1)
            scf.yield %45#0, %45#1, %45#2, %45#3, %45#4, %45#5, %45#6, %45#7, %45#8, %45#9, %45#10 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
          } else {
            scf.yield %1, %2, %40, %c772_i32, %40, %16, %0, %c1_i32, %c1_i32, %0, %c0_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
          } loc(#loc1)
          scf.yield %42#0, %42#1, %42#2, %42#3, %42#4, %42#5, %42#6, %42#7, %42#8, %42#9, %42#10 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
        } else {
          %40 = llvm.load %10 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %41 = llvm.call @fputc(%c10_i32, %40) {no_unwind} : (i32, !llvm.ptr) -> i32 loc(#loc1)
          %42 = llvm.load %10 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %43 = llvm.load %20 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
          %44 = llvm.call @fprintf(%42, %14, %43) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, i32) -> i32 loc(#loc1)
          %45 = llvm.load %10 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %46 = llvm.call @fprintf(%45, %15, %35) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, i32) -> i32 loc(#loc1)
          %47 = llvm.load %10 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %48 = llvm.call @fputc(%c10_i32, %47) {no_unwind} : (i32, !llvm.ptr) -> i32 loc(#loc1)
          %49 = arith.subi %c0_i32, %35 : i32 loc(#loc1)
          scf.yield %1, %2, %0, %0, %0, %1, %0, %0, %0, %49, %c1_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32 loc(#loc1)
        } loc(#loc1)
        %38 = arith.index_castui %37#10 : i32 to index loc(#loc1)
        %39:9 = scf.index_switch %38 -> !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 
        case 0 {
          scf.yield %37#0, %37#1, %37#2, %37#3, %37#4, %37#5, %37#6, %37#7, %37#8 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
        }
        default {
          llvm.intr.lifetime.end 4, %20 : !llvm.ptr loc(#loc1)
          scf.yield %1, %2, %0, %0, %0, %1, %37#9, %c2_i32, %c1_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
        } loc(#loc1)
        scf.yield %39#0, %39#1, %39#2, %39#3, %39#4, %39#5, %39#6, %39#7, %39#8 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
      } loc(#loc1)
      %33 = arith.index_castui %32#8 : i32 to index loc(#loc1)
      %34:6 = scf.index_switch %33 -> i32, i32, i32, !llvm.ptr, i32, i32 
      case 0 {
        %35 = llvm.load %10 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
        %36 = llvm.call @fwrite(%32#0, %32#1, %c1_i64, %35) {no_unwind} : (!llvm.ptr, i64, i64, !llvm.ptr) -> i64 loc(#loc1)
        llvm.call @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
        scf.yield %0, %0, %0, %1, %0, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
      }
      default {
        scf.yield %32#2, %32#3, %32#4, %32#5, %32#6, %32#7 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
      } loc(#loc1)
      scf.yield %34#0, %34#1, %34#2, %34#3, %34#4, %34#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
    } else {
      scf.yield %24, %c746_i32, %24, %13, %0, %c1_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
    } loc(#loc1)
    %27 = arith.index_castui %26#5 : i32 to index loc(#loc1)
    %28:2 = scf.index_switch %27 -> i32, i32 
    case 0 {
      scf.yield %0, %c1_i32 : i32, i32 loc(#loc1)
    }
    case 1 {
      %30 = llvm.load %10 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
      %31 = llvm.call fastcc @_ZL17_cudaGetErrorEnum9cudaError(%26#0) : (i32) -> !llvm.ptr loc(#loc1)
      %32 = llvm.call @fprintf(%30, %11, %12, %26#1, %26#2, %31, %26#3) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
      llvm.call @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
      scf.yield %0, %c1_i32 : i32, i32 loc(#loc1)
    }
    default {
      scf.yield %26#4, %c0_i32 : i32, i32 loc(#loc1)
    } loc(#loc1)
    cf.switch %28#1 : i32, [
      default: ^bb1,
      0: ^bb2(%28#0 : i32)
    ] loc(#loc1)
  ^bb1:  // pred: ^bb0
    llvm.unreachable loc(#loc1)
  ^bb2(%29: i32 loc(unknown)):  // pred: ^bb0
    llvm.return %29 : i32 loc(#loc1)
  } loc(#loc1)
  llvm.func linkonce_odr local_unnamed_addr @_Z23gpuGetMaxGflopsDeviceIdv() -> (i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z23gpuGetMaxGflopsDeviceIdv) attributes {passthrough = ["inlinehint", "mustprogress", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc1)
    %c2_i32 = arith.constant 2 : i32 loc(#loc1)
    %0 = ub.poison : i64 loc(#loc1)
    %1 = ub.poison : !llvm.ptr loc(#loc1)
    %2 = ub.poison : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c66_i64 = arith.constant 66 : i64 loc(#loc1)
    %3 = llvm.mlir.addressof @".str.69" : !llvm.ptr loc(#loc1)
    %c838_i32 = arith.constant 838 : i32 loc(#loc1)
    %4 = llvm.mlir.addressof @".str.74" : !llvm.ptr loc(#loc1)
    %c13_i32 = arith.constant 13 : i32 loc(#loc1)
    %5 = llvm.mlir.addressof @".str.73" : !llvm.ptr loc(#loc1)
    %c829_i32 = arith.constant 829 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %6 = llvm.mlir.addressof @".str.76" : !llvm.ptr loc(#loc1)
    %7 = llvm.mlir.addressof @__const._Z19_ConvertSMVer2Coresii.nGpuArchCoresPerSM : !llvm.ptr loc(#loc1)
    %c128_i32 = arith.constant 128 : i32 loc(#loc1)
    %8 = llvm.mlir.addressof @stderr : !llvm.ptr loc(#loc1)
    %9 = llvm.mlir.addressof @".str.88" : !llvm.ptr loc(#loc1)
    %10 = llvm.mlir.addressof @".str.56" : !llvm.ptr loc(#loc1)
    %c801_i32 = arith.constant 801 : i32 loc(#loc1)
    %11 = llvm.mlir.addressof @".str.60" : !llvm.ptr loc(#loc1)
    %c0_i64 = arith.constant 0 : i64 loc(#loc1)
    %12 = llvm.mlir.addressof @".str.75" : !llvm.ptr loc(#loc1)
    %c80_i64 = arith.constant 80 : i64 loc(#loc1)
    %c1_i64 = arith.constant 1 : i64 loc(#loc1)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %c20_i32 = arith.constant 20 : i32 loc(#loc1)
    %c815_i32 = arith.constant 815 : i32 loc(#loc1)
    %13 = llvm.mlir.addressof @".str.70" : !llvm.ptr loc(#loc1)
    %c75_i32 = arith.constant 75 : i32 loc(#loc1)
    %c816_i32 = arith.constant 816 : i32 loc(#loc1)
    %14 = llvm.mlir.addressof @".str.71" : !llvm.ptr loc(#loc1)
    %c76_i32 = arith.constant 76 : i32 loc(#loc1)
    %c817_i32 = arith.constant 817 : i32 loc(#loc1)
    %15 = llvm.mlir.addressof @".str.72" : !llvm.ptr loc(#loc1)
    %c9999_i32 = arith.constant 9999 : i32 loc(#loc1)
    %false = arith.constant false loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c18_i64 = arith.constant 18 : i64 loc(#loc1)
    %16 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %17 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %18 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %19 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %20 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    %21 = llvm.alloca %c1_i32 x i32 {alignment = 4 : i64} : (i32) -> !llvm.ptr loc(#loc1)
    llvm.intr.lifetime.start 4, %16 : !llvm.ptr loc(#loc1)
    llvm.store %c0_i32, %16 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
    %22 = llvm.call @cudaGetDeviceCount(%16) : (!llvm.ptr) -> i32 loc(#loc1)
    %23 = arith.cmpi eq, %22, %c0_i32 : i32 loc(#loc1)
    %24:6 = scf.if %23 -> (i32, i32, i32, !llvm.ptr, i32, i32) {
      %28 = llvm.load %16 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
      %29 = arith.cmpi eq, %28, %c0_i32 : i32 loc(#loc1)
      %30:9 = scf.if %29 -> (!llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32) {
        scf.yield %3, %c66_i64, %2, %2, %2, %1, %2, %2, %c0_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
      } else {
        %33:14 = scf.while (%arg0 = %28, %arg1 = %c0_i32, %arg2 = %c0_i32, %arg3 = %c0_i64, %arg4 = %c0_i32) : (i32, i32, i32, i64, i32) -> (i32, i32, i32, i64, i32, i32, i32, i32, i32, i32, i32, i32, !llvm.ptr, i32) {
          %36 = arith.cmpi slt, %arg4, %arg0 : i32 loc(#loc1)
          %37:12 = scf.if %36 -> (i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32) {
            llvm.intr.lifetime.start 4, %17 : !llvm.ptr loc(#loc1)
            llvm.store %c-1_i32, %17 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
            llvm.intr.lifetime.start 4, %18 : !llvm.ptr loc(#loc1)
            llvm.store %c0_i32, %18 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
            llvm.intr.lifetime.start 4, %19 : !llvm.ptr loc(#loc1)
            llvm.store %c0_i32, %19 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
            %39 = llvm.call @cudaDeviceGetAttribute(%17, %c20_i32, %arg4) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
            %40 = arith.cmpi eq, %39, %c0_i32 : i32 loc(#loc1)
            %41:12 = scf.if %40 -> (i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32) {
              %42 = llvm.call @cudaDeviceGetAttribute(%18, %c75_i32, %arg4) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
              %43 = arith.cmpi eq, %42, %c0_i32 : i32 loc(#loc1)
              %44:12 = scf.if %43 -> (i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32) {
                %45 = llvm.call @cudaDeviceGetAttribute(%19, %c76_i32, %arg4) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
                %46 = arith.cmpi eq, %45, %c0_i32 : i32 loc(#loc1)
                %47:12 = scf.if %46 -> (i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32) {
                  %48 = llvm.load %17 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                  %49 = arith.cmpi eq, %48, %c2_i32 : i32 loc(#loc1)
                  %50:16 = scf.if %49 -> (i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32) {
                    %53 = arith.addi %arg2, %c1_i32 : i32 loc(#loc1)
                    scf.yield %arg1, %53, %arg3, %2, %2, %2, %0, %2, %2, %2, %2, %1, %2, %2, %2, %c0_i32 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32 loc(#loc1)
                  } else {
                    %53 = llvm.load %18 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                    %54 = arith.cmpi eq, %53, %c9999_i32 : i32 loc(#loc1)
                    %55 = llvm.load %19 {alignment = 4 : i64} : !llvm.ptr -> i32 loc(#loc1)
                    %56 = arith.cmpi eq, %55, %c9999_i32 : i32 loc(#loc1)
                    %57 = arith.select %54, %56, %false {fastmathFlags = #llvm.fastmath<none>} : i1 loc(#loc1)
                    %58 = scf.if %57 -> (i32) {
                      scf.yield %c1_i32 : i32 loc(#loc1)
                    } else {
                      %62 = arith.shli %53, %c4_i32 : i32 loc(#loc1)
                      %63 = arith.addi %62, %55 : i32 loc(#loc1)
                      %64:3 = scf.while (%arg5 = %c0_i64) : (i64) -> (i64, !llvm.ptr, i32) {
                        %67 = arith.cmpi eq, %arg5, %c18_i64 : i64 loc(#loc1)
                        %68:4 = scf.if %67 -> (i64, i32, i32, !llvm.ptr) {
                          scf.yield %0, %c2_i32, %c0_i32, %1 : i64, i32, i32, !llvm.ptr loc(#loc1)
                        } else {
                          %70 = llvm.getelementptr inbounds %7[0, %arg5] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.array<19 x struct<"struct.sSMtoCores", (i32, i32)>> loc(#loc1)
                          %71 = llvm.load %70 {alignment = 8 : i64, tbaa = [#tbaa_tag9]} : !llvm.ptr -> i32 loc(#loc1)
                          %72 = arith.cmpi eq, %71, %63 : i32 loc(#loc1)
                          %73 = arith.extui %72 : i1 to i32 loc(#loc1)
                          %74 = arith.cmpi ne, %71, %63 : i32 loc(#loc1)
                          %75 = arith.extui %74 : i1 to i32 loc(#loc1)
                          %76 = scf.if %72 -> (i64) {
                            scf.yield %0 : i64 loc(#loc1)
                          } else {
                            %77 = arith.addi %arg5, %c1_i64 : i64 loc(#loc1)
                            scf.yield %77 : i64 loc(#loc1)
                          } loc(#loc1)
                          scf.yield %76, %73, %75, %70 : i64, i32, i32, !llvm.ptr loc(#loc1)
                        } loc(#loc1)
                        %69 = arith.trunci %68#2 : i32 to i1 loc(#loc1)
                        scf.condition(%69) %68#0, %68#3, %68#1 : i64, !llvm.ptr, i32 loc(#loc1)
                      } do {
                      ^bb0(%arg5: i64 loc(unknown), %arg6: !llvm.ptr loc(unknown), %arg7: i32 loc(unknown)):
                        scf.yield %arg5 : i64 loc(#loc1)
                      } loc(#loc1)
                      %65 = arith.index_castui %64#2 : i32 to index loc(#loc1)
                      %66 = scf.index_switch %65 -> i32 
                      case 1 {
                        %67 = llvm.getelementptr inbounds %64#1[4] : (!llvm.ptr) -> !llvm.ptr, i8 loc(#loc1)
                        %68 = llvm.load %67 {alignment = 4 : i64, tbaa = [#tbaa_tag10]} : !llvm.ptr -> i32 loc(#loc1)
                        scf.yield %68 : i32 loc(#loc1)
                      }
                      default {
                        %67 = llvm.call @printf(%6, %53, %55, %c128_i32) vararg(!llvm.func<i32 (ptr, ...)>) {no_unwind} : (!llvm.ptr, i32, i32, i32) -> i32 loc(#loc1)
                        scf.yield %c128_i32 : i32 loc(#loc1)
                      } loc(#loc1)
                      scf.yield %66 : i32 loc(#loc1)
                    } loc(#loc1)
                    llvm.intr.lifetime.start 4, %20 : !llvm.ptr loc(#loc1)
                    llvm.store %c0_i32, %20 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
                    llvm.intr.lifetime.start 4, %21 : !llvm.ptr loc(#loc1)
                    llvm.store %c0_i32, %21 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : i32, !llvm.ptr loc(#loc1)
                    %59 = llvm.call @cudaDeviceGetAttribute(%20, %c16_i32, %arg4) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
                    %60 = arith.cmpi eq, %59, %c0_i32 : i32 loc(#loc1)
                    %61:16 = scf.if %60 -> (i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32) {
                      %62 = llvm.call @cudaDeviceGetAttribute(%21, %c13_i32, %arg4) : (!llvm.ptr, i32, i32) -> i32 loc(#loc1)
                      %63 = arith.index_castui %62 : i32 to index loc(#loc1)
                      %64:18 = scf.index_switch %63 -> i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32, i32 
                      case 0 {
                        %67 = llvm.load %21 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                        scf.yield %2, %2, %0, %2, %2, %2, %0, %2, %2, %2, %2, %1, %2, %2, %2, %2, %67, %c1_i32 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32, i32 loc(#loc1)
                      }
                      case 1 {
                        scf.yield %2, %2, %0, %2, %2, %2, %0, %2, %2, %2, %2, %1, %2, %2, %2, %2, %62, %c1_i32 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32, i32 loc(#loc1)
                      }
                      default {
                        scf.yield %2, %2, %0, %2, %2, %2, %0, %2, %2, %2, %2, %1, %c1_i32, %c0_i32, %62, %c1_i32, %2, %c0_i32 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32, i32, i32 loc(#loc1)
                      } loc(#loc1)
                      %65 = arith.index_castui %64#17 : i32 to index loc(#loc1)
                      %66:16 = scf.index_switch %65 -> i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32 
                      case 0 {
                        scf.yield %64#0, %64#1, %64#2, %64#3, %64#4, %64#5, %64#6, %64#7, %64#8, %64#9, %64#10, %64#11, %64#12, %64#13, %64#14, %64#15 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32 loc(#loc1)
                      }
                      default {
                        %67 = llvm.load %20 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                        %68 = arith.extsi %67 : i32 to i64 loc(#loc1)
                        %69 = arith.extsi %58 : i32 to i64 loc(#loc1)
                        %70 = arith.muli %68, %69 : i64 loc(#loc1)
                        %71 = arith.extsi %64#16 : i32 to i64 loc(#loc1)
                        %72 = arith.muli %70, %71 : i64 loc(#loc1)
                        %73 = arith.cmpi ugt, %72, %arg3 : i64 loc(#loc1)
                        %74 = arith.select %73, %arg4, %arg1 {fastmathFlags = #llvm.fastmath<none>} : i32 loc(#loc1)
                        %75 = arith.maxui %72, %arg3 : i64 loc(#loc1)
                        llvm.intr.lifetime.end 4, %21 : !llvm.ptr loc(#loc1)
                        llvm.intr.lifetime.end 4, %20 : !llvm.ptr loc(#loc1)
                        scf.yield %74, %arg2, %75, %2, %2, %2, %0, %2, %2, %2, %2, %1, %2, %2, %2, %c0_i32 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32 loc(#loc1)
                      } loc(#loc1)
                      scf.yield %66#0, %66#1, %66#2, %66#3, %66#4, %66#5, %66#6, %66#7, %66#8, %66#9, %66#10, %66#11, %66#12, %66#13, %66#14, %66#15 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32 loc(#loc1)
                    } else {
                      scf.yield %2, %2, %0, %2, %2, %2, %0, %2, %59, %c829_i32, %59, %5, %c2_i32, %c0_i32, %2, %c1_i32 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32 loc(#loc1)
                    } loc(#loc1)
                    scf.yield %61#0, %61#1, %61#2, %61#3, %61#4, %61#5, %61#6, %61#7, %61#8, %61#9, %61#10, %61#11, %61#12, %61#13, %61#14, %61#15 : i32, i32, i64, i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32, i32 loc(#loc1)
                  } loc(#loc1)
                  %51 = arith.index_castui %50#15 : i32 to index loc(#loc1)
                  %52:12 = scf.index_switch %51 -> i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 
                  case 0 {
                    %53 = arith.addi %arg4, %c1_i32 : i32 loc(#loc1)
                    llvm.intr.lifetime.end 4, %19 : !llvm.ptr loc(#loc1)
                    llvm.intr.lifetime.end 4, %18 : !llvm.ptr loc(#loc1)
                    llvm.intr.lifetime.end 4, %17 : !llvm.ptr loc(#loc1)
                    %54 = llvm.load %16 {alignment = 4 : i64, tbaa = [#tbaa_tag3]} : !llvm.ptr -> i32 loc(#loc1)
                    scf.yield %54, %50#0, %50#1, %50#2, %53, %2, %2, %2, %1, %c0_i32, %c1_i32, %2 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
                  }
                  default {
                    scf.yield %50#3, %50#4, %50#5, %50#6, %50#7, %50#8, %50#9, %50#10, %50#11, %50#12, %50#13, %50#14 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
                  } loc(#loc1)
                  scf.yield %52#0, %52#1, %52#2, %52#3, %52#4, %52#5, %52#6, %52#7, %52#8, %52#9, %52#10, %52#11 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
                } else {
                  scf.yield %2, %2, %2, %0, %2, %45, %c817_i32, %45, %15, %c2_i32, %c0_i32, %2 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
                } loc(#loc1)
                scf.yield %47#0, %47#1, %47#2, %47#3, %47#4, %47#5, %47#6, %47#7, %47#8, %47#9, %47#10, %47#11 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
              } else {
                scf.yield %2, %2, %2, %0, %2, %42, %c816_i32, %42, %14, %c2_i32, %c0_i32, %2 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
              } loc(#loc1)
              scf.yield %44#0, %44#1, %44#2, %44#3, %44#4, %44#5, %44#6, %44#7, %44#8, %44#9, %44#10, %44#11 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
            } else {
              scf.yield %2, %2, %2, %0, %2, %39, %c815_i32, %39, %13, %c2_i32, %c0_i32, %2 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
            } loc(#loc1)
            scf.yield %41#0, %41#1, %41#2, %41#3, %41#4, %41#5, %41#6, %41#7, %41#8, %41#9, %41#10, %41#11 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
          } else {
            scf.yield %2, %2, %2, %0, %2, %2, %2, %2, %1, %c3_i32, %c0_i32, %2 : i32, i32, i32, i64, i32, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
          } loc(#loc1)
          %38 = arith.trunci %37#10 : i32 to i1 loc(#loc1)
          scf.condition(%38) %37#0, %37#1, %37#2, %37#3, %37#4, %37#11, %arg0, %arg1, %arg2, %37#5, %37#6, %37#7, %37#8, %37#9 : i32, i32, i32, i64, i32, i32, i32, i32, i32, i32, i32, i32, !llvm.ptr, i32 loc(#loc1)
        } do {
        ^bb0(%arg0: i32 loc(unknown), %arg1: i32 loc(unknown), %arg2: i32 loc(unknown), %arg3: i64 loc(unknown), %arg4: i32 loc(unknown), %arg5: i32 loc(unknown), %arg6: i32 loc(unknown), %arg7: i32 loc(unknown), %arg8: i32 loc(unknown), %arg9: i32 loc(unknown), %arg10: i32 loc(unknown), %arg11: i32 loc(unknown), %arg12: !llvm.ptr loc(unknown), %arg13: i32 loc(unknown)):
          scf.yield %arg0, %arg1, %arg2, %arg3, %arg4 : i32, i32, i32, i64, i32 loc(#loc1)
        } loc(#loc1)
        %34 = arith.index_castui %33#13 : i32 to index loc(#loc1)
        %35:9 = scf.index_switch %34 -> !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 
        case 1 {
          %36 = llvm.load %8 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
          %37 = llvm.call fastcc @_ZL17_cudaGetErrorEnum9cudaError(%33#5) : (i32) -> !llvm.ptr loc(#loc1)
          %38 = llvm.call @fprintf(%36, %4, %10, %c838_i32, %33#5, %37) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32, !llvm.ptr) -> i32 loc(#loc1)
          llvm.call @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
          scf.yield %1, %0, %2, %2, %2, %1, %2, %c0_i32, %c1_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
        }
        case 2 {
          scf.yield %1, %0, %33#9, %33#10, %33#11, %33#12, %2, %c1_i32, %c1_i32 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
        }
        default {
          %36 = arith.cmpi eq, %33#8, %33#6 : i32 loc(#loc1)
          %37 = arith.cmpi ne, %33#8, %33#6 : i32 loc(#loc1)
          %38 = arith.extui %37 : i1 to i32 loc(#loc1)
          scf.if %36 {
          } else {
            llvm.intr.lifetime.end 4, %16 : !llvm.ptr loc(#loc1)
          } loc(#loc1)
          scf.yield %12, %c80_i64, %2, %2, %2, %1, %33#7, %c2_i32, %38 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
        } loc(#loc1)
        scf.yield %35#0, %35#1, %35#2, %35#3, %35#4, %35#5, %35#6, %35#7, %35#8 : !llvm.ptr, i64, i32, i32, i32, !llvm.ptr, i32, i32, i32 loc(#loc1)
      } loc(#loc1)
      %31 = arith.index_castui %30#8 : i32 to index loc(#loc1)
      %32:6 = scf.index_switch %31 -> i32, i32, i32, !llvm.ptr, i32, i32 
      case 0 {
        %33 = llvm.load %8 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
        %34 = llvm.call @fwrite(%30#0, %30#1, %c1_i64, %33) {no_unwind} : (!llvm.ptr, i64, i64, !llvm.ptr) -> i64 loc(#loc1)
        llvm.call @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
        scf.yield %2, %2, %2, %1, %2, %c0_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
      }
      default {
        scf.yield %30#2, %30#3, %30#4, %30#5, %30#6, %30#7 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
      } loc(#loc1)
      scf.yield %32#0, %32#1, %32#2, %32#3, %32#4, %32#5 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
    } else {
      scf.yield %22, %c801_i32, %22, %11, %2, %c1_i32 : i32, i32, i32, !llvm.ptr, i32, i32 loc(#loc1)
    } loc(#loc1)
    %25 = arith.index_castui %24#5 : i32 to index loc(#loc1)
    %26:2 = scf.index_switch %25 -> i32, i32 
    case 0 {
      scf.yield %2, %c1_i32 : i32, i32 loc(#loc1)
    }
    case 1 {
      %28 = llvm.load %8 {alignment = 8 : i64, tbaa = [#tbaa_tag2]} : !llvm.ptr -> !llvm.ptr loc(#loc1)
      %29 = llvm.call fastcc @_ZL17_cudaGetErrorEnum9cudaError(%24#0) : (i32) -> !llvm.ptr loc(#loc1)
      %30 = llvm.call @fprintf(%28, %9, %10, %24#1, %24#2, %29, %24#3) vararg(!llvm.func<i32 (ptr, ptr, ...)>) {no_unwind} : (!llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
      llvm.call @exit(%c1_i32) {no_unwind} : (i32) -> () loc(#loc1)
      scf.yield %2, %c1_i32 : i32, i32 loc(#loc1)
    }
    default {
      scf.yield %24#4, %c0_i32 : i32, i32 loc(#loc1)
    } loc(#loc1)
    cf.switch %26#1 : i32, [
      default: ^bb1,
      0: ^bb2(%26#0 : i32)
    ] loc(#loc1)
  ^bb1:  // pred: ^bb0
    llvm.unreachable loc(#loc1)
  ^bb2(%27: i32 loc(unknown)):  // pred: ^bb0
    llvm.return %27 : i32 loc(#loc1)
  } loc(#loc1)
  llvm.func local_unnamed_addr @cudaSetDevice(i32 {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaDeviceGetAttribute(!llvm.ptr {llvm.noundef}, i32 {llvm.noundef}, i32 {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaGetDeviceCount(!llvm.ptr {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func internal unnamed_addr fastcc @_ZL17_cudaGetErrorEnum9cudaError(%arg0: i32 {llvm.noundef} loc(unknown)) -> (!llvm.ptr {llvm.noundef}) attributes {dso_local, passthrough = ["mustprogress", ["uwtable", "2"], ["min-legal-vector-width", "0"], ["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} {
    %0 = llvm.call tail @cudaGetErrorName(%arg0) : (i32) -> !llvm.ptr loc(#loc1)
    llvm.return %0 : !llvm.ptr loc(#loc1)
  } loc(#loc1)
  llvm.func local_unnamed_addr @cudaGetErrorName(i32 {llvm.noundef}) -> !llvm.ptr attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @__isoc23_strtol(!llvm.ptr {llvm.noundef}, !llvm.ptr {llvm.noundef}, i32 {llvm.noundef}) -> i64 attributes {no_unwind, passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @cudaHostAlloc(!llvm.ptr {llvm.noundef}, i64 {llvm.noundef}, i32 {llvm.noundef}) -> i32 attributes {passthrough = [["no-trapping-math", "true"], ["stack-protector-buffer-size", "8"], ["target-cpu", "x86-64"]], target_cpu = "x86-64", target_features = #llvm.target_features<["+cmov", "+cx8", "+fxsr", "+mmx", "+sse", "+sse2", "+x87"]>, tune_cpu = "generic"} loc(#loc1)
  llvm.func local_unnamed_addr @__cudaPopCallConfiguration(!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
  llvm.func local_unnamed_addr @__cudaRegisterFunction(!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
  llvm.func local_unnamed_addr @__cudaRegisterFatBinary(!llvm.ptr) -> !llvm.ptr loc(#loc1)
  llvm.func internal @__cuda_module_ctor() attributes {dso_local} {
    %0 = llvm.mlir.addressof @__cuda_module_dtor : !llvm.ptr loc(#loc1)
    %1 = llvm.mlir.addressof @mlir.llvm.nameless_global_1 : !llvm.ptr loc(#loc1)
    %2 = llvm.mlir.addressof @_Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii : !llvm.ptr loc(#loc1)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %3 = llvm.mlir.addressof @mlir.llvm.nameless_global_0 : !llvm.ptr loc(#loc1)
    %4 = llvm.mlir.addressof @_Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii : !llvm.ptr loc(#loc1)
    %5 = llvm.mlir.addressof @__cuda_gpubin_handle : !llvm.ptr loc(#loc1)
    %6 = llvm.mlir.addressof @__cuda_fatbin_wrapper : !llvm.ptr loc(#loc1)
    %7 = llvm.mlir.zero : !llvm.ptr loc(#loc1)
    %8 = llvm.call tail @__cudaRegisterFatBinary(%6) : (!llvm.ptr) -> !llvm.ptr loc(#loc1)
    llvm.store %8, %5 {alignment = 8 : i64} : !llvm.ptr, !llvm.ptr loc(#loc1)
    %9 = llvm.call tail @__cudaRegisterFunction(%8, %4, %3, %3, %c-1_i32, %7, %7, %7, %7, %7) : (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
    %10 = llvm.call tail @__cudaRegisterFunction(%8, %2, %1, %1, %c-1_i32, %7, %7, %7, %7, %7) : (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32 loc(#loc1)
    llvm.call tail @__cudaRegisterFatBinaryEnd(%8) : (!llvm.ptr) -> () loc(#loc1)
    %11 = llvm.call tail @atexit(%0) : (!llvm.ptr) -> i32 loc(#loc1)
    llvm.return loc(#loc1)
  } loc(#loc1)
  llvm.func local_unnamed_addr @__cudaRegisterFatBinaryEnd(!llvm.ptr) loc(#loc1)
  llvm.func local_unnamed_addr @__cudaUnregisterFatBinary(!llvm.ptr) loc(#loc1)
  llvm.func internal @__cuda_module_dtor() attributes {dso_local} {
    %0 = llvm.mlir.addressof @__cuda_gpubin_handle : !llvm.ptr loc(#loc1)
    %1 = llvm.load %0 {alignment = 8 : i64} : !llvm.ptr -> !llvm.ptr loc(#loc1)
    llvm.call tail @__cudaUnregisterFatBinary(%1) : (!llvm.ptr) -> () loc(#loc1)
    llvm.return loc(#loc1)
  } loc(#loc1)
  llvm.func local_unnamed_addr @atexit(!llvm.ptr) -> i32 attributes {passthrough = ["nofree"]} loc(#loc1)
  llvm.func local_unnamed_addr @__mlir_launch_coerced_kernel__Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii(!llvm.ptr, i64, i32, i64, i32, i64, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32) loc(#loc1)
  llvm.func local_unnamed_addr @__mlir_launch_coerced_kernel__Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii(!llvm.ptr, i64, i32, i64, i32, i64, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32) loc(#loc1)
  llvm.func local_unnamed_addr @__mlir_launch_kernel__Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii(!llvm.ptr, i32, i32, i32, i32, i32, i32, i64, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32) loc(#loc1)
  llvm.func local_unnamed_addr @__mlir_launch_kernel__Z28__device_stub__MatrixMulCUDAILi16EEvPfS0_S0_ii.89(!llvm.ptr, i32, i32, i32, i32, i32, i32, i64, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32) loc(#loc1)
  llvm.func local_unnamed_addr @__mlir_launch_kernel__Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii(!llvm.ptr, i32, i32, i32, i32, i32, i32, i64, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32) loc(#loc1)
  llvm.func local_unnamed_addr @__mlir_launch_kernel__Z28__device_stub__MatrixMulCUDAILi32EEvPfS0_S0_ii.90(!llvm.ptr, i32, i32, i32, i32, i32, i32, i64, !llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr, i32, i32) loc(#loc1)
  llvm.func local_unnamed_addr @puts(!llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}) -> (i32 {llvm.noundef}) attributes {no_unwind, passthrough = ["nofree"]} loc(#loc1)
  llvm.func local_unnamed_addr @fwrite(!llvm.ptr {llvm.nocapture, llvm.noundef}, i64 {llvm.noundef}, i64 {llvm.noundef}, !llvm.ptr {llvm.nocapture, llvm.noundef}) -> (i64 {llvm.noundef}) attributes {no_unwind, passthrough = ["nofree"]} loc(#loc1)
  llvm.func local_unnamed_addr @fputc(i32 {llvm.noundef}, !llvm.ptr {llvm.nocapture, llvm.noundef}) -> (i32 {llvm.noundef}) attributes {no_unwind, passthrough = ["nofree"]} loc(#loc1)
} loc(#loc)
#loc = loc("matrixMul.cu":0:0)
 
