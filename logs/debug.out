gpu-affine-opt: Before opt:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c4_i32 = arith.constant 4 : i32
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %c16_i32 = arith.constant 16 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %1 = arith.index_cast %arg1 : i64 to index
  %2 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%2), symbol(%1), 1) {
    %3 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    %4 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %5 = llvm.addrspacecast %3 : !llvm.ptr<3> to !llvm.ptr
      %6 = llvm.addrspacecast %4 : !llvm.ptr<3> to !llvm.ptr
      %7 = arith.index_cast %arg12 : index to i32
      %8 = arith.index_cast %arg13 : index to i32
      %9 = arith.index_cast %arg15 : index to i32
      %10 = arith.index_cast %arg16 : index to i32
      %11 = arith.shli %arg10, %c4_i32 : i32
      %12 = arith.muli %11, %8 : i32
      %13 = arith.addi %12, %arg10 : i32
      %14 = arith.shli %7, %c4_i32 : i32
      %15 = arith.shli %arg11, %c4_i32 : i32
      %16 = arith.muli %10, %arg10 : i32
      %17 = arith.addi %16, %9 : i32
      %18 = arith.extui %10 : i32 to i64
      %19 = arith.extui %9 : i32 to i64
      %20 = llvm.getelementptr inbounds %5[0, %18, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %21 = arith.muli %10, %arg11 : i32
      %22 = arith.addi %21, %9 : i32
      %23 = llvm.getelementptr inbounds %6[0, %18, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %24:2 = scf.for %arg18 = %12 to %13 step %c16_i32 iter_args(%arg19 = %14, %arg20 = %0) -> (i32, f32)  : i32 {
        %31 = arith.addi %17, %arg18 : i32
        %32 = arith.extsi %31 : i32 to i64
        %33 = llvm.getelementptr inbounds %arg8[%32] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %34 = llvm.load %33 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %34, %20 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        %35 = arith.addi %22, %arg19 : i32
        %36 = arith.extsi %35 : i32 to i64
        %37 = llvm.getelementptr inbounds %arg9[%36] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %38 = llvm.load %37 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %38, %23 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %39 = scf.for %arg21 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg22 = %arg20) -> (f32)  : i32 {
          %41 = arith.extui %arg21 : i32 to i64
          %42 = llvm.getelementptr inbounds %5[0, %18, %41] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %43 = llvm.load %42 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %44 = llvm.getelementptr inbounds %6[0, %41, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %45 = llvm.load %44 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %46 = llvm.fmul %43, %45  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %47 = llvm.fadd %arg22, %46  {fastmathFlags = #llvm.fastmath<contract>} : f32
          scf.yield %47 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %40 = arith.addi %arg19, %15 : i32
        scf.yield %40, %39 : i32, f32
      }
      %25 = arith.muli %15, %8 : i32
      %26 = arith.addi %14, %9 : i32
      %27 = arith.addi %26, %21 : i32
      %28 = arith.addi %27, %25 : i32
      %29 = arith.extsi %28 : i32 to i64
      %30 = llvm.getelementptr inbounds %arg7[%29] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %24#1, %30 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Removed IVs:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c4_i32 = arith.constant 4 : i32
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %c16_i32 = arith.constant 16 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %1 = arith.index_cast %arg1 : i64 to index
  %2 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%2), symbol(%1), 1) {
    %3 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    %4 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %5 = llvm.addrspacecast %3 : !llvm.ptr<3> to !llvm.ptr
      %6 = llvm.addrspacecast %4 : !llvm.ptr<3> to !llvm.ptr
      %7 = arith.index_cast %arg12 : index to i32
      %8 = arith.index_cast %arg13 : index to i32
      %9 = arith.index_cast %arg15 : index to i32
      %10 = arith.index_cast %arg16 : index to i32
      %11 = arith.shli %arg10, %c4_i32 : i32
      %12 = arith.muli %11, %8 : i32
      %13 = arith.shli %7, %c4_i32 : i32
      %14 = arith.shli %arg11, %c4_i32 : i32
      %15 = arith.muli %10, %arg10 : i32
      %16 = arith.addi %15, %9 : i32
      %17 = arith.extui %10 : i32 to i64
      %18 = arith.extui %9 : i32 to i64
      %19 = llvm.getelementptr inbounds %5[0, %17, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %20 = arith.muli %10, %arg11 : i32
      %21 = arith.addi %20, %9 : i32
      %22 = llvm.getelementptr inbounds %6[0, %17, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %23 = arith.subi %arg10, %c1_i32 : i32
      %24 = arith.divui %23, %c16_i32 : i32
      %25 = arith.addi %24, %c1_i32 : i32
      %26 = scf.for %arg18 = %c0_i32 to %25 step %c1_i32 iter_args(%arg19 = %0) -> (f32)  : i32 {
        %33 = arith.muli %arg18, %14 : i32
        %34 = arith.addi %33, %13 : i32
        %35 = arith.muli %arg18, %c16_i32 : i32
        %36 = arith.addi %12, %35 : i32
        %37 = arith.addi %16, %36 : i32
        %38 = arith.extsi %37 : i32 to i64
        %39 = llvm.getelementptr inbounds %arg8[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %40 = llvm.load %39 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %40, %19 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        %41 = arith.addi %21, %34 : i32
        %42 = arith.extsi %41 : i32 to i64
        %43 = llvm.getelementptr inbounds %arg9[%42] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %44 = llvm.load %43 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %44, %22 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %45 = scf.for %arg20 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg21 = %arg19) -> (f32)  : i32 {
          %46 = arith.extui %arg20 : i32 to i64
          %47 = llvm.getelementptr inbounds %5[0, %17, %46] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %48 = llvm.load %47 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %49 = llvm.getelementptr inbounds %6[0, %46, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %50 = llvm.load %49 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %51 = llvm.fmul %48, %50  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %52 = llvm.fadd %arg21, %51  {fastmathFlags = #llvm.fastmath<contract>} : f32
          scf.yield %52 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        scf.yield %45 : f32
      }
      %27 = arith.muli %14, %8 : i32
      %28 = arith.addi %13, %9 : i32
      %29 = arith.addi %28, %20 : i32
      %30 = arith.addi %29, %27 : i32
      %31 = arith.extsi %30 : i32 to i64
      %32 = llvm.getelementptr inbounds %arg7[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %26, %32 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: To Affine:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg11 : i32 to index
  %6 = arith.index_cast %arg10 : i32 to index
  %7 = arith.index_cast %arg10 : i32 to index
  %8 = arith.index_cast %arg11 : i32 to index
  %9 = arith.index_cast %arg11 : i32 to index
  %10 = arith.index_cast %arg10 : i32 to index
  %11 = arith.index_cast %arg1 : i64 to index
  %12 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%12), symbol(%11), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %13 = affine.for %arg18 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%10] iter_args(%arg19 = %0) -> (f32) {
        %15 = affine.vector_load %2[(%arg16 * symbol(%7)) * 4 + %arg15 * 4 + %arg18 * 64 + (%arg13 * (symbol(%6) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %15, %alloca[%arg16 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %16 = affine.vector_load %1[(%arg16 * symbol(%5)) * 4 + %arg15 * 4 + %arg12 * 64 + (%arg18 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %16, %alloca_0[%arg16 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %17 = affine.for %arg20 = 0 to 16 iter_args(%arg21 = %arg19) -> (f32) {
          %18 = affine.vector_load %alloca[%arg16 * 64 + %arg20 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %19 = llvm.bitcast %18 : vector<4xi8> to f32
          %20 = affine.vector_load %alloca_0[%arg20 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %21 = llvm.bitcast %20 : vector<4xi8> to f32
          %22 = llvm.fmul %19, %21  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %23 = llvm.fadd %arg21, %22  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %23 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        affine.yield %17 : f32
      }
      %14 = llvm.bitcast %13 : f32 to vector<4xi8>
      affine.vector_store %14, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%9)) * 4 + (%arg13 * (symbol(%8) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Distributed:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c1 = arith.constant 1 : index
  %c16 = arith.constant 16 : index
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg11 : i32 to index
  %6 = arith.index_cast %arg10 : i32 to index
  %7 = arith.index_cast %arg10 : i32 to index
  %8 = arith.index_cast %arg11 : i32 to index
  %9 = arith.index_cast %arg11 : i32 to index
  %10 = arith.index_cast %arg10 : i32 to index
  %11 = arith.index_cast %arg1 : i64 to index
  %12 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%12), symbol(%11), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    %alloca_1 = memref.alloca(%c16, %c16, %c1) : memref<?x?x?xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] : memref<?x?x?xf32, 16>
    } {gpu.par.block}
    affine.for %arg15 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%10] {
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %13 = affine.vector_load %2[(%arg17 * symbol(%7)) * 4 + %arg16 * 4 + %arg15 * 64 + (%arg13 * (symbol(%6) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %13, %alloca[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %14 = affine.vector_load %1[(%arg17 * symbol(%5)) * 4 + %arg16 * 4 + %arg12 * 64 + (%arg15 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %14, %alloca_0[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
      } {gpu.par.block}
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %13 = affine.load %alloca_1[%arg16, %arg17, %arg18] : memref<?x?x?xf32, 16>
        %14 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %13) -> (f32) {
          %15 = affine.vector_load %alloca[%arg17 * 64 + %arg19 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %16 = llvm.bitcast %15 : vector<4xi8> to f32
          %17 = affine.vector_load %alloca_0[%arg19 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %18 = llvm.bitcast %17 : vector<4xi8> to f32
          %19 = llvm.fmul %16, %18  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %20 = llvm.fadd %arg20, %19  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %20 : f32
        }
        affine.store %14, %alloca_1[%arg16, %arg17, %arg18] : memref<?x?x?xf32, 16>
      } {gpu.par.block}
    }
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %13 = affine.load %alloca_1[%arg15, %arg16, %arg17] : memref<?x?x?xf32, 16>
      %14 = llvm.bitcast %13 : f32 to vector<4xi8>
      affine.vector_store %14, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%9)) * 4 + (%arg13 * (symbol(%8) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Canonicalized:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg10 : i32 to index
  %6 = arith.index_cast %arg1 : i64 to index
  %7 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%7), symbol(%6), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    %alloca_1 = memref.alloca() : memref<16x16x1xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] : memref<16x16x1xf32, 16>
    } {gpu.par.block}
    affine.for %arg15 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%5] {
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %8 = affine.vector_load %2[(%arg17 * symbol(%5)) * 4 + %arg16 * 4 + %arg15 * 64 + (%arg13 * (symbol(%5) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %8, %alloca[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %9 = affine.vector_load %1[(%arg17 * symbol(%4)) * 4 + %arg16 * 4 + %arg12 * 64 + (%arg15 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %9, %alloca_0[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
      } {gpu.par.block}
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %8 = affine.load %alloca_1[%arg16, %arg17, %arg18] : memref<16x16x1xf32, 16>
        %9 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %8) -> (f32) {
          %10 = affine.vector_load %alloca[%arg17 * 64 + %arg19 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %11 = llvm.bitcast %10 : vector<4xi8> to f32
          %12 = affine.vector_load %alloca_0[%arg19 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %13 = llvm.bitcast %12 : vector<4xi8> to f32
          %14 = llvm.fmul %11, %13  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %15 = llvm.fadd %arg20, %14  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %15 : f32
        }
        affine.store %9, %alloca_1[%arg16, %arg17, %arg18] : memref<16x16x1xf32, 16>
      } {gpu.par.block}
    }
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %8 = affine.load %alloca_1[%arg15, %arg16, %arg17] : memref<16x16x1xf32, 16>
      %9 = llvm.bitcast %8 : f32 to vector<4xi8>
      affine.vector_store %9, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%4)) * 4 + (%arg13 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
Schedule:
domain: "[P0, P1, P2, P3] -> { S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S25_llvm_fadd[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S7_arith_index_cast[]; S32_affine_vector_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S18_affine_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S19_affine_store_var[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S31_llvm_bitcast[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S1_memref_ataddr[]; S21_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S23_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S24_llvm_fmul[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S5_arith_index_cast[]; S14_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S30_affine_load[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S22_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S16_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S11_affine_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S4_arith_index_cast[]; S27_affine_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S33_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S0_llvm_mlir_constant[]; S12_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S20_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S3_memref_ataddr[]; S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
child:
  sequence:
  - filter: "[P0, P1, P2, P3] -> { S0_llvm_mlir_constant[] }"
  - filter: "[P0, P1, P2, P3] -> { S1_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S2_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S3_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S4_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S5_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S6_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S7_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S10_memref_alloca[i0, i1, i2]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S30_affine_load[i0, i1, i2, i3, i4, i5]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S34_affine_yield[i0, i1, i2]; S8_memref_alloca[i0, i1, i2]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S11_affine_store[i0, i1, i2, i3, i4, i5]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S33_affine_yield[i0, i1, i2, i3, i4, i5]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S12_affine_yield[i0, i1, i2, i3, i4, i5]; S9_memref_alloca[i0, i1, i2]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
    child:
      schedule: "[P0, P1, P2, P3] -> L16.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i0)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i0)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i0)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S10_memref_alloca[i0, i1, i2] -> [(i0)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i0)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S34_affine_yield[i0, i1, i2] -> [(i0)]; S8_memref_alloca[i0, i1, i2] -> [(i0)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i0)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i0)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i0)]; S9_memref_alloca[i0, i1, i2] -> [(i0)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)] }]"
      permutable: 1
      array_expansion: [ none ]
      child:
        schedule: "[P0, P1, P2, P3] -> L15.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i1)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i1)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i1)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S10_memref_alloca[i0, i1, i2] -> [(i1)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i1)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S34_affine_yield[i0, i1, i2] -> [(i1)]; S8_memref_alloca[i0, i1, i2] -> [(i1)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i1)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i1)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i1)]; S9_memref_alloca[i0, i1, i2] -> [(i1)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)] }]"
        permutable: 1
        array_expansion: [ none ]
        child:
          schedule: "[P0, P1, P2, P3] -> L14.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i2)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i2)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i2)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S10_memref_alloca[i0, i1, i2] -> [(i2)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i2)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S34_affine_yield[i0, i1, i2] -> [(i2)]; S8_memref_alloca[i0, i1, i2] -> [(i2)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i2)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i2)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i2)]; S9_memref_alloca[i0, i1, i2] -> [(i2)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)] }]"
          permutable: 1
          array_expansion: [ none ]
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S9_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S10_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S12_affine_yield[i0, i1, i2, i3, i4, i5]; S11_affine_store[i0, i1, i2, i3, i4, i5] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i3)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i3)] }]"
                permutable: 1
                array_expansion: [ none ]
                child:
                  schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i4)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i4)] }]"
                  permutable: 1
                  array_expansion: [ none ]
                  child:
                    schedule: "[P0, P1, P2, P3] -> L0.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i5)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i5)] }]"
                    permutable: 1
                    array_expansion: [ none ]
                    child:
                      sequence:
                      - filter: "[P0, P1, P2, P3] -> { S11_affine_store[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S12_affine_yield[i0, i1, i2, i3, i4, i5] }"
            - filter: "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S29_affine_yield[i0, i1, i2, i3]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L10.affine.for[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S29_affine_yield[i0, i1, i2, i3] -> [(i3)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)] }]"
                array_expansion: [ none ]
                child:
                  sequence:
                  - filter: "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                    child:
                      schedule: "[P0, P1, P2, P3] -> L5.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)] }]"
                      permutable: 1
                      array_expansion: [ none ]
                      child:
                        schedule: "[P0, P1, P2, P3] -> L4.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)] }]"
                        permutable: 1
                        array_expansion: [ none ]
                        child:
                          schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)] }]"
                          permutable: 1
                          array_expansion: [ none ]
                          child:
                            sequence:
                            - filter: "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                  - filter: "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] }"
                    child:
                      schedule: "[P0, P1, P2, P3] -> L9.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)] }]"
                      permutable: 1
                      array_expansion: [ none ]
                      child:
                        schedule: "[P0, P1, P2, P3] -> L8.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)] }]"
                        permutable: 1
                        array_expansion: [ none ]
                        child:
                          schedule: "[P0, P1, P2, P3] -> L7.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)] }]"
                          permutable: 1
                          array_expansion: [ none ]
                          child:
                            sequence:
                            - filter: "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] }"
                              child:
                                schedule: "[P0, P1, P2, P3] -> L6.affine.for[{ S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)] }]"
                                array_expansion: [ none ]
                                child:
                                  sequence:
                                  - filter: "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] }"
                            - filter: "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, i2, i3, i4, i5]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5]; S30_affine_load[i0, i1, i2, i3, i4, i5] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L13.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i3)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i3)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i3)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i3)] }]"
                permutable: 1
                array_expansion: [ none ]
                child:
                  schedule: "[P0, P1, P2, P3] -> L12.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i4)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i4)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i4)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i4)] }]"
                  permutable: 1
                  array_expansion: [ none ]
                  child:
                    schedule: "[P0, P1, P2, P3] -> L11.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i5)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i5)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i5)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i5)] }]"
                    permutable: 1
                    array_expansion: [ none ]
                    child:
                      sequence:
                      - filter: "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, i2, i3, i4, i5] }"
            - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2] }"
Accesses:
domain: "[P0, P1, P2, P3] -> { S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S25_llvm_fadd[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S7_arith_index_cast[]; S32_affine_vector_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S18_affine_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S19_affine_store_var[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S31_llvm_bitcast[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S1_memref_ataddr[]; S21_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S23_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S24_llvm_fmul[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S5_arith_index_cast[]; S14_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S30_affine_load[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S22_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S16_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S11_affine_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S4_arith_index_cast[]; S27_affine_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S33_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S0_llvm_mlir_constant[]; S12_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S20_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S3_memref_ataddr[]; S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
accesses:
  - S0_llvm_mlir_constant:
  - S1_memref_ataddr:
  - S2_memref_ataddr:
  - S3_memref_ataddr:
  - S4_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[] }"
  - S5_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S5_arith_index_cast[] -> A_llvm_func_arg_10_1[] }"
  - S6_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }"
  - S7_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[] }"
  - S8_memref_alloca:
  - S9_memref_alloca:
  - S10_memref_alloca:
  - S11_affine_store:
        - must_write "[P0, P1, P2, P3] -> { S11_affine_store[i0, i1, i2, i3, i4, i5] -> A_memref_alloca_res_4[i3, i4, i5] }"
  - S12_affine_yield:
  - S13_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - must_write "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_6[] }"
  - S14_affine_vector_store:
        - must_write "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_7[4i4 + 64i5] }"
        - read "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_6[] }"
  - S15_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - must_write "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_9[] }"
  - S16_affine_vector_store:
        - must_write "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_10[4i4 + 64i5] }"
        - read "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_9[] }"
  - S17_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_vector_load_res_6[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_vector_load_res_9[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
  - S18_affine_load:
        - read "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_4[i4, i5, i6] }"
        - must_write "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_load_res_11[] }"
  - S19_affine_store_var:
        - read "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> A_affine_load_res_11[] }"
        - must_write "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> A_affine_for_res_12[] }"
  - S20_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_memref_alloca_res_7[64i5 + 4i7] }"
        - must_write "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_13[] }"
  - S21_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_14[] }"
        - read "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_13[] }"
  - S22_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_memref_alloca_res_10[4i4 + 64i7] }"
        - must_write "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_15[] }"
  - S23_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_16[] }"
        - read "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_15[] }"
  - S24_llvm_fmul:
        - must_write "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fmul_res_17[] }"
        - read "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_14[] }"
        - read "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_16[] }"
  - S25_llvm_fadd:
        - must_write "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fadd_res_18[] }"
        - read "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_for_res_12[] }"
        - read "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fmul_res_17[] }"
  - S26_affine_yield:
        - must_write "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_for_res_12[] }"
        - read "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fadd_res_18[] }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_affine_vector_load_res_13[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_bitcast_res_14[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_affine_vector_load_res_15[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_bitcast_res_16[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_fmul_res_17[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_fadd_res_18[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
  - S27_affine_store:
        - must_write "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_4[i4, i5, i6] }"
        - read "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_for_res_12[] }"
  - S28_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_load_res_11[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_for_res_12[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
  - S29_affine_yield:
  - S30_affine_load:
        - read "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] -> A_memref_alloca_res_4[i3, i4, i5] }"
        - must_write "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] -> A_affine_load_res_19[] }"
  - S31_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> A_llvm_bitcast_res_20[] }"
        - read "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> A_affine_load_res_19[] }"
  - S32_affine_vector_store:
        - may_write "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, 0, i3, i4, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
        - read "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> A_llvm_bitcast_res_20[] }"
  - S33_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, 0, i3, i4, 0] -> A_affine_load_res_19[] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, 0, i3, i4, 0] -> A_llvm_bitcast_res_20[] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
  - S34_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
  - S35_llvm_return:
Schedule:
domain: "[P0, P1, P2, P3] -> { S4_arith_index_cast[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S1_memref_ataddr[]; RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S0_llvm_mlir_constant[]; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
child:
  sequence:
  - filter: "[P0, P1, P2, P3] -> { S0_llvm_mlir_constant[] }"
  - filter: "[P0, P1, P2, P3] -> { S1_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S2_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S3_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S4_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S5_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S6_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S7_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3]; S8_memref_alloca[i0, i1, i2]; RS3_affine_parallel[i0, i1, i2]; S29_affine_yield[i0, i1, i2, i3]; S10_memref_alloca[i0, i1, i2]; S9_memref_alloca[i0, i1, i2]; RS0_affine_parallel[i0, i1, i2] }"
    child:
      schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; S9_memref_alloca[i0, i1, i2] -> [(i0)]; S8_memref_alloca[i0, i1, i2] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; S29_affine_yield[i0, i1, i2, i3] -> [(i0)]; S34_affine_yield[i0, i1, i2] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; S10_memref_alloca[i0, i1, i2] -> [(i0)] }]"
      permutable: 1
      array_expansion: [ none ]
      child:
        schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; S9_memref_alloca[i0, i1, i2] -> [(i1)]; S8_memref_alloca[i0, i1, i2] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; S29_affine_yield[i0, i1, i2, i3] -> [(i1)]; S34_affine_yield[i0, i1, i2] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; S10_memref_alloca[i0, i1, i2] -> [(i1)] }]"
        permutable: 1
        array_expansion: [ none ]
        child:
          schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i2)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i2)]; S9_memref_alloca[i0, i1, i2] -> [(i2)]; S8_memref_alloca[i0, i1, i2] -> [(i2)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i2)]; S29_affine_yield[i0, i1, i2, i3] -> [(i2)]; S34_affine_yield[i0, i1, i2] -> [(i2)]; RS3_affine_parallel[i0, i1, i2] -> [(i2)]; S10_memref_alloca[i0, i1, i2] -> [(i2)] }]"
          permutable: 1
          array_expansion: [ none ]
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S9_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S10_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L0.affine.for[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)]; S29_affine_yield[i0, i1, i2, i3] -> [(i3)] }]"
                array_expansion: [ none ]
                child:
                  sequence:
                  - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
                  - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
                  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2] }"
Accesses:
domain: "[P0, P1, P2, P3] -> { S4_arith_index_cast[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S1_memref_ataddr[]; RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S0_llvm_mlir_constant[]; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
accesses:
  - S0_llvm_mlir_constant:
  - S1_memref_ataddr:
  - S2_memref_ataddr:
  - S3_memref_ataddr:
  - S4_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[] }"
  - S5_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S5_arith_index_cast[] -> A_llvm_func_arg_10_1[] }"
  - S6_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }"
  - S7_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[] }"
  - S8_memref_alloca:
  - S9_memref_alloca:
  - S10_memref_alloca:
  - S29_affine_yield:
  - S34_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
  - S35_llvm_return:
  - RS0_affine_parallel:
        - must_write "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
  - RS1_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
        - must_write "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - read "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
        - must_write "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
  - RS2_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - must_write "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
  - RS3_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
        - may_write "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
ReductionTagMap: [P0, P1, P2, P3] -> {  }
TaggedStmtDomain: [P2, P3, P0, P1] -> { [RS2_affine_parallel[i0, i1, i2, i3] -> S18_affine_load_Read0[]]; [RS0_affine_parallel[i0, i1, i2] -> S11_affine_store_Write0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S14_affine_vector_store_Write0[]]; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S27_affine_store_Write0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield2[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S20_affine_vector_load_Read0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield1[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S15_affine_vector_load_Read0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S22_affine_vector_load_Read0[]]; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]]; [RS3_affine_parallel[i0, i1, i2] -> S32_affine_vector_store_MayWrite0[]]; [RS3_affine_parallel[i0, i1, i2] -> S30_affine_load_Read0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S16_affine_vector_store_Write0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S13_affine_vector_load_Read0[]]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] }
dep_order for A_llvm_func_arg_11_0 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_10_1 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_1_2 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_0_3 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_4 [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, i2] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0); RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and o3 < i3) or (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 > i3 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and o3 < i3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and o1 > i1 and o1 < P2 and o3 > i3 and 16o3 < P0); RS2_affine_parallel[i0, i1, i2, i3] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2); RS3_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and o1 > i1 and o1 < P2) }
dep_order for A_memref_ataddr_res_5 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_6 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_7 [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0) }
dep_order for A_memref_ataddr_res_8 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_9 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_10 [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0) }
dep_order for A_affine_load_res_11 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_for_res_12 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_13 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_14 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_15 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_16 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_fmul_res_17 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_fadd_res_18 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_load_res_19 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_20 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_ataddr_res_21 [P2, P3, P0, P1] -> {  }
ReductionTagMap: [P0, P1, P2, P3] -> {  }
TaggedStmtDomain: [P2, P3, P0, P1] -> { [RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_8[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_10[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]]; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_5[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_7[]]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_ataddr_res_21[]]; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]]; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]]; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] }
dep_order for A_llvm_func_arg_11_0 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_10_1 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_1_2 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_0_3 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_4 [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, i2] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0); RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and o3 < i3) or (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 > i3 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and o3 < i3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and o1 > i1 and o1 < P2 and o3 > i3 and 16o3 < P0); RS2_affine_parallel[i0, i1, i2, i3] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2); RS3_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and o1 > i1 and o1 < P2) }
dep_order for A_memref_ataddr_res_5 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_6 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_7 [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0) }
dep_order for A_memref_ataddr_res_8 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_9 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_10 [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0) }
dep_order for A_affine_load_res_11 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_for_res_12 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_13 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_14 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_15 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_16 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_fmul_res_17 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_fadd_res_18 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_load_res_19 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_20 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_ataddr_res_21 [P2, P3, P0, P1] -> {  }
tagged_reads [P2, P3, P0, P1] -> { [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]] -> A_llvm_func_arg_0_3[]; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS1_affine_parallel[i0, i1, 0, i3] -> S15_affine_vector_load_Read0[]] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S13_affine_vector_load_Read0[]] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]] -> A_llvm_func_arg_11_0[]; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]] -> A_llvm_func_arg_1_2[]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] -> A_llvm_func_arg_10_1[] }
atagged_reads [P2, P3, P0, P1] -> { [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]] -> A_llvm_func_arg_0_3[]; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]] -> A_llvm_func_arg_10_1[]; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[]] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]] -> A_llvm_func_arg_11_0[]; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]] -> A_llvm_func_arg_1_2[]; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[]] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
reads [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]; S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]; RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
async_reads [P0, P2, P3, P1] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
tagged_may_writes [P2, P3, P0, P1] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }
atagged_may_writes [P2, P3, P0, P1] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[]] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
may_writes [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
tagged_must_writes [P0, P2, P3, P1] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
atagged_must_writes [P0, P2, P3, P1] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
must_writes [P0, P2, P3, P1] -> { RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
async_must_writes [P0, P2, P3, P1] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
tagged_must_kills [P0, P1, P2, P3] -> { [S34_affine_yield[i0, i1, 0] -> S34_affine_yield1[]] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; [S34_affine_yield[i0, i1, 0] -> S34_affine_yield0[]] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; [S34_affine_yield[i0, i1, 0] -> S34_affine_yield2[]] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2 }
atagged_must_kills [P0, P1, P2, P3] -> { [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2; [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }
must_kills [P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2; S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }
live_in [P0, P2, P3, P1] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]; S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]; S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
live_out [P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }
independence [P2, P3, P0, P1] -> { S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : o2 < i2 or o2 > i2; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, i1, i2] : o0 < i0 or o0 > i0; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, i2] : o1 < i1 or o1 > i1; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, o1, o2] : o2 > i2 or o2 < i2; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, i1, i2] : o0 > i0 or o0 < i0; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, o1, i2] : o1 > i1 or o1 < i1; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, i3] : o2 > i2 or o2 < i2; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[i0, i1, i2, o3] : o3 > i3 or o3 < i3; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, i2, i3] : o1 > i1 or o1 < i1; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, i1, i2, i3] : o0 > i0 or o0 < i0; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, i3] : o2 > i2 or o2 < i2; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[i0, i1, i2, o3] : o3 > i3 or o3 < i3; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, i2, i3] : o1 > i1 or o1 < i1; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, i1, i2, i3] : o0 > i0 or o0 < i0; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, o1, o2] : o2 < i2 or o2 > i2; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, i1, i2] : o0 < i0 or o0 > i0; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, o1, i2] : o1 < i1 or o1 > i1; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, o1, o2, i3] : o2 > i2 or o2 < i2; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[i0, i1, i2, o3] : o3 > i3 or o3 < i3; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, o1, i2, i3] : o1 > i1 or o1 < i1; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, i1, i2, i3] : o0 > i0 or o0 < i0 }
dep_flow [P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }
tagged_dep_flow [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0 }
atagged_dep_flow [P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> A_memref_alloca_res_4[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> A_memref_alloca_res_4[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
dep_false [P2, P3, P0, P1] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 <= -2 + P2 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, -1 + P2, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P2 > 0 and P0 > 0 and 0 <= i0 <= -2 + P3 and -16 + P0 <= 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 <= -2 + P2 and -16 + P0 <= 16i3 < P0; RS1_affine_parallel[i0, -1 + P2, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P2 > 0 and P0 > 0 and 0 <= i0 <= -2 + P3 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P3 and 0 <= i1 <= -2 + P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, -1 + P2, 0, i3] -> RS0_affine_parallel[1 + i0, 0, 0] : P2 > 0 and 0 <= i0 <= -2 + P3 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P3 and 0 <= i1 <= -2 + P2; RS3_affine_parallel[i0, -1 + P2, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P2 > 0 and 0 <= i0 <= -2 + P3; RS0_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 <= -2 + P2; RS0_affine_parallel[i0, -1 + P2, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P2 > 0 and P0 <= 0 and 0 <= i0 <= -2 + P3 }
dep_forced [P2, P3, P0, P1] -> {  }
dep_order [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 }
tagged_dep_order [P2, P3, P0, P1] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0 }
dep_async [P0, P2, P3, P1] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
array_order [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and ((16i3 < P0 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P0)); RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and ((16i3 < P0 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P0)); RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 }
tagger [P0, P1, P2, P3] -> { [RS2_affine_parallel[i0, i1, i2, i3] -> S18_affine_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS0_affine_parallel[i0, i1, i2] -> S11_affine_store_Write0[]] -> RS0_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S14_affine_vector_store_Write0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]] -> S6_arith_index_cast[]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]] -> S4_arith_index_cast[]; [RS2_affine_parallel[i0, i1, i2, i3] -> S27_affine_store_Write0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS2_affine_parallel[i0, i1, i2, i3] -> S20_affine_vector_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield2[]] -> S34_affine_yield[(i0), (i1), (i2)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield1[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S15_affine_vector_load_Read0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield0[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> S22_affine_vector_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]] -> S7_arith_index_cast[]; [RS3_affine_parallel[i0, i1, i2] -> S32_affine_vector_store_MayWrite0[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS3_affine_parallel[i0, i1, i2] -> S30_affine_load_Read0[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S16_affine_vector_store_Write0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S13_affine_vector_load_Read0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] -> S5_arith_index_cast[] }
atagger [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]] -> RS0_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_8[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_4[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_10[]] -> S34_affine_yield[(i0), (i1), (i2)]; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]] -> S4_arith_index_cast[]; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]] -> S7_arith_index_cast[]; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]] -> S6_arith_index_cast[]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_7[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_5[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]] -> S5_arith_index_cast[]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_ataddr_res_21[]] -> RS3_affine_parallel[(i0), (i1), (i2)] }
schedule
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
child:
  schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; RS0_affine_parallel[i0, i1, i2] -> [(i0)] }]"
  permutable: 1
  array_expansion: [ none ]
  child:
    schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; RS0_affine_parallel[i0, i1, i2] -> [(i1)] }]"
    permutable: 1
    array_expansion: [ none ]
    child:
      schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(0)]; RS3_affine_parallel[i0, i1, i2] -> [(0)]; RS0_affine_parallel[i0, i1, i2] -> [(0)] }]"
      permutable: 1
      array_expansion: [ none ]
      child:
        sequence:
        - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
        - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
          child:
            schedule: "[P0, P1, P2, P3] -> L0.affine.for[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
            array_expansion: [ none ]
            child:
              sequence:
              - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
              - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
        - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
Schedule constraints:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
validity: "[P2, P3, P0, P1] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
coincidence: "[P2, P3, P0, P1] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
condition: "[P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0 }"
conditional_validity: "[P2, P3, P0, P1] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0 }"
proximity: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
anti_proximity: "[P0, P2, P3, P1] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
live_range_span: "[P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> A_memref_alloca_res_4[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> A_memref_alloca_res_4[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
live_range_maximal_span: "[P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and (P0 >= 17 or P0 <= 0 or (0 < P0 <= 16)); [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
array_sizes: "[P0, P1, P2, P3] -> { A_memref_alloca_res_10[] -> [1024]; A_memref_alloca_res_4[] -> [1024]; A_memref_alloca_res_7[] -> [1024] }"
Building sched graph from scheudle constraints:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
validity: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
coincidence: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
condition: "[P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0 }"
conditional_validity: "[P0, P1, P2, P3] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0 }"
proximity: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
anti_proximity: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
live_range_span: "[P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> A_memref_alloca_res_4[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> A_memref_alloca_res_4[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
live_range_maximal_span: "[P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and (P0 >= 17 or P0 <= 0 or (0 < P0 <= 16)); [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
array_sizes: "[P0, P1, P2, P3] -> { A_memref_alloca_res_10[] -> [1024]; A_memref_alloca_res_4[] -> [1024]; A_memref_alloca_res_7[] -> [1024] }"
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i48 = i17 and i39 = i28 and i7 = i6 and i48 = i28 and i28 = i17 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i28 = i17 and i48 = i28 and i39 = i28 and i48 = i17 and i22 >= i21 and i27 >= i16 and i30 >= -i12 + i13 + i19 + i23 - i24 and i30 >= i19 and i29 >= -i14 + i15 + i18 + i25 - i26 and i29 >= i18 and i31 >= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 >= -i21 + i22 + 16i27 and i50 >= i30 and i49 >= -i25 + i26 + i29 + i45 - i46 and i49 >= i29 and i50 >= -i23 + i24 + i30 + i43 - i44 and i51 >= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i41 <= -i23 + i24 + i30 + i34 - i35 and i41 <= i30 and i40 <= -i25 + i26 + i29 + i36 - i37 and i40 <= i29 and 16i38 <= -i21 + i22 + 16i27 + i32 - i33 and i38 <= i27 and i42 <= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 <= i16 and i50 >= -i12 + i13 + i19 + i43 - i44 and i50 >= i19 and i49 >= -i14 + i15 + i18 + i45 - i46 and i49 >= i18 and i51 >= i18 + i19 + i20 - i49 - i50 and i27 <= i16 and i30 <= -i12 + i13 + i19 + i23 - i24 and i30 <= i19 and i29 <= -i14 + i15 + i18 + i25 - i26 and i29 <= i18 and i31 <= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 <= -i21 + i22 + 16i27 and i50 <= i30 and i49 <= -i25 + i26 + i29 + i45 - i46 and i49 <= i29 and i50 <= -i23 + i24 + i30 + i43 - i44 and i51 <= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i9 >= i8 and i11 >= i10 and i5 >= i4 and i22 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i21 and i41 >= -i23 + i24 + i30 + i34 - i35 and i41 >= i30 and i40 >= -i25 + i26 + i29 + i36 - i37 and i40 >= i29 and 16i38 >= -i21 + i22 + 16i27 + i32 - i33 and i38 >= i27 and i42 >= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 >= i16 and i50 <= -i12 + i13 + i19 + i43 - i44 and i50 <= i19 and i49 <= -i14 + i15 + i18 + i45 - i46 and i49 <= i18 and i51 <= i18 + i19 + i20 - i49 - i50 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[1,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0]
added row to overlapping live ranges
[[1,1,1]]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i48 = i17 and i39 = i28 and i48 = i28 and i28 = i17 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i28 = i17 and i48 = i28 and i39 = i28 and i48 = i17 and i22 >= i21 and i27 >= i16 and i30 >= -i12 + i13 + i19 + i23 - i24 and i30 >= i19 and i29 >= -i14 + i15 + i18 + i25 - i26 and i29 >= i18 and i31 >= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 >= -i21 + i22 + 16i27 and i50 >= i30 and i49 >= -i25 + i26 + i29 + i45 - i46 and i49 >= i29 and i50 >= -i23 + i24 + i30 + i43 - i44 and i51 >= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i41 <= -i23 + i24 + i30 + i34 - i35 and i41 <= i30 and i40 <= -i25 + i26 + i29 + i36 - i37 and i40 <= i29 and 16i38 <= -i21 + i22 + 16i27 + i32 - i33 and i38 <= i27 and i42 <= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 <= i16 and i50 >= -i12 + i13 + i19 + i43 - i44 and i50 >= i19 and i49 >= -i14 + i15 + i18 + i45 - i46 and i49 >= i18 and i51 >= i18 + i19 + i20 - i49 - i50 and i27 <= i16 and i30 <= -i12 + i13 + i19 + i23 - i24 and i30 <= i19 and i29 <= -i14 + i15 + i18 + i25 - i26 and i29 <= i18 and i31 <= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 <= -i21 + i22 + 16i27 and i50 <= i30 and i49 <= -i25 + i26 + i29 + i45 - i46 and i49 <= i29 and i50 <= -i23 + i24 + i30 + i43 - i44 and i51 <= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i22 <= i21 and i41 >= -i23 + i24 + i30 + i34 - i35 and i41 >= i30 and i40 >= -i25 + i26 + i29 + i36 - i37 and i40 >= i29 and 16i38 >= -i21 + i22 + 16i27 + i32 - i33 and i38 >= i27 and i42 >= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 >= i16 and i50 <= -i12 + i13 + i19 + i43 - i44 and i50 <= i19 and i49 <= -i14 + i15 + i18 + i45 - i46 and i49 <= i18 and i51 <= i18 + i19 + i20 - i49 - i50 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[1,0,0,0,4,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]
added row to overlapping live ranges
[[1,1,1]
 [1,1,1]]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i48 = i17 and i39 = i28 and i48 = i28 and i28 = i17 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i28 = i17 and i48 = i28 and i39 = i28 and i48 = i17 and i22 >= i21 and i27 >= i16 and i30 >= -i12 + i13 + i19 + i23 - i24 and i30 >= i19 and i29 >= -i14 + i15 + i18 + i25 - i26 and i29 >= i18 and i31 >= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 >= -i21 + i22 + 16i27 and i50 >= i30 and i49 >= -i25 + i26 + i29 + i45 - i46 and i49 >= i29 and i50 >= -i23 + i24 + i30 + i43 - i44 and i51 >= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i41 <= -i23 + i24 + i30 + i34 - i35 and i41 <= i30 and i40 <= -i25 + i26 + i29 + i36 - i37 and i40 <= i29 and 16i38 <= -i21 + i22 + 16i27 + i32 - i33 and i38 <= i27 and i42 <= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 <= i16 and i50 >= -i12 + i13 + i19 + i43 - i44 and i50 >= i19 and i49 >= -i14 + i15 + i18 + i45 - i46 and i49 >= i18 and i51 >= i18 + i19 + i20 - i49 - i50 and i27 <= i16 and i30 <= -i12 + i13 + i19 + i23 - i24 and i30 <= i19 and i29 <= -i14 + i15 + i18 + i25 - i26 and i29 <= i18 and i31 <= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 <= -i21 + i22 + 16i27 and i50 <= i30 and i49 <= -i25 + i26 + i29 + i45 - i46 and i49 <= i29 and i50 <= -i23 + i24 + i30 + i43 - i44 and i51 <= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i22 <= i21 and i41 >= -i23 + i24 + i30 + i34 - i35 and i41 >= i30 and i40 >= -i25 + i26 + i29 + i36 - i37 and i40 >= i29 and 16i38 >= -i21 + i22 + 16i27 + i32 - i33 and i38 >= i27 and i42 >= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 >= i16 and i50 <= -i12 + i13 + i19 + i43 - i44 and i50 <= i19 and i49 <= -i14 + i15 + i18 + i45 - i46 and i49 <= i18 and i51 <= i18 + i19 + i20 - i49 - i50 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i48 = i17 and i39 = i28 and i48 = i28 and i28 = i17 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i28 = i17 and i48 = i28 and i39 = i28 and i48 = i17 and i22 >= i21 and i27 >= i16 and i30 >= -i12 + i13 + i19 + i23 - i24 and i30 >= i19 and i29 >= -i14 + i15 + i18 + i25 - i26 and i29 >= i18 and i31 >= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 >= -i21 + i22 + 16i27 and i50 >= i30 and i49 >= -i25 + i26 + i29 + i45 - i46 and i49 >= i29 and i50 >= -i23 + i24 + i30 + i43 - i44 and i51 >= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i41 <= -i23 + i24 + i30 + i34 - i35 and i41 <= i30 and i40 <= -i25 + i26 + i29 + i36 - i37 and i40 <= i29 and 16i38 <= -i21 + i22 + 16i27 + i32 - i33 and i38 <= i27 and i42 <= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 <= i16 and i50 >= -i12 + i13 + i19 + i43 - i44 and i50 >= i19 and i49 >= -i14 + i15 + i18 + i45 - i46 and i49 >= i18 and i51 >= i18 + i19 + i20 - i49 - i50 and i27 <= i16 and i30 <= -i12 + i13 + i19 + i23 - i24 and i30 <= i19 and i29 <= -i14 + i15 + i18 + i25 - i26 and i29 <= i18 and i31 <= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 <= -i21 + i22 + 16i27 and i50 <= i30 and i49 <= -i25 + i26 + i29 + i45 - i46 and i49 <= i29 and i50 <= -i23 + i24 + i30 + i43 - i44 and i51 <= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i22 <= i21 and i41 >= -i23 + i24 + i30 + i34 - i35 and i41 >= i30 and i40 >= -i25 + i26 + i29 + i36 - i37 and i40 >= i29 and 16i38 >= -i21 + i22 + 16i27 + i32 - i33 and i38 >= i27 and i42 >= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 >= i16 and i50 <= -i12 + i13 + i19 + i43 - i44 and i50 <= i19 and i49 <= -i14 + i15 + i18 + i45 - i46 and i49 <= i18 and i51 <= i18 + i19 + i20 - i49 - i50 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[]
computed band mupa:
[P0, P1, P2, P3] -> [{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)] }, { RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)] }]
handling array expansion for row 0 of
[[1,1,1]
 [1,1,1]]
setting for member 0
handling array expansion for row 1 of
[[1,1,1]
 [1,1,1]]
setting for member 1
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51, i52, i53, i54, i55, i56, i57, i58, i59] : i36 = -i7 + i8 + i25 and i56 = i25 and i47 = i36 and i56 = i36 and i36 = i25 and i54 = i4 - i20 - i21 - i22 - i23 - i29 - i30 - i31 - i32 - i33 - i34 - i40 - i41 - i42 - i43 - i44 - i45 - i51 - i52 - i53 and i58 = i3 - i24 - i25 - i26 - i27 - i35 - i36 - i37 - i38 - i46 - i47 - i48 - i49 - i55 - i56 - i57 and i13 = 100000 - i0 and i12 = i1 - i5 - i6 - i7 - i8 - i9 - i10 - i11 and i19 = 1 + i16 and i18 = 1 + i15 and i17 = 1 + i14 and i55 = i24 and i56 = i25 and i47 = i36 and i47 = i36 and i47 = i36 and i56 = -i7 + i8 + i36 and i8 = i7 and i47 = i7 - i8 + i36 and i56 = -i7 + i8 + i25 and i49 <= -i31 + i32 + i38 + i42 - i43 and i49 <= i38 and i48 <= -i33 + i34 + i37 + i44 - i45 and i48 <= i37 and 16i46 <= -i29 + i30 + 16i35 + i40 - i41 and i46 <= i35 and i50 <= -i13 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i49 >= -i31 + i32 + i38 + i42 - i43 and i49 >= i38 and i48 >= -i33 + i34 + i37 + i44 - i45 and i48 >= i37 and 16i46 >= -i29 + i30 + 16i35 + i40 - i41 and i46 >= i35 and i50 >= -i15 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i49 >= -i31 + i32 + i38 + i42 - i43 and i49 >= i38 and i48 >= -i33 + i34 + i37 + i44 - i45 and i48 >= i37 and 16i46 >= -i29 + i30 + 16i35 + i40 - i41 and i46 >= i35 and i50 >= -i16 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i59 <= i14 + i26 + i27 + i28 - i57 - i58 and i58 <= -i20 + i21 + i27 + i51 - i52 and i58 <= i27 and i57 <= -i22 + i23 + i26 + i53 - i54 and i57 <= i26 and 1024i19 <= 48000 - 1024i17 - 1024i18 and i17 > 0 and i18 > 0 and i19 > 0 and i30 >= i29 and i35 >= i24 and i38 >= -i20 + i21 + i27 + i31 - i32 and i38 >= i27 and i37 >= -i22 + i23 + i26 + i33 - i34 and i37 >= i26 and i39 >= i24 + i26 + i27 + i28 - i35 - i37 - i38 and 16i55 >= -i29 + i30 + 16i35 and i58 >= i38 and i57 >= -i33 + i34 + i37 + i53 - i54 and i57 >= i37 and i58 >= -i31 + i32 + i38 + i51 - i52 and i59 >= i35 + i37 + i38 + i39 - i55 - i57 - i58 and 16i59 >= 15i29 - 15i30 + 16i35 + 16i37 + 16i38 + 16i39 - 16i55 - 16i57 - 16i58 and i49 <= -i31 + i32 + i38 + i42 - i43 and i49 <= i38 and i48 <= -i33 + i34 + i37 + i44 - i45 and i48 <= i37 and 16i46 <= -i29 + i30 + 16i35 + i40 - i41 and i46 <= i35 and i50 <= i35 + i37 + i38 + i39 - i46 - i48 - i49 and i55 <= i24 and i58 >= -i20 + i21 + i27 + i51 - i52 and i58 >= i27 and i57 >= -i22 + i23 + i26 + i53 - i54 and i57 >= i26 and i59 >= i26 + i27 + i28 - i57 - i58 and i35 <= -i5 + i6 + i24 and i38 <= -i11 + i12 - i20 + i21 + i27 + i31 - i32 and i38 <= -i11 + i12 + i27 and i37 <= -i9 + i10 - i22 + i23 + i26 + i33 - i34 and i37 <= -i9 + i10 + i26 and i39 <= i2 - i5 + i6 - i9 + i10 - i11 + i12 + i24 + i26 + i27 + i28 - i35 - i37 - i38 and 16i55 <= -16i5 + 16i6 - i29 + i30 + 16i35 and i58 <= -i11 + i12 + i38 and i57 <= -i9 + i10 - i33 + i34 + i37 + i53 - i54 and i57 <= -i9 + i10 + i37 and i58 <= -i11 + i12 - i31 + i32 + i38 + i51 - i52 and i59 <= i2 - i5 + i6 - i9 + i10 - i11 + i12 + i35 + i37 + i38 + i39 - i55 - i57 - i58 and 16i59 <= 16i2 - 16i5 + 16i6 - 16i9 + 16i10 - 16i11 + 16i12 + 15i29 - 15i30 + 16i35 + 16i37 + 16i38 + 16i39 - 16i55 - 16i57 - 16i58 and i10 >= i9 and i12 >= i11 and i6 >= i5 and i30 <= i2 - 17i5 + 17i6 - i9 + i10 - i11 + i12 + i29 and i49 >= i11 - i12 - i31 + i32 + i38 + i42 - i43 and i49 >= i11 - i12 + i38 and i48 >= i9 - i10 - i33 + i34 + i37 + i44 - i45 and i48 >= i9 - i10 + i37 and 16i46 >= 16i5 - 16i6 - i29 + i30 + 16i35 + i40 - i41 and i46 >= i5 - i6 + i35 and i50 >= -i2 + i5 - i6 + i9 - i10 + i11 - i12 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i55 >= -i5 + i6 + i24 and i58 <= -i11 + i12 - i20 + i21 + i27 + i51 - i52 and i58 <= -i11 + i12 + i27 and i57 <= -i9 + i10 - i22 + i23 + i26 + i53 - i54 and i57 <= -i9 + i10 + i26 and i59 <= i2 - i9 + i10 - i11 + i12 + i26 + i27 + i28 - i57 - i58 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51, i52, i53, i54, i55, i56, i57, i58, i59] : i0 = 100000 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 1 and i18 = 1 and i19 = 1 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 and i52 = 0 and i53 = 0 and i54 = 0 and i55 = 0 and i56 = 0 and i57 = 0 and i58 = 0 and i59 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51, i52, i53, i54, i55, i56, i57, i58, i59] : i36 = -i7 + i8 + i25 and i56 = i25 and i47 = i36 and i56 = i36 and i36 = i25 and i54 = i4 - i20 - i21 - i22 - i23 - i29 - i30 - i31 - i32 - i33 - i34 - i40 - i41 - i42 - i43 - i44 - i45 - i51 - i52 - i53 and i58 = i3 - i24 - i25 - i26 - i27 - i35 - i36 - i37 - i38 - i46 - i47 - i48 - i49 - i55 - i56 - i57 and i13 = 100000 - i0 and i12 = i1 - i5 - i6 - i7 - i8 - i9 - i10 - i11 and i19 = 1 + i16 and i18 = 1 + i15 and i17 = 1 + i14 and i55 = i24 and i56 = i25 and i47 = i36 and i47 = i36 and i47 = i36 and i56 = -i7 + i8 + i36 and i8 = i7 and i47 = i7 - i8 + i36 and i56 = -i7 + i8 + i25 and i49 <= -i31 + i32 + i38 + i42 - i43 and i49 <= i38 and i48 <= -i33 + i34 + i37 + i44 - i45 and i48 <= i37 and 16i46 <= -i29 + i30 + 16i35 + i40 - i41 and i46 <= i35 and i50 <= -i13 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i49 >= -i31 + i32 + i38 + i42 - i43 and i49 >= i38 and i48 >= -i33 + i34 + i37 + i44 - i45 and i48 >= i37 and 16i46 >= -i29 + i30 + 16i35 + i40 - i41 and i46 >= i35 and i50 >= -i15 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i49 >= -i31 + i32 + i38 + i42 - i43 and i49 >= i38 and i48 >= -i33 + i34 + i37 + i44 - i45 and i48 >= i37 and 16i46 >= -i29 + i30 + 16i35 + i40 - i41 and i46 >= i35 and i50 >= -i16 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i59 <= i14 + i26 + i27 + i28 - i57 - i58 and i58 <= -i20 + i21 + i27 + i51 - i52 and i58 <= i27 and i57 <= -i22 + i23 + i26 + i53 - i54 and i57 <= i26 and 1024i19 <= 48000 - 1024i17 - 1024i18 and i17 > 0 and i18 > 0 and i19 > 0 and i30 >= i29 and i35 >= i24 and i38 >= -i20 + i21 + i27 + i31 - i32 and i38 >= i27 and i37 >= -i22 + i23 + i26 + i33 - i34 and i37 >= i26 and i39 >= i24 + i26 + i27 + i28 - i35 - i37 - i38 and 16i55 >= -i29 + i30 + 16i35 and i58 >= i38 and i57 >= -i33 + i34 + i37 + i53 - i54 and i57 >= i37 and i58 >= -i31 + i32 + i38 + i51 - i52 and i59 >= i35 + i37 + i38 + i39 - i55 - i57 - i58 and 16i59 >= 15i29 - 15i30 + 16i35 + 16i37 + 16i38 + 16i39 - 16i55 - 16i57 - 16i58 and i49 <= -i31 + i32 + i38 + i42 - i43 and i49 <= i38 and i48 <= -i33 + i34 + i37 + i44 - i45 and i48 <= i37 and 16i46 <= -i29 + i30 + 16i35 + i40 - i41 and i46 <= i35 and i50 <= i35 + i37 + i38 + i39 - i46 - i48 - i49 and i55 <= i24 and i58 >= -i20 + i21 + i27 + i51 - i52 and i58 >= i27 and i57 >= -i22 + i23 + i26 + i53 - i54 and i57 >= i26 and i59 >= i26 + i27 + i28 - i57 - i58 and i35 <= -i5 + i6 + i24 and i38 <= -i11 + i12 - i20 + i21 + i27 + i31 - i32 and i38 <= -i11 + i12 + i27 and i37 <= -i9 + i10 - i22 + i23 + i26 + i33 - i34 and i37 <= -i9 + i10 + i26 and i39 <= i2 - i5 + i6 - i9 + i10 - i11 + i12 + i24 + i26 + i27 + i28 - i35 - i37 - i38 and 16i55 <= -16i5 + 16i6 - i29 + i30 + 16i35 and i58 <= -i11 + i12 + i38 and i57 <= -i9 + i10 - i33 + i34 + i37 + i53 - i54 and i57 <= -i9 + i10 + i37 and i58 <= -i11 + i12 - i31 + i32 + i38 + i51 - i52 and i59 <= i2 - i5 + i6 - i9 + i10 - i11 + i12 + i35 + i37 + i38 + i39 - i55 - i57 - i58 and 16i59 <= 16i2 - 16i5 + 16i6 - 16i9 + 16i10 - 16i11 + 16i12 + 15i29 - 15i30 + 16i35 + 16i37 + 16i38 + 16i39 - 16i55 - 16i57 - 16i58 and i10 >= i9 and i12 >= i11 and i6 >= i5 and i30 <= i2 - 17i5 + 17i6 - i9 + i10 - i11 + i12 + i29 and i49 >= i11 - i12 - i31 + i32 + i38 + i42 - i43 and i49 >= i11 - i12 + i38 and i48 >= i9 - i10 - i33 + i34 + i37 + i44 - i45 and i48 >= i9 - i10 + i37 and 16i46 >= 16i5 - 16i6 - i29 + i30 + 16i35 + i40 - i41 and i46 >= i5 - i6 + i35 and i50 >= -i2 + i5 - i6 + i9 - i10 + i11 - i12 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i55 >= -i5 + i6 + i24 and i58 <= -i11 + i12 - i20 + i21 + i27 + i51 - i52 and i58 <= -i11 + i12 + i27 and i57 <= -i9 + i10 - i22 + i23 + i26 + i53 - i54 and i57 <= -i9 + i10 + i26 and i59 <= i2 - i9 + i10 - i11 + i12 + i26 + i27 + i28 - i57 - i58 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51, i52, i53, i54, i55, i56, i57, i58, i59] : i0 = 100000 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 1 and i18 = 1 and i19 = 1 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 and i52 = 0 and i53 = 0 and i54 = 0 and i55 = 0 and i56 = 0 and i57 = 0 and i58 = 0 and i59 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50] : i47 = i7 - i8 + i36 and i8 = i7 and i36 = -i7 + i8 + i25 and i47 = i36 and i36 = i25 and i45 = i4 - i20 - i21 - i22 - i23 - i29 - i30 - i31 - i32 - i33 - i34 - i40 - i41 - i42 - i43 - i44 and i49 = i3 - i24 - i25 - i26 - i27 - i35 - i36 - i37 - i38 - i46 - i47 - i48 and i13 = 100000 - i0 and i12 = i1 - i5 - i6 - i7 - i8 - i9 - i10 - i11 and i19 = 1 + i16 and i18 = 1 + i15 and i17 = 1 + i14 and i47 = i36 and i47 = i36 and i47 = i36 and i49 <= -i31 + i32 + i38 + i42 - i43 and i49 <= i38 and i48 <= -i33 + i34 + i37 + i44 - i45 and i48 <= i37 and 16i46 <= -i29 + i30 + 16i35 + i40 - i41 and i46 <= i35 and i50 <= -i13 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i49 >= -i31 + i32 + i38 + i42 - i43 and i49 >= i38 and i48 >= -i33 + i34 + i37 + i44 - i45 and i48 >= i37 and 16i46 >= -i29 + i30 + 16i35 + i40 - i41 and i46 >= i35 and i50 >= -i15 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and i49 >= -i31 + i32 + i38 + i42 - i43 and i49 >= i38 and i48 >= -i33 + i34 + i37 + i44 - i45 and i48 >= i37 and 16i46 >= -i29 + i30 + 16i35 + i40 - i41 and i46 >= i35 and i50 >= -i16 + i35 + i37 + i38 + i39 - i46 - i48 - i49 and 1024i19 <= 48000 - 1024i17 - 1024i18 and i17 > 0 and i18 > 0 and i19 > 0 and i30 >= i29 and i35 >= i24 and i38 >= -i20 + i21 + i27 + i31 - i32 and i38 >= i27 and i37 >= -i22 + i23 + i26 + i33 - i34 and i37 >= i26 and i39 >= i24 + i26 + i27 + i28 - i35 - i37 - i38 and i49 <= -i31 + i32 + i38 + i42 - i43 and i49 <= i38 and i48 <= -i33 + i34 + i37 + i44 - i45 and i48 <= i37 and 16i46 <= -i29 + i30 + 16i35 + i40 - i41 and i46 <= i35 and i50 <= i35 + i37 + i38 + i39 - i46 - i48 - i49 and i35 <= -i5 + i6 + i24 and i38 <= -i11 + i12 - i20 + i21 + i27 + i31 - i32 and i38 <= -i11 + i12 + i27 and i37 <= -i9 + i10 - i22 + i23 + i26 + i33 - i34 and i37 <= -i9 + i10 + i26 and i39 <= i2 - i5 + i6 - i9 + i10 - i11 + i12 + i24 + i26 + i27 + i28 - i35 - i37 - i38 and i10 >= i9 and i12 >= i11 and i6 >= i5 and i30 <= i2 - 17i5 + 17i6 - i9 + i10 - i11 + i12 + i29 and i49 >= i11 - i12 - i31 + i32 + i38 + i42 - i43 and i49 >= i11 - i12 + i38 and i48 >= i9 - i10 - i33 + i34 + i37 + i44 - i45 and i48 >= i9 - i10 + i37 and 16i46 >= 16i5 - 16i6 - i29 + i30 + 16i35 + i40 - i41 and i46 >= i5 - i6 + i35 and i50 >= -i2 + i5 - i6 + i9 - i10 + i11 - i12 + i35 + i37 + i38 + i39 - i46 - i48 - i49 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50] : i0 = 100000 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 43 and i16 = 0 and i17 = 1 and i18 = 44 and i19 = 1 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 }
sol:
[1,99979,0,21,0,2,0,0,0,0,0,0,0,0,21,0,21,21,1,22,22,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,21,0,1,0,0,0,0,0,0,0,0,0]
added row to overlapping live ranges
[[1,1,1]
 [1,1,1]
 [1,22,22]]
computed band mupa:
[P0, P1, P2, P3] -> [{ RS0_affine_parallel[i0, i1, i2] -> [(0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(21 + i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]
handling array expansion for row 2 of
[[1,1,1]
 [1,1,1]
 [1,22,22]]
setting for member 0
New Schedule:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
child:
  schedule: "[P0, P1, P2, P3] -> [{ RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; RS0_affine_parallel[i0, i1, i2] -> [(i1)] }, { RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; RS0_affine_parallel[i0, i1, i2] -> [(i0)] }]"
  permutable: 1
  coincident: [ 1, 1 ]
  array_expansion: [ [ A_memref_alloca_res_10: 1, A_memref_alloca_res_7: 1, A_memref_alloca_res_4: 1 ], [ A_memref_alloca_res_10: 1, A_memref_alloca_res_7: 1, A_memref_alloca_res_4: 1 ] ]
  child:
    sequence:
    - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
      child:
        schedule: "[P0, P1, P2, P3] -> [{ RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(21 + i3)]; RS0_affine_parallel[i0, i1, i2] -> [(0)] }]"
        permutable: 1
        coincident: [ 1 ]
        array_expansion: [ [ A_memref_alloca_res_10: 22, A_memref_alloca_res_7: 22, A_memref_alloca_res_4: 1 ] ]
        child:
          set:
          - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
            child:
              sequence:
              - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
              - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
          - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
    - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
New Schedule Prepared for GPU:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
child:
  mark: "grid_parallel"
  child:
    schedule: "[P0, P1, P2, P3] -> [{ RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; RS0_affine_parallel[i0, i1, i2] -> [(i1)] }, { RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; RS0_affine_parallel[i0, i1, i2] -> [(i0)] }]"
    permutable: 1
    coincident: [ 1, 1 ]
    array_expansion: [ [ A_memref_alloca_res_10: 1, A_memref_alloca_res_7: 1, A_memref_alloca_res_4: 1 ], [ A_memref_alloca_res_10: 1, A_memref_alloca_res_7: 1, A_memref_alloca_res_4: 1 ] ]
    child:
      sequence:
      - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
        child:
          schedule: "[P0, P1, P2, P3] -> [{ RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(21 + i3)]; RS0_affine_parallel[i0, i1, i2] -> [(0)] }]"
          permutable: 1
          coincident: [ 1 ]
          array_expansion: [ [ A_memref_alloca_res_10: 22, A_memref_alloca_res_7: 22, A_memref_alloca_res_4: 1 ] ]
          child:
            set:
            - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
              child:
                sequence:
                - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
                - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
      - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
New AST:
mark: grid_parallel@0x2
node:
  iterator:
    id: c0
  init:
    val: 0
  cond:
    op: lt
    args:
    - id: c0
    - id: P2@0x4d070540
  inc:
    val: 1
  body:
    iterator:
      id: c1
    init:
      val: 0
    cond:
      op: lt
      args:
      - id: c1
      - id: P3@0x4d070630
    inc:
      val: 1
    body:
    - 
      - user:
          op: call
          args:
          - id: RS0_affine_parallel@0x4d069210
          - id: c1
          - id: c0
          - val: 0
      - iterator:
          id: c2
        init:
          val: 0
        cond:
          op: le
          args:
          - id: c2
          - op: min
            args:
            - val: 20
            - op: fdiv_q
              args:
              - op: sub
                args:
                - id: P0@0x4d057950
                - val: 1
              - val: 16
        inc:
          val: 1
        body:
          user:
            op: call
            args:
            - id: RS1_affine_parallel@0x4d06c7e0
            - id: c1
            - id: c0
            - val: 0
            - id: c2
    - iterator:
        id: c2
      init:
        val: 21
      cond:
        op: le
        args:
        - id: c2
        - op: add
          args:
          - op: fdiv_q
            args:
            - op: sub
              args:
              - id: P0@0x4d057950
              - val: 1
            - val: 16
          - val: 21
      inc:
        val: 1
      body:
      - user:
          op: call
          args:
          - id: RS2_affine_parallel@0x4d082660
          - id: c1
          - id: c0
          - val: 0
          - op: sub
            args:
            - id: c2
            - val: 21
      - guard:
          op: ge
          args:
          - id: P0@0x4d057950
          - op: add
            args:
            - op: mul
              args:
              - val: 16
              - id: c2
            - val: 1
        then:
          user:
            op: call
            args:
            - id: RS1_affine_parallel@0x4d06c7e0
            - id: c1
            - id: c0
            - val: 0
            - id: c2
    - user:
        op: call
        args:
        - id: RS3_affine_parallel@0x4d0823c0
        - id: c1
        - id: c0
        - val: 0
New func:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %5 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %6 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %7 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
  %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
  %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S10_memref_alloca"} : () -> memref<16x16x1xf32, 16>
  %11 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %12 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %13 = "arith.index_cast"(%6) : (index) -> i64
  %14 = "arith.index_cast"(%11) : (i64) -> index
  %15 = "arith.index_cast"(%13) : (i64) -> index
  %16 = "arith.index_cast"(%12) : (i64) -> index
  %17 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %18 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %19 = "arith.index_cast"(%7) : (index) -> i64
  %20 = "arith.index_cast"(%17) : (i64) -> index
  %21 = "arith.index_cast"(%19) : (i64) -> index
  %22 = "arith.index_cast"(%18) : (i64) -> index
  "scf.parallel"(%14, %20, %15, %21, %16, %22) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %23 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %24 = "arith.index_cast"(%5) : (index) -> i64
    %25 = "arith.cmpi"(%24, %23) <{predicate = 5 : i64}> : (i64, i64) -> i1
    "scf.if"(%25) ({
      %87 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %88 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg33: index, %arg34: index, %arg35: index):
        %89 = "affine.vector_load"(%2, %arg34, %arg33, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%89, %8, %arg34, %arg33) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %90 = "affine.vector_load"(%1, %arg34, %arg33, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%90, %9, %arg34, %arg33) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }, {
    }) : (i1) -> ()
    %26 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg30: index, %arg31: index, %arg32: index):
      "affine.store"(%0, %10, %arg30, %arg31, %arg32) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S11_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    %27 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %28 = "arith.constant"() <{value = 20 : i64}> : () -> i64
    %29 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %30 = "arith.index_cast"(%5) : (index) -> i64
    %31 = "arith.subi"(%30, %29) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %32 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %33 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %34 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %35 = "arith.subi"(%31, %32) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %36 = "arith.addi"(%35, %33) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %37 = "arith.cmpi"(%31, %34) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %38 = "arith.select"(%37, %36, %31) : (i1, i64, i64) -> i64
    %39 = "arith.divsi"(%38, %32) : (i64, i64) -> i64
    %40 = "arith.minsi"(%39, %28) : (i64, i64) -> i64
    %41 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %42 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %43 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%27, %43, %41) ({
    ^bb0(%arg26: i64):
      %84 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg27: index, %arg28: index, %arg29: index):
        %85 = "affine.vector_load"(%2, %arg28, %arg27, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%85, %8, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %86 = "affine.vector_load"(%1, %arg28, %arg27, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%86, %9, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %44 = "arith.constant"() <{value = 21 : i64}> : () -> i64
    %45 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %46 = "arith.index_cast"(%5) : (index) -> i64
    %47 = "arith.subi"(%46, %45) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %48 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %49 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %50 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %51 = "arith.subi"(%47, %48) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %52 = "arith.addi"(%51, %49) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %53 = "arith.cmpi"(%47, %50) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %54 = "arith.select"(%53, %52, %47) : (i1, i64, i64) -> i64
    %55 = "arith.divsi"(%54, %48) : (i64, i64) -> i64
    %56 = "arith.constant"() <{value = 21 : i64}> : () -> i64
    %57 = "arith.addi"(%55, %56) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %58 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %59 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %60 = "arith.addi"(%57, %59) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%44, %60, %58) ({
    ^bb0(%arg17: i64):
      %64 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %65 = "arith.constant"() <{value = 21 : i64}> : () -> i64
      %66 = "arith.subi"(%arg17, %65) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg21: index, %arg22: index, %arg23: index):
        %76 = "affine.load"(%10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S18_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
        %77 = "affine.for"(%76) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg24: index, %arg25: f32):
          %78 = "affine.vector_load"(%8, %arg22, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %79 = "llvm.bitcast"(%78) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %80 = "affine.vector_load"(%9, %arg24, %arg21) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %81 = "llvm.bitcast"(%80) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %82 = "llvm.fmul"(%79, %81) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %83 = "llvm.fadd"(%arg25, %82) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%83) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "affine.store"(%77, %10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S27_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S28_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"} : () -> ()
      %67 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %68 = "arith.muli"(%67, %arg17) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %69 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %70 = "arith.addi"(%68, %69) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %71 = "arith.index_cast"(%5) : (index) -> i64
      %72 = "arith.cmpi"(%71, %70) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%72) ({
        %73 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
        ^bb0(%arg18: index, %arg19: index, %arg20: index):
          %74 = "affine.vector_load"(%2, %arg19, %arg18, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%74, %8, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %75 = "affine.vector_load"(%1, %arg19, %arg18, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%75, %9, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
        }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %61 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %62 = "affine.load"(%10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S30_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
      %63 = "llvm.bitcast"(%62) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%63, %3, %arg13, %arg14, %arg15, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S33_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
/scr/ivan/src/transformer-llvm-project/polly/lib/External/isl/isl_ctx.c:295: isl_ctx not freed as some objects still reference it
gpu-affine-opt: After opt:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %5 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %6 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %7 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
  %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
  %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S10_memref_alloca"} : () -> memref<16x16x1xf32, 16>
  %11 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %12 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %13 = "arith.index_cast"(%6) : (index) -> i64
  %14 = "arith.index_cast"(%11) : (i64) -> index
  %15 = "arith.index_cast"(%13) : (i64) -> index
  %16 = "arith.index_cast"(%12) : (i64) -> index
  %17 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %18 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %19 = "arith.index_cast"(%7) : (index) -> i64
  %20 = "arith.index_cast"(%17) : (i64) -> index
  %21 = "arith.index_cast"(%19) : (i64) -> index
  %22 = "arith.index_cast"(%18) : (i64) -> index
  "scf.parallel"(%14, %20, %15, %21, %16, %22) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %23 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %24 = "arith.index_cast"(%5) : (index) -> i64
    %25 = "arith.cmpi"(%24, %23) <{predicate = 5 : i64}> : (i64, i64) -> i1
    "scf.if"(%25) ({
      %87 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %88 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg33: index, %arg34: index, %arg35: index):
        %89 = "affine.vector_load"(%2, %arg34, %arg33, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%89, %8, %arg34, %arg33) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %90 = "affine.vector_load"(%1, %arg34, %arg33, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%90, %9, %arg34, %arg33) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }, {
    }) : (i1) -> ()
    %26 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg30: index, %arg31: index, %arg32: index):
      "affine.store"(%0, %10, %arg30, %arg31, %arg32) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S11_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    %27 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %28 = "arith.constant"() <{value = 20 : i64}> : () -> i64
    %29 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %30 = "arith.index_cast"(%5) : (index) -> i64
    %31 = "arith.subi"(%30, %29) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %32 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %33 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %34 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %35 = "arith.subi"(%31, %32) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %36 = "arith.addi"(%35, %33) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %37 = "arith.cmpi"(%31, %34) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %38 = "arith.select"(%37, %36, %31) : (i1, i64, i64) -> i64
    %39 = "arith.divsi"(%38, %32) : (i64, i64) -> i64
    %40 = "arith.minsi"(%39, %28) : (i64, i64) -> i64
    %41 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %42 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %43 = "arith.addi"(%40, %42) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%27, %43, %41) ({
    ^bb0(%arg26: i64):
      %84 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg27: index, %arg28: index, %arg29: index):
        %85 = "affine.vector_load"(%2, %arg28, %arg27, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%85, %8, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %86 = "affine.vector_load"(%1, %arg28, %arg27, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%86, %9, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %44 = "arith.constant"() <{value = 21 : i64}> : () -> i64
    %45 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %46 = "arith.index_cast"(%5) : (index) -> i64
    %47 = "arith.subi"(%46, %45) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %48 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %49 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %50 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %51 = "arith.subi"(%47, %48) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %52 = "arith.addi"(%51, %49) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %53 = "arith.cmpi"(%47, %50) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %54 = "arith.select"(%53, %52, %47) : (i1, i64, i64) -> i64
    %55 = "arith.divsi"(%54, %48) : (i64, i64) -> i64
    %56 = "arith.constant"() <{value = 21 : i64}> : () -> i64
    %57 = "arith.addi"(%55, %56) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %58 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %59 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %60 = "arith.addi"(%57, %59) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%44, %60, %58) ({
    ^bb0(%arg17: i64):
      %64 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %65 = "arith.constant"() <{value = 21 : i64}> : () -> i64
      %66 = "arith.subi"(%arg17, %65) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg21: index, %arg22: index, %arg23: index):
        %76 = "affine.load"(%10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S18_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
        %77 = "affine.for"(%76) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg24: index, %arg25: f32):
          %78 = "affine.vector_load"(%8, %arg22, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %79 = "llvm.bitcast"(%78) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %80 = "affine.vector_load"(%9, %arg24, %arg21) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %81 = "llvm.bitcast"(%80) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %82 = "llvm.fmul"(%79, %81) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %83 = "llvm.fadd"(%arg25, %82) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%83) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "affine.store"(%77, %10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S27_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S28_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"} : () -> ()
      %67 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %68 = "arith.muli"(%67, %arg17) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %69 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %70 = "arith.addi"(%68, %69) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %71 = "arith.index_cast"(%5) : (index) -> i64
      %72 = "arith.cmpi"(%71, %70) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%72) ({
        %73 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
        ^bb0(%arg18: index, %arg19: index, %arg20: index):
          %74 = "affine.vector_load"(%2, %arg19, %arg18, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%74, %8, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %75 = "affine.vector_load"(%1, %arg19, %arg18, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%75, %9, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
        }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %61 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %62 = "affine.load"(%10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S30_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
      %63 = "llvm.bitcast"(%62) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%63, %3, %arg13, %arg14, %arg15, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S33_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
gpu-affine-opt: After gpuify:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %5 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %6 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %7 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
  %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
  %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S10_memref_alloca"} : () -> memref<16x16x1xf32, 16>
  %11 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %12 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %13 = "arith.index_cast"(%6) : (index) -> i64
  %14 = "arith.index_cast"(%11) : (i64) -> index
  %15 = "arith.index_cast"(%13) : (i64) -> index
  %16 = "arith.index_cast"(%12) : (i64) -> index
  %17 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %18 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %19 = "arith.index_cast"(%7) : (index) -> i64
  %20 = "arith.index_cast"(%17) : (i64) -> index
  %21 = "arith.index_cast"(%19) : (i64) -> index
  %22 = "arith.index_cast"(%18) : (i64) -> index
  "scf.parallel"(%14, %20, %15, %21, %16, %22) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %23 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %24 = "arith.index_cast"(%5) : (index) -> i64
      %25 = "arith.cmpi"(%24, %23) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%25) ({
        %144 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        %145 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        %146 = "affine.vector_load"(%2, %arg15, %arg14, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%146, %8, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %147 = "affine.vector_load"(%1, %arg15, %arg14, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%147, %9, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "nvvm.barrier0"() : () -> ()
      %26 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %27 = "arith.index_cast"(%5) : (index) -> i64
      %28 = "arith.cmpi"(%27, %26) <{predicate = 5 : i64}> : (i64, i64) -> i1
      %29 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.store"(%0, %10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S11_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
      "nvvm.barrier0"() : () -> ()
      %30 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %31 = "arith.constant"() <{value = 20 : i64}> : () -> i64
      %32 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %33 = "arith.index_cast"(%5) : (index) -> i64
      %34 = "arith.subi"(%33, %32) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %35 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %36 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %37 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %38 = "arith.subi"(%34, %35) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %39 = "arith.addi"(%38, %36) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %40 = "arith.cmpi"(%34, %37) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %41 = "arith.select"(%40, %39, %34) : (i1, i64, i64) -> i64
      %42 = "arith.divsi"(%41, %35) : (i64, i64) -> i64
      %43 = "arith.minsi"(%42, %31) : (i64, i64) -> i64
      %44 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %45 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %46 = "arith.addi"(%43, %45) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "scf.for"(%30, %46, %44) ({
      ^bb0(%arg20: i64):
        %141 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        %142 = "affine.vector_load"(%2, %arg15, %arg14, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%142, %8, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %143 = "affine.vector_load"(%1, %arg15, %arg14, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%143, %9, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (i64, i64, i64) -> ()
      "nvvm.barrier0"() : () -> ()
      %47 = "arith.constant"() <{value = 21 : i64}> : () -> i64
      %48 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %49 = "arith.index_cast"(%5) : (index) -> i64
      %50 = "arith.subi"(%49, %48) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %51 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %52 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %53 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %54 = "arith.subi"(%50, %51) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %55 = "arith.addi"(%54, %52) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %56 = "arith.cmpi"(%50, %53) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %57 = "arith.select"(%56, %55, %50) : (i1, i64, i64) -> i64
      %58 = "arith.divsi"(%57, %51) : (i64, i64) -> i64
      %59 = "arith.constant"() <{value = 21 : i64}> : () -> i64
      %60 = "arith.addi"(%58, %59) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %61 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %62 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %63 = "arith.addi"(%60, %62) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "scf.for"(%47, %63, %61) ({
      ^bb0(%arg17: i64):
        %121 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        %122 = "arith.constant"() <{value = 21 : i64}> : () -> i64
        %123 = "arith.subi"(%arg17, %122) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
        %124 = "affine.load"(%10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S18_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
        %125 = "affine.for"(%124) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg18: index, %arg19: f32):
          %135 = "affine.vector_load"(%8, %arg15, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %136 = "llvm.bitcast"(%135) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %137 = "affine.vector_load"(%9, %arg18, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %138 = "llvm.bitcast"(%137) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %139 = "llvm.fmul"(%136, %138) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %140 = "llvm.fadd"(%arg19, %139) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%140) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "affine.store"(%125, %10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S27_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
        "nvvm.barrier0"() : () -> ()
        %126 = "arith.constant"() <{value = 16 : i64}> : () -> i64
        %127 = "arith.muli"(%126, %arg17) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
        %128 = "arith.constant"() <{value = 1 : i64}> : () -> i64
        %129 = "arith.addi"(%127, %128) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
        %130 = "arith.index_cast"(%5) : (index) -> i64
        %131 = "arith.cmpi"(%130, %129) <{predicate = 5 : i64}> : (i64, i64) -> i1
        "scf.if"(%131) ({
          %132 = "arith.constant"() <{value = 0 : i64}> : () -> i64
          %133 = "affine.vector_load"(%2, %arg15, %arg14, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%133, %8, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %134 = "affine.vector_load"(%1, %arg15, %arg14, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%134, %9, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "scf.yield"() : () -> ()
        }, {
        }) : (i1) -> ()
        "scf.yield"() : () -> ()
      }) : (i64, i64, i64) -> ()
      "nvvm.barrier0"() : () -> ()
      %64 = "arith.constant"() <{value = 21 : i64}> : () -> i64
      %65 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %66 = "arith.index_cast"(%5) : (index) -> i64
      %67 = "arith.subi"(%66, %65) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %68 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %69 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %70 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %71 = "arith.subi"(%67, %68) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %72 = "arith.addi"(%71, %69) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %73 = "arith.cmpi"(%67, %70) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %74 = "arith.select"(%73, %72, %67) : (i1, i64, i64) -> i64
      %75 = "arith.divsi"(%74, %68) : (i64, i64) -> i64
      %76 = "arith.constant"() <{value = 21 : i64}> : () -> i64
      %77 = "arith.addi"(%75, %76) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %78 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %79 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %80 = "arith.addi"(%77, %79) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %81 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %82 = "arith.index_cast"(%5) : (index) -> i64
      %83 = "arith.cmpi"(%82, %81) <{predicate = 5 : i64}> : (i64, i64) -> i1
      %84 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %85 = "arith.constant"() <{value = 20 : i64}> : () -> i64
      %86 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %87 = "arith.index_cast"(%5) : (index) -> i64
      %88 = "arith.subi"(%87, %86) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %89 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %90 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %91 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %92 = "arith.subi"(%88, %89) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %93 = "arith.addi"(%92, %90) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %94 = "arith.cmpi"(%88, %91) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %95 = "arith.select"(%94, %93, %88) : (i1, i64, i64) -> i64
      %96 = "arith.divsi"(%95, %89) : (i64, i64) -> i64
      %97 = "arith.minsi"(%96, %85) : (i64, i64) -> i64
      %98 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %99 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %100 = "arith.addi"(%97, %99) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %101 = "arith.constant"() <{value = 21 : i64}> : () -> i64
      %102 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %103 = "arith.index_cast"(%5) : (index) -> i64
      %104 = "arith.subi"(%103, %102) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %105 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %106 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %107 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %108 = "arith.subi"(%104, %105) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %109 = "arith.addi"(%108, %106) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %110 = "arith.cmpi"(%104, %107) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %111 = "arith.select"(%110, %109, %104) : (i1, i64, i64) -> i64
      %112 = "arith.divsi"(%111, %105) : (i64, i64) -> i64
      %113 = "arith.constant"() <{value = 21 : i64}> : () -> i64
      %114 = "arith.addi"(%112, %113) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %115 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %116 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %117 = "arith.addi"(%114, %116) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %118 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %119 = "affine.load"(%10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S30_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
      %120 = "llvm.bitcast"(%119) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%120, %3, %arg13, %arg14, %arg15, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() : () -> ()
    }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
gpu-affine-opt: After rar:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 1 : index}> : () -> index
  %1 = "arith.constant"() <{value = 0 : index}> : () -> index
  %2 = "arith.constant"() <{value = 21 : i64}> : () -> i64
  %3 = "arith.constant"() <{value = 16 : i64}> : () -> i64
  %4 = "arith.constant"() <{value = 20 : i64}> : () -> i64
  %5 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %6 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %7 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %8 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %9 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %10 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %11 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %12 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %13 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %14 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %15 = "arith.index_cast"(%13) : (index) -> i64
  %16 = "arith.index_cast"(%15) : (i64) -> index
  %17 = "arith.index_cast"(%14) : (index) -> i64
  %18 = "arith.index_cast"(%17) : (i64) -> index
  "scf.parallel"(%1, %1, %16, %18, %0, %0) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %19 = "memref.get_global"() <{name = @shared_mem_1}> : () -> memref<1024xi8, 3>
    %20 = "memref.get_global"() <{name = @shared_mem_0}> : () -> memref<1024xi8, 3>
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %21 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<f32>
      %22 = "arith.index_cast"(%12) : (index) -> i64
      %23 = "arith.cmpi"(%22, %5) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%23) ({
        %60 = "affine.vector_load"(%9, %arg15, %arg14, %arg13, %arg12, %12) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%60, %19, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %61 = "affine.vector_load"(%8, %arg15, %arg14, %arg12, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%61, %20, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "nvvm.barrier0"() : () -> ()
      "memref.store"(%7, %21) <{nontemporal = false}> : (f32, memref<f32>) -> ()
      "nvvm.barrier0"() : () -> ()
      %24 = "arith.index_cast"(%12) : (index) -> i64
      %25 = "arith.subi"(%24, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %26 = "arith.subi"(%25, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %27 = "arith.addi"(%26, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %28 = "arith.cmpi"(%25, %6) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %29 = "arith.select"(%28, %27, %25) : (i1, i64, i64) -> i64
      %30 = "arith.divsi"(%29, %3) : (i64, i64) -> i64
      %31 = "arith.minsi"(%30, %4) : (i64, i64) -> i64
      %32 = "arith.addi"(%31, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "scf.for"(%5, %32, %5) ({
      ^bb0(%arg20: i64):
        %58 = "affine.vector_load"(%9, %arg15, %arg14, %arg13, %arg12, %12) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%58, %19, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %59 = "affine.vector_load"(%8, %arg15, %arg14, %arg12, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%59, %20, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (i64, i64, i64) -> ()
      "nvvm.barrier0"() : () -> ()
      %33 = "arith.index_cast"(%12) : (index) -> i64
      %34 = "arith.subi"(%33, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %35 = "arith.subi"(%34, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %36 = "arith.addi"(%35, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %37 = "arith.cmpi"(%34, %6) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %38 = "arith.select"(%37, %36, %34) : (i1, i64, i64) -> i64
      %39 = "arith.divsi"(%38, %3) : (i64, i64) -> i64
      %40 = "arith.addi"(%39, %2) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %41 = "arith.addi"(%40, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "scf.for"(%2, %41, %5) ({
      ^bb0(%arg17: i64):
        %44 = "memref.load"(%21) <{nontemporal = false}> : (memref<f32>) -> f32
        %45 = "affine.for"(%44) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg18: index, %arg19: f32):
          %52 = "affine.vector_load"(%19, %arg15, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %53 = "llvm.bitcast"(%52) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %54 = "affine.vector_load"(%20, %arg18, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %55 = "llvm.bitcast"(%54) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %56 = "llvm.fmul"(%53, %55) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %57 = "llvm.fadd"(%arg19, %56) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%57) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "memref.store"(%45, %21) <{nontemporal = false}> : (f32, memref<f32>) -> ()
        "nvvm.barrier0"() : () -> ()
        %46 = "arith.muli"(%arg17, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
        %47 = "arith.addi"(%46, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
        %48 = "arith.index_cast"(%12) : (index) -> i64
        %49 = "arith.cmpi"(%48, %47) <{predicate = 5 : i64}> : (i64, i64) -> i1
        "scf.if"(%49) ({
          %50 = "affine.vector_load"(%9, %arg15, %arg14, %arg13, %arg12, %12) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%50, %19, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %51 = "affine.vector_load"(%8, %arg15, %arg14, %arg12, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%51, %20, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "scf.yield"() : () -> ()
        }, {
        }) : (i1) -> ()
        "scf.yield"() : () -> ()
      }) : (i64, i64, i64) -> ()
      "nvvm.barrier0"() : () -> ()
      %42 = "memref.load"(%21) <{nontemporal = false}> : (memref<f32>) -> f32
      %43 = "llvm.bitcast"(%42) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%43, %10, %arg13, %arg14, %arg15, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() : () -> ()
    }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
gpu-affine-opt: After lower affine:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c21_i64 = arith.constant 21 : i64
  %c16_i64 = arith.constant 16 : i64
  %c20_i64 = arith.constant 20 : i64
  %c1_i64 = arith.constant 1 : i64
  %c0_i64 = arith.constant 0 : i64
  %0 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 {polymer.stmt.name = "S4_arith_index_cast"} : i32 to index
  %5 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
  %6 = arith.index_cast %arg1 {polymer.stmt.name = "S6_arith_index_cast"} : i64 to index
  %7 = arith.index_cast %arg0 {polymer.stmt.name = "S7_arith_index_cast"} : i64 to index
  %8 = arith.index_cast %6 : index to i64
  %9 = arith.index_cast %8 : i64 to index
  %10 = arith.index_cast %7 : index to i64
  %11 = arith.index_cast %10 : i64 to index
  scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%9, %11) step (%c1, %c1) {
    %12 = memref.get_global @shared_mem_1 : memref<1024xi8, 3>
    %13 = memref.get_global @shared_mem_0 : memref<1024xi8, 3>
    %c0_0 = arith.constant 0 : index
    %c16 = arith.constant 16 : index
    %c0_1 = arith.constant 0 : index
    %c16_2 = arith.constant 16 : index
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %c1_5 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    scf.parallel (%arg14, %arg15, %arg16) = (%c0_0, %c0_1, %c0_3) to (%c16, %c16_2, %c1_4) step (%c1_5, %c1_6, %c1_7) {
      %alloca = memref.alloca() : memref<f32>
      %14 = arith.index_cast %5 : index to i64
      %15 = arith.cmpi sge, %14, %c1_i64 : i64
      scf.if %15 {
        %46 = arith.muli %arg15, %5 : index
        %c4_11 = arith.constant 4 : index
        %47 = arith.muli %46, %c4_11 : index
        %c4_12 = arith.constant 4 : index
        %48 = arith.muli %arg14, %c4_12 : index
        %49 = arith.addi %47, %48 : index
        %c64_13 = arith.constant 64 : index
        %50 = arith.muli %arg12, %c64_13 : index
        %51 = arith.addi %49, %50 : index
        %c16_14 = arith.constant 16 : index
        %52 = arith.muli %5, %c16_14 : index
        %53 = arith.muli %arg13, %52 : index
        %c4_15 = arith.constant 4 : index
        %54 = arith.muli %53, %c4_15 : index
        %55 = arith.addi %51, %54 : index
        %56 = vector.load %2[%55] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        %c64_16 = arith.constant 64 : index
        %57 = arith.muli %arg15, %c64_16 : index
        %c4_17 = arith.constant 4 : index
        %58 = arith.muli %arg14, %c4_17 : index
        %59 = arith.addi %57, %58 : index
        vector.store %56, %12[%59] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        %60 = arith.muli %arg15, %4 : index
        %c4_18 = arith.constant 4 : index
        %61 = arith.muli %60, %c4_18 : index
        %c4_19 = arith.constant 4 : index
        %62 = arith.muli %arg14, %c4_19 : index
        %63 = arith.addi %61, %62 : index
        %c64_20 = arith.constant 64 : index
        %64 = arith.muli %arg13, %c64_20 : index
        %65 = arith.addi %63, %64 : index
        %c16_21 = arith.constant 16 : index
        %66 = arith.muli %4, %c16_21 : index
        %67 = arith.muli %arg12, %66 : index
        %c4_22 = arith.constant 4 : index
        %68 = arith.muli %67, %c4_22 : index
        %69 = arith.addi %65, %68 : index
        %70 = vector.load %1[%69] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        %c64_23 = arith.constant 64 : index
        %71 = arith.muli %arg15, %c64_23 : index
        %c4_24 = arith.constant 4 : index
        %72 = arith.muli %arg14, %c4_24 : index
        %73 = arith.addi %71, %72 : index
        vector.store %70, %13[%73] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
      }
      nvvm.barrier0
      memref.store %0, %alloca[] : memref<f32>
      nvvm.barrier0
      %16 = arith.index_cast %5 : index to i64
      %17 = arith.subi %16, %c1_i64 : i64
      %18 = arith.subi %17, %c16_i64 : i64
      %19 = arith.addi %18, %c1_i64 : i64
      %20 = arith.cmpi slt, %17, %c0_i64 : i64
      %21 = arith.select %20, %19, %17 : i64
      %22 = arith.divsi %21, %c16_i64 : i64
      %23 = arith.minsi %22, %c20_i64 : i64
      %24 = arith.addi %23, %c1_i64 : i64
      scf.for %arg17 = %c1_i64 to %24 step %c1_i64  : i64 {
        %46 = arith.muli %arg15, %5 : index
        %c4_11 = arith.constant 4 : index
        %47 = arith.muli %46, %c4_11 : index
        %c4_12 = arith.constant 4 : index
        %48 = arith.muli %arg14, %c4_12 : index
        %49 = arith.addi %47, %48 : index
        %c64_13 = arith.constant 64 : index
        %50 = arith.muli %arg12, %c64_13 : index
        %51 = arith.addi %49, %50 : index
        %c16_14 = arith.constant 16 : index
        %52 = arith.muli %5, %c16_14 : index
        %53 = arith.muli %arg13, %52 : index
        %c4_15 = arith.constant 4 : index
        %54 = arith.muli %53, %c4_15 : index
        %55 = arith.addi %51, %54 : index
        %56 = vector.load %2[%55] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        %c64_16 = arith.constant 64 : index
        %57 = arith.muli %arg15, %c64_16 : index
        %c4_17 = arith.constant 4 : index
        %58 = arith.muli %arg14, %c4_17 : index
        %59 = arith.addi %57, %58 : index
        vector.store %56, %12[%59] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        %60 = arith.muli %arg15, %4 : index
        %c4_18 = arith.constant 4 : index
        %61 = arith.muli %60, %c4_18 : index
        %c4_19 = arith.constant 4 : index
        %62 = arith.muli %arg14, %c4_19 : index
        %63 = arith.addi %61, %62 : index
        %c64_20 = arith.constant 64 : index
        %64 = arith.muli %arg13, %c64_20 : index
        %65 = arith.addi %63, %64 : index
        %c16_21 = arith.constant 16 : index
        %66 = arith.muli %4, %c16_21 : index
        %67 = arith.muli %arg12, %66 : index
        %c4_22 = arith.constant 4 : index
        %68 = arith.muli %67, %c4_22 : index
        %69 = arith.addi %65, %68 : index
        %70 = vector.load %1[%69] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        %c64_23 = arith.constant 64 : index
        %71 = arith.muli %arg15, %c64_23 : index
        %c4_24 = arith.constant 4 : index
        %72 = arith.muli %arg14, %c4_24 : index
        %73 = arith.addi %71, %72 : index
        vector.store %70, %13[%73] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
      }
      nvvm.barrier0
      %25 = arith.index_cast %5 : index to i64
      %26 = arith.subi %25, %c1_i64 : i64
      %27 = arith.subi %26, %c16_i64 : i64
      %28 = arith.addi %27, %c1_i64 : i64
      %29 = arith.cmpi slt, %26, %c0_i64 : i64
      %30 = arith.select %29, %28, %26 : i64
      %31 = arith.divsi %30, %c16_i64 : i64
      %32 = arith.addi %31, %c21_i64 : i64
      %33 = arith.addi %32, %c1_i64 : i64
      scf.for %arg17 = %c21_i64 to %33 step %c1_i64  : i64 {
        %46 = memref.load %alloca[] : memref<f32>
        %c0_11 = arith.constant 0 : index
        %c16_12 = arith.constant 16 : index
        %c1_13 = arith.constant 1 : index
        %47 = scf.for %arg18 = %c0_11 to %c16_12 step %c1_13 iter_args(%arg19 = %46) -> (f32) {
          %c64_14 = arith.constant 64 : index
          %52 = arith.muli %arg15, %c64_14 : index
          %c4_15 = arith.constant 4 : index
          %53 = arith.muli %arg18, %c4_15 : index
          %54 = arith.addi %52, %53 : index
          %55 = vector.load %12[%54] {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
          %56 = llvm.bitcast %55 {polymer.stmt.name = "S21_llvm_bitcast"} : vector<4xi8> to f32
          %c64_16 = arith.constant 64 : index
          %57 = arith.muli %arg18, %c64_16 : index
          %c4_17 = arith.constant 4 : index
          %58 = arith.muli %arg14, %c4_17 : index
          %59 = arith.addi %57, %58 : index
          %60 = vector.load %13[%59] {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
          %61 = llvm.bitcast %60 {polymer.stmt.name = "S23_llvm_bitcast"} : vector<4xi8> to f32
          %62 = llvm.fmul %56, %61  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
          %63 = llvm.fadd %arg19, %62  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
          scf.yield %63 : f32
        }
        memref.store %47, %alloca[] : memref<f32>
        nvvm.barrier0
        %48 = arith.muli %arg17, %c16_i64 : i64
        %49 = arith.addi %48, %c1_i64 : i64
        %50 = arith.index_cast %5 : index to i64
        %51 = arith.cmpi sge, %50, %49 : i64
        scf.if %51 {
          %52 = arith.muli %arg15, %5 : index
          %c4_14 = arith.constant 4 : index
          %53 = arith.muli %52, %c4_14 : index
          %c4_15 = arith.constant 4 : index
          %54 = arith.muli %arg14, %c4_15 : index
          %55 = arith.addi %53, %54 : index
          %c64_16 = arith.constant 64 : index
          %56 = arith.muli %arg12, %c64_16 : index
          %57 = arith.addi %55, %56 : index
          %c16_17 = arith.constant 16 : index
          %58 = arith.muli %5, %c16_17 : index
          %59 = arith.muli %arg13, %58 : index
          %c4_18 = arith.constant 4 : index
          %60 = arith.muli %59, %c4_18 : index
          %61 = arith.addi %57, %60 : index
          %62 = vector.load %2[%61] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
          %c64_19 = arith.constant 64 : index
          %63 = arith.muli %arg15, %c64_19 : index
          %c4_20 = arith.constant 4 : index
          %64 = arith.muli %arg14, %c4_20 : index
          %65 = arith.addi %63, %64 : index
          vector.store %62, %12[%65] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
          %66 = arith.muli %arg15, %4 : index
          %c4_21 = arith.constant 4 : index
          %67 = arith.muli %66, %c4_21 : index
          %c4_22 = arith.constant 4 : index
          %68 = arith.muli %arg14, %c4_22 : index
          %69 = arith.addi %67, %68 : index
          %c64_23 = arith.constant 64 : index
          %70 = arith.muli %arg13, %c64_23 : index
          %71 = arith.addi %69, %70 : index
          %c16_24 = arith.constant 16 : index
          %72 = arith.muli %4, %c16_24 : index
          %73 = arith.muli %arg12, %72 : index
          %c4_25 = arith.constant 4 : index
          %74 = arith.muli %73, %c4_25 : index
          %75 = arith.addi %71, %74 : index
          %76 = vector.load %1[%75] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
          %c64_26 = arith.constant 64 : index
          %77 = arith.muli %arg15, %c64_26 : index
          %c4_27 = arith.constant 4 : index
          %78 = arith.muli %arg14, %c4_27 : index
          %79 = arith.addi %77, %78 : index
          vector.store %76, %13[%79] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        }
      }
      nvvm.barrier0
      %34 = memref.load %alloca[] : memref<f32>
      %35 = llvm.bitcast %34 {polymer.stmt.name = "S31_llvm_bitcast"} : f32 to vector<4xi8>
      %c64 = arith.constant 64 : index
      %36 = arith.muli %arg13, %c64 : index
      %c4 = arith.constant 4 : index
      %37 = arith.muli %arg14, %c4 : index
      %38 = arith.addi %36, %37 : index
      %39 = arith.muli %arg15, %4 : index
      %c4_8 = arith.constant 4 : index
      %40 = arith.muli %39, %c4_8 : index
      %41 = arith.addi %38, %40 : index
      %c16_9 = arith.constant 16 : index
      %42 = arith.muli %4, %c16_9 : index
      %43 = arith.muli %arg13, %42 : index
      %c4_10 = arith.constant 4 : index
      %44 = arith.muli %43, %c4_10 : index
      %45 = arith.addi %41, %44 : index
      vector.store %35, %3[%45] {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : memref<?xi8>, vector<4xi8>
      scf.reduce 
    } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
    scf.reduce 
  } {gpu.par.grid}
  llvm.return {polymer.stmt.name = "S35_llvm_return"}
}
gpu-affine-opt: After lower accesses:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c21_i64 = arith.constant 21 : i64
  %c16_i64 = arith.constant 16 : i64
  %c20_i64 = arith.constant 20 : i64
  %c1_i64 = arith.constant 1 : i64
  %c0_i64 = arith.constant 0 : i64
  %0 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
  %1 = arith.index_cast %arg11 {polymer.stmt.name = "S4_arith_index_cast"} : i32 to index
  %2 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
  %3 = arith.index_cast %arg1 {polymer.stmt.name = "S6_arith_index_cast"} : i64 to index
  %4 = arith.index_cast %arg0 {polymer.stmt.name = "S7_arith_index_cast"} : i64 to index
  %5 = arith.index_cast %3 : index to i64
  %6 = arith.index_cast %5 : i64 to index
  %7 = arith.index_cast %4 : index to i64
  %8 = arith.index_cast %7 : i64 to index
  scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%6, %8) step (%c1, %c1) {
    %9 = llvm.mlir.addressof @shared_mem_1 : !llvm.ptr<3>
    %10 = llvm.mlir.addressof @shared_mem_0 : !llvm.ptr<3>
    %c0_0 = arith.constant 0 : index
    %c16 = arith.constant 16 : index
    %c0_1 = arith.constant 0 : index
    %c16_2 = arith.constant 16 : index
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %c1_5 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    scf.parallel (%arg14, %arg15, %arg16) = (%c0_0, %c0_1, %c0_3) to (%c16, %c16_2, %c1_4) step (%c1_5, %c1_6, %c1_7) {
      %11 = llvm.mlir.constant(1 : index) : i64
      %12 = llvm.alloca %11 x f32 : (i64) -> !llvm.ptr
      %13 = arith.index_cast %2 : index to i64
      %14 = arith.cmpi sge, %13, %c1_i64 : i64
      scf.if %14 {
        %48 = arith.muli %arg15, %2 : index
        %c4_11 = arith.constant 4 : index
        %49 = arith.muli %48, %c4_11 : index
        %c4_12 = arith.constant 4 : index
        %50 = arith.muli %arg14, %c4_12 : index
        %51 = arith.addi %49, %50 : index
        %c64_13 = arith.constant 64 : index
        %52 = arith.muli %arg12, %c64_13 : index
        %53 = arith.addi %51, %52 : index
        %c16_14 = arith.constant 16 : index
        %54 = arith.muli %2, %c16_14 : index
        %55 = arith.muli %arg13, %54 : index
        %c4_15 = arith.constant 4 : index
        %56 = arith.muli %55, %c4_15 : index
        %57 = arith.addi %53, %56 : index
        %58 = llvm.load %arg8 : !llvm.ptr -> f32
        %59 = llvm.bitcast %58 : f32 to vector<4xi8>
        %c64_16 = arith.constant 64 : index
        %60 = arith.muli %arg15, %c64_16 : index
        %c4_17 = arith.constant 4 : index
        %61 = arith.muli %arg14, %c4_17 : index
        %62 = arith.addi %60, %61 : index
        %63 = llvm.bitcast %59 : vector<4xi8> to f32
        llvm.store %63, %9 : f32, !llvm.ptr<3>
        %64 = arith.muli %arg15, %1 : index
        %c4_18 = arith.constant 4 : index
        %65 = arith.muli %64, %c4_18 : index
        %c4_19 = arith.constant 4 : index
        %66 = arith.muli %arg14, %c4_19 : index
        %67 = arith.addi %65, %66 : index
        %c64_20 = arith.constant 64 : index
        %68 = arith.muli %arg13, %c64_20 : index
        %69 = arith.addi %67, %68 : index
        %c16_21 = arith.constant 16 : index
        %70 = arith.muli %1, %c16_21 : index
        %71 = arith.muli %arg12, %70 : index
        %c4_22 = arith.constant 4 : index
        %72 = arith.muli %71, %c4_22 : index
        %73 = arith.addi %69, %72 : index
        %74 = llvm.load %arg9 : !llvm.ptr -> f32
        %75 = llvm.bitcast %74 : f32 to vector<4xi8>
        %c64_23 = arith.constant 64 : index
        %76 = arith.muli %arg15, %c64_23 : index
        %c4_24 = arith.constant 4 : index
        %77 = arith.muli %arg14, %c4_24 : index
        %78 = arith.addi %76, %77 : index
        %79 = llvm.bitcast %75 : vector<4xi8> to f32
        llvm.store %79, %10 : f32, !llvm.ptr<3>
      }
      nvvm.barrier0
      %15 = llvm.getelementptr %12[] : (!llvm.ptr) -> !llvm.ptr, f32
      llvm.store %0, %15 : f32, !llvm.ptr
      nvvm.barrier0
      %16 = arith.index_cast %2 : index to i64
      %17 = arith.subi %16, %c1_i64 : i64
      %18 = arith.subi %17, %c16_i64 : i64
      %19 = arith.addi %18, %c1_i64 : i64
      %20 = arith.cmpi slt, %17, %c0_i64 : i64
      %21 = arith.select %20, %19, %17 : i64
      %22 = arith.divsi %21, %c16_i64 : i64
      %23 = arith.minsi %22, %c20_i64 : i64
      %24 = arith.addi %23, %c1_i64 : i64
      scf.for %arg17 = %c1_i64 to %24 step %c1_i64  : i64 {
        %48 = arith.muli %arg15, %2 : index
        %c4_11 = arith.constant 4 : index
        %49 = arith.muli %48, %c4_11 : index
        %c4_12 = arith.constant 4 : index
        %50 = arith.muli %arg14, %c4_12 : index
        %51 = arith.addi %49, %50 : index
        %c64_13 = arith.constant 64 : index
        %52 = arith.muli %arg12, %c64_13 : index
        %53 = arith.addi %51, %52 : index
        %c16_14 = arith.constant 16 : index
        %54 = arith.muli %2, %c16_14 : index
        %55 = arith.muli %arg13, %54 : index
        %c4_15 = arith.constant 4 : index
        %56 = arith.muli %55, %c4_15 : index
        %57 = arith.addi %53, %56 : index
        %58 = llvm.load %arg8 : !llvm.ptr -> f32
        %59 = llvm.bitcast %58 : f32 to vector<4xi8>
        %c64_16 = arith.constant 64 : index
        %60 = arith.muli %arg15, %c64_16 : index
        %c4_17 = arith.constant 4 : index
        %61 = arith.muli %arg14, %c4_17 : index
        %62 = arith.addi %60, %61 : index
        %63 = llvm.bitcast %59 : vector<4xi8> to f32
        llvm.store %63, %9 : f32, !llvm.ptr<3>
        %64 = arith.muli %arg15, %1 : index
        %c4_18 = arith.constant 4 : index
        %65 = arith.muli %64, %c4_18 : index
        %c4_19 = arith.constant 4 : index
        %66 = arith.muli %arg14, %c4_19 : index
        %67 = arith.addi %65, %66 : index
        %c64_20 = arith.constant 64 : index
        %68 = arith.muli %arg13, %c64_20 : index
        %69 = arith.addi %67, %68 : index
        %c16_21 = arith.constant 16 : index
        %70 = arith.muli %1, %c16_21 : index
        %71 = arith.muli %arg12, %70 : index
        %c4_22 = arith.constant 4 : index
        %72 = arith.muli %71, %c4_22 : index
        %73 = arith.addi %69, %72 : index
        %74 = llvm.load %arg9 : !llvm.ptr -> f32
        %75 = llvm.bitcast %74 : f32 to vector<4xi8>
        %c64_23 = arith.constant 64 : index
        %76 = arith.muli %arg15, %c64_23 : index
        %c4_24 = arith.constant 4 : index
        %77 = arith.muli %arg14, %c4_24 : index
        %78 = arith.addi %76, %77 : index
        %79 = llvm.bitcast %75 : vector<4xi8> to f32
        llvm.store %79, %10 : f32, !llvm.ptr<3>
      }
      nvvm.barrier0
      %25 = arith.index_cast %2 : index to i64
      %26 = arith.subi %25, %c1_i64 : i64
      %27 = arith.subi %26, %c16_i64 : i64
      %28 = arith.addi %27, %c1_i64 : i64
      %29 = arith.cmpi slt, %26, %c0_i64 : i64
      %30 = arith.select %29, %28, %26 : i64
      %31 = arith.divsi %30, %c16_i64 : i64
      %32 = arith.addi %31, %c21_i64 : i64
      %33 = arith.addi %32, %c1_i64 : i64
      scf.for %arg17 = %c21_i64 to %33 step %c1_i64  : i64 {
        %48 = llvm.getelementptr %12[] : (!llvm.ptr) -> !llvm.ptr, f32
        %49 = llvm.load %48 : !llvm.ptr -> f32
        %c0_11 = arith.constant 0 : index
        %c16_12 = arith.constant 16 : index
        %c1_13 = arith.constant 1 : index
        %50 = scf.for %arg18 = %c0_11 to %c16_12 step %c1_13 iter_args(%arg19 = %49) -> (f32) {
          %c64_14 = arith.constant 64 : index
          %56 = arith.muli %arg15, %c64_14 : index
          %c4_15 = arith.constant 4 : index
          %57 = arith.muli %arg18, %c4_15 : index
          %58 = arith.addi %56, %57 : index
          %59 = llvm.load %9 : !llvm.ptr<3> -> f32
          %60 = llvm.bitcast %59 : f32 to vector<4xi8>
          %61 = llvm.bitcast %60 {polymer.stmt.name = "S21_llvm_bitcast"} : vector<4xi8> to f32
          %c64_16 = arith.constant 64 : index
          %62 = arith.muli %arg18, %c64_16 : index
          %c4_17 = arith.constant 4 : index
          %63 = arith.muli %arg14, %c4_17 : index
          %64 = arith.addi %62, %63 : index
          %65 = llvm.load %10 : !llvm.ptr<3> -> f32
          %66 = llvm.bitcast %65 : f32 to vector<4xi8>
          %67 = llvm.bitcast %66 {polymer.stmt.name = "S23_llvm_bitcast"} : vector<4xi8> to f32
          %68 = llvm.fmul %61, %67  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
          %69 = llvm.fadd %arg19, %68  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
          scf.yield %69 : f32
        }
        %51 = llvm.getelementptr %12[] : (!llvm.ptr) -> !llvm.ptr, f32
        llvm.store %50, %51 : f32, !llvm.ptr
        nvvm.barrier0
        %52 = arith.muli %arg17, %c16_i64 : i64
        %53 = arith.addi %52, %c1_i64 : i64
        %54 = arith.index_cast %2 : index to i64
        %55 = arith.cmpi sge, %54, %53 : i64
        scf.if %55 {
          %56 = arith.muli %arg15, %2 : index
          %c4_14 = arith.constant 4 : index
          %57 = arith.muli %56, %c4_14 : index
          %c4_15 = arith.constant 4 : index
          %58 = arith.muli %arg14, %c4_15 : index
          %59 = arith.addi %57, %58 : index
          %c64_16 = arith.constant 64 : index
          %60 = arith.muli %arg12, %c64_16 : index
          %61 = arith.addi %59, %60 : index
          %c16_17 = arith.constant 16 : index
          %62 = arith.muli %2, %c16_17 : index
          %63 = arith.muli %arg13, %62 : index
          %c4_18 = arith.constant 4 : index
          %64 = arith.muli %63, %c4_18 : index
          %65 = arith.addi %61, %64 : index
          %66 = llvm.load %arg8 : !llvm.ptr -> f32
          %67 = llvm.bitcast %66 : f32 to vector<4xi8>
          %c64_19 = arith.constant 64 : index
          %68 = arith.muli %arg15, %c64_19 : index
          %c4_20 = arith.constant 4 : index
          %69 = arith.muli %arg14, %c4_20 : index
          %70 = arith.addi %68, %69 : index
          %71 = llvm.bitcast %67 : vector<4xi8> to f32
          llvm.store %71, %9 : f32, !llvm.ptr<3>
          %72 = arith.muli %arg15, %1 : index
          %c4_21 = arith.constant 4 : index
          %73 = arith.muli %72, %c4_21 : index
          %c4_22 = arith.constant 4 : index
          %74 = arith.muli %arg14, %c4_22 : index
          %75 = arith.addi %73, %74 : index
          %c64_23 = arith.constant 64 : index
          %76 = arith.muli %arg13, %c64_23 : index
          %77 = arith.addi %75, %76 : index
          %c16_24 = arith.constant 16 : index
          %78 = arith.muli %1, %c16_24 : index
          %79 = arith.muli %arg12, %78 : index
          %c4_25 = arith.constant 4 : index
          %80 = arith.muli %79, %c4_25 : index
          %81 = arith.addi %77, %80 : index
          %82 = llvm.load %arg9 : !llvm.ptr -> f32
          %83 = llvm.bitcast %82 : f32 to vector<4xi8>
          %c64_26 = arith.constant 64 : index
          %84 = arith.muli %arg15, %c64_26 : index
          %c4_27 = arith.constant 4 : index
          %85 = arith.muli %arg14, %c4_27 : index
          %86 = arith.addi %84, %85 : index
          %87 = llvm.bitcast %83 : vector<4xi8> to f32
          llvm.store %87, %10 : f32, !llvm.ptr<3>
        }
      }
      nvvm.barrier0
      %34 = llvm.getelementptr %12[] : (!llvm.ptr) -> !llvm.ptr, f32
      %35 = llvm.load %34 : !llvm.ptr -> f32
      %36 = llvm.bitcast %35 {polymer.stmt.name = "S31_llvm_bitcast"} : f32 to vector<4xi8>
      %c64 = arith.constant 64 : index
      %37 = arith.muli %arg13, %c64 : index
      %c4 = arith.constant 4 : index
      %38 = arith.muli %arg14, %c4 : index
      %39 = arith.addi %37, %38 : index
      %40 = arith.muli %arg15, %1 : index
      %c4_8 = arith.constant 4 : index
      %41 = arith.muli %40, %c4_8 : index
      %42 = arith.addi %39, %41 : index
      %c16_9 = arith.constant 16 : index
      %43 = arith.muli %1, %c16_9 : index
      %44 = arith.muli %arg13, %43 : index
      %c4_10 = arith.constant 4 : index
      %45 = arith.muli %44, %c4_10 : index
      %46 = arith.addi %42, %45 : index
      %47 = llvm.bitcast %36 : vector<4xi8> to f32
      llvm.store %47, %arg7 : f32, !llvm.ptr
      scf.reduce 
    } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
    scf.reduce 
  } {gpu.par.grid}
  llvm.return {polymer.stmt.name = "S35_llvm_return"}
}
gpu-affine-opt: Canonicalized:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c22_i64 = arith.constant 22 : i64
  %c-16_i64 = arith.constant -16 : i64
  %0 = llvm.mlir.constant(1 : index) : i64
  %c16 = arith.constant 16 : index
  %1 = llvm.mlir.addressof @shared_mem_0 : !llvm.ptr<3>
  %2 = llvm.mlir.addressof @shared_mem_1 : !llvm.ptr<3>
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c21_i64 = arith.constant 21 : i64
  %c16_i64 = arith.constant 16 : i64
  %c20_i64 = arith.constant 20 : i64
  %c1_i64 = arith.constant 1 : i64
  %c0_i64 = arith.constant 0 : i64
  %3 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
  %4 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
  %5 = arith.index_cast %arg1 : i64 to index
  %6 = arith.index_cast %arg0 : i64 to index
  scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%5, %6) step (%c1, %c1) {
    scf.parallel (%arg14, %arg15, %arg16) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
      %7 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
      %8 = arith.index_cast %4 : index to i64
      %9 = arith.cmpi sge, %8, %c1_i64 : i64
      scf.if %9 {
        %20 = llvm.load %arg8 : !llvm.ptr -> f32
        llvm.store %20, %2 : f32, !llvm.ptr<3>
        %21 = llvm.load %arg9 : !llvm.ptr -> f32
        llvm.store %21, %1 : f32, !llvm.ptr<3>
      }
      nvvm.barrier0
      %10 = llvm.getelementptr %7[] : (!llvm.ptr) -> !llvm.ptr, f32
      llvm.store %3, %10 : f32, !llvm.ptr
      nvvm.barrier0
      %11 = arith.subi %8, %c1_i64 : i64
      %12 = arith.addi %8, %c-16_i64 : i64
      %13 = arith.cmpi slt, %11, %c0_i64 : i64
      %14 = arith.select %13, %12, %11 : i64
      %15 = arith.divsi %14, %c16_i64 : i64
      %16 = arith.minsi %15, %c20_i64 : i64
      %17 = arith.addi %16, %c1_i64 : i64
      scf.for %arg17 = %c1_i64 to %17 step %c1_i64  : i64 {
        %20 = llvm.load %arg8 : !llvm.ptr -> f32
        llvm.store %20, %2 : f32, !llvm.ptr<3>
        %21 = llvm.load %arg9 : !llvm.ptr -> f32
        llvm.store %21, %1 : f32, !llvm.ptr<3>
      }
      nvvm.barrier0
      %18 = arith.addi %15, %c22_i64 : i64
      scf.for %arg17 = %c21_i64 to %18 step %c1_i64  : i64 {
        %20 = llvm.load %10 : !llvm.ptr -> f32
        %21 = scf.for %arg18 = %c0 to %c16 step %c1 iter_args(%arg19 = %20) -> (f32) {
          %25 = llvm.load %2 : !llvm.ptr<3> -> f32
          %26 = llvm.load %1 : !llvm.ptr<3> -> f32
          %27 = llvm.fmul %25, %26  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
          %28 = llvm.fadd %arg19, %27  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
          scf.yield %28 : f32
        }
        llvm.store %21, %10 : f32, !llvm.ptr
        nvvm.barrier0
        %22 = arith.muli %arg17, %c16_i64 : i64
        %23 = arith.addi %22, %c1_i64 : i64
        %24 = arith.cmpi sge, %8, %23 : i64
        scf.if %24 {
          %25 = llvm.load %arg8 : !llvm.ptr -> f32
          llvm.store %25, %2 : f32, !llvm.ptr<3>
          %26 = llvm.load %arg9 : !llvm.ptr -> f32
          llvm.store %26, %1 : f32, !llvm.ptr<3>
        }
      }
      nvvm.barrier0
      %19 = llvm.load %10 : !llvm.ptr -> f32
      llvm.store %19, %arg7 : f32, !llvm.ptr
      scf.reduce 
    } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
    scf.reduce 
  } {gpu.par.grid}
  llvm.return {polymer.stmt.name = "S35_llvm_return"}
}
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi64>>, #dlti.dl_entry<i128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi64>>, #dlti.dl_entry<i64, dense<64> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f16, dense<16> : vector<2xi64>>, #dlti.dl_entry<f64, dense<64> : vector<2xi64>>, #dlti.dl_entry<i16, dense<16> : vector<2xi64>>, #dlti.dl_entry<i32, dense<32> : vector<2xi64>>, #dlti.dl_entry<i1, dense<8> : vector<2xi64>>, #dlti.dl_entry<i8, dense<8> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi64>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i64>, #dlti.dl_entry<"dlti.endianness", "little">>, gpu.container_module} {
  gpu.module @__mlir_gpu_module [#nvvm.target<chip = "sm_80">]  {
    llvm.mlir.global external @shared_mem_1() {addr_space = 3 : i32} : !llvm.array<1024 x i8> {
      %0 = llvm.mlir.undef : !llvm.array<1024 x i8>
      llvm.return %0 : !llvm.array<1024 x i8>
    }
    llvm.mlir.global external @shared_mem_0() {addr_space = 3 : i32} : !llvm.array<1024 x i8> {
      %0 = llvm.mlir.undef : !llvm.array<1024 x i8>
      llvm.return %0 : !llvm.array<1024 x i8>
    }
    llvm.comdat @__llvm_global_comdat {
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs any
      llvm.comdat_selector @_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii any
      llvm.comdat_selector @_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii any
    }
    llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
      %c22_i64 = arith.constant 22 : i64
      %c-16_i64 = arith.constant -16 : i64
      %0 = llvm.mlir.constant(1 : index) : i64
      %c16 = arith.constant 16 : index
      %1 = llvm.mlir.addressof @shared_mem_0 : !llvm.ptr<3>
      %2 = llvm.mlir.addressof @shared_mem_1 : !llvm.ptr<3>
      %c1 = arith.constant 1 : index
      %c0 = arith.constant 0 : index
      %c21_i64 = arith.constant 21 : i64
      %c16_i64 = arith.constant 16 : i64
      %c20_i64 = arith.constant 20 : i64
      %c1_i64 = arith.constant 1 : i64
      %c0_i64 = arith.constant 0 : i64
      %3 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
      %4 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
      %5 = arith.index_cast %arg1 : i64 to index
      %6 = arith.index_cast %arg0 : i64 to index
      scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%5, %6) step (%c1, %c1) {
        scf.parallel (%arg14, %arg15, %arg16) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
          %7 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
          %8 = arith.index_cast %4 : index to i64
          %9 = arith.cmpi sge, %8, %c1_i64 : i64
          scf.if %9 {
            %20 = llvm.load %arg8 : !llvm.ptr -> f32
            llvm.store %20, %2 : f32, !llvm.ptr<3>
            %21 = llvm.load %arg9 : !llvm.ptr -> f32
            llvm.store %21, %1 : f32, !llvm.ptr<3>
          }
          nvvm.barrier0
          %10 = llvm.getelementptr %7[] : (!llvm.ptr) -> !llvm.ptr, f32
          llvm.store %3, %10 : f32, !llvm.ptr
          nvvm.barrier0
          %11 = arith.subi %8, %c1_i64 : i64
          %12 = arith.addi %8, %c-16_i64 : i64
          %13 = arith.cmpi slt, %11, %c0_i64 : i64
          %14 = arith.select %13, %12, %11 : i64
          %15 = arith.divsi %14, %c16_i64 : i64
          %16 = arith.minsi %15, %c20_i64 : i64
          %17 = arith.addi %16, %c1_i64 : i64
          scf.for %arg17 = %c1_i64 to %17 step %c1_i64  : i64 {
            %20 = llvm.load %arg8 : !llvm.ptr -> f32
            llvm.store %20, %2 : f32, !llvm.ptr<3>
            %21 = llvm.load %arg9 : !llvm.ptr -> f32
            llvm.store %21, %1 : f32, !llvm.ptr<3>
          }
          nvvm.barrier0
          %18 = arith.addi %15, %c22_i64 : i64
          scf.for %arg17 = %c21_i64 to %18 step %c1_i64  : i64 {
            %20 = llvm.load %10 : !llvm.ptr -> f32
            %21 = scf.for %arg18 = %c0 to %c16 step %c1 iter_args(%arg19 = %20) -> (f32) {
              %25 = llvm.load %2 : !llvm.ptr<3> -> f32
              %26 = llvm.load %1 : !llvm.ptr<3> -> f32
              %27 = llvm.fmul %25, %26  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
              %28 = llvm.fadd %arg19, %27  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
              scf.yield %28 : f32
            }
            llvm.store %21, %10 : f32, !llvm.ptr
            nvvm.barrier0
            %22 = arith.muli %arg17, %c16_i64 : i64
            %23 = arith.addi %22, %c1_i64 : i64
            %24 = arith.cmpi sge, %8, %23 : i64
            scf.if %24 {
              %25 = llvm.load %arg8 : !llvm.ptr -> f32
              llvm.store %25, %2 : f32, !llvm.ptr<3>
              %26 = llvm.load %arg9 : !llvm.ptr -> f32
              llvm.store %26, %1 : f32, !llvm.ptr<3>
            }
          }
          nvvm.barrier0
          %19 = llvm.load %10 : !llvm.ptr -> f32
          llvm.store %19, %arg7 : f32, !llvm.ptr
          scf.reduce 
        } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
        scf.reduce 
      } {gpu.par.grid}
      llvm.return {polymer.stmt.name = "S35_llvm_return"}
    }
  }
}

Eliminated dead instances: [P0, P1, P2, P3] -> { S4_arith_index_cast[]; S1_memref_ataddr[]; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S0_llvm_mlir_constant[] }
Eliminated dead instances: [P0, P1, P2, P3] -> { S4_arith_index_cast[]; S1_memref_ataddr[]; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S0_llvm_mlir_constant[] }
