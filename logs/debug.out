gpu-affine-opt: Before opt:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c4_i32 = arith.constant 4 : i32
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %c16_i32 = arith.constant 16 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %1 = arith.index_cast %arg1 : i64 to index
  %2 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%2), symbol(%1), 1) {
    %3 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    %4 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %5 = llvm.addrspacecast %3 : !llvm.ptr<3> to !llvm.ptr
      %6 = llvm.addrspacecast %4 : !llvm.ptr<3> to !llvm.ptr
      %7 = arith.index_cast %arg12 : index to i32
      %8 = arith.index_cast %arg13 : index to i32
      %9 = arith.index_cast %arg15 : index to i32
      %10 = arith.index_cast %arg16 : index to i32
      %11 = arith.shli %arg10, %c4_i32 : i32
      %12 = arith.muli %11, %8 : i32
      %13 = arith.addi %12, %arg10 : i32
      %14 = arith.shli %7, %c4_i32 : i32
      %15 = arith.shli %arg11, %c4_i32 : i32
      %16 = arith.muli %10, %arg10 : i32
      %17 = arith.addi %16, %9 : i32
      %18 = arith.extui %10 : i32 to i64
      %19 = arith.extui %9 : i32 to i64
      %20 = llvm.getelementptr inbounds %5[0, %18, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %21 = arith.muli %10, %arg11 : i32
      %22 = arith.addi %21, %9 : i32
      %23 = llvm.getelementptr inbounds %6[0, %18, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %24:2 = scf.for %arg18 = %12 to %13 step %c16_i32 iter_args(%arg19 = %14, %arg20 = %0) -> (i32, f32)  : i32 {
        %31 = arith.addi %17, %arg18 : i32
        %32 = arith.extsi %31 : i32 to i64
        %33 = llvm.getelementptr inbounds %arg8[%32] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %34 = llvm.load %33 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %34, %20 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        %35 = arith.addi %22, %arg19 : i32
        %36 = arith.extsi %35 : i32 to i64
        %37 = llvm.getelementptr inbounds %arg9[%36] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %38 = llvm.load %37 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %38, %23 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %39 = scf.for %arg21 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg22 = %arg20) -> (f32)  : i32 {
          %41 = arith.extui %arg21 : i32 to i64
          %42 = llvm.getelementptr inbounds %5[0, %18, %41] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %43 = llvm.load %42 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %44 = llvm.getelementptr inbounds %6[0, %41, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %45 = llvm.load %44 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %46 = llvm.fmul %43, %45  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %47 = llvm.fadd %arg22, %46  {fastmathFlags = #llvm.fastmath<contract>} : f32
          scf.yield %47 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %40 = arith.addi %arg19, %15 : i32
        scf.yield %40, %39 : i32, f32
      }
      %25 = arith.muli %15, %8 : i32
      %26 = arith.addi %14, %9 : i32
      %27 = arith.addi %26, %21 : i32
      %28 = arith.addi %27, %25 : i32
      %29 = arith.extsi %28 : i32 to i64
      %30 = llvm.getelementptr inbounds %arg7[%29] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %24#1, %30 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Removed IVs:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c4_i32 = arith.constant 4 : i32
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %c16_i32 = arith.constant 16 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %1 = arith.index_cast %arg1 : i64 to index
  %2 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%2), symbol(%1), 1) {
    %3 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    %4 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %5 = llvm.addrspacecast %3 : !llvm.ptr<3> to !llvm.ptr
      %6 = llvm.addrspacecast %4 : !llvm.ptr<3> to !llvm.ptr
      %7 = arith.index_cast %arg12 : index to i32
      %8 = arith.index_cast %arg13 : index to i32
      %9 = arith.index_cast %arg15 : index to i32
      %10 = arith.index_cast %arg16 : index to i32
      %11 = arith.shli %arg10, %c4_i32 : i32
      %12 = arith.muli %11, %8 : i32
      %13 = arith.shli %7, %c4_i32 : i32
      %14 = arith.shli %arg11, %c4_i32 : i32
      %15 = arith.muli %10, %arg10 : i32
      %16 = arith.addi %15, %9 : i32
      %17 = arith.extui %10 : i32 to i64
      %18 = arith.extui %9 : i32 to i64
      %19 = llvm.getelementptr inbounds %5[0, %17, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %20 = arith.muli %10, %arg11 : i32
      %21 = arith.addi %20, %9 : i32
      %22 = llvm.getelementptr inbounds %6[0, %17, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %23 = arith.subi %arg10, %c1_i32 : i32
      %24 = arith.divui %23, %c16_i32 : i32
      %25 = arith.addi %24, %c1_i32 : i32
      %26 = scf.for %arg18 = %c0_i32 to %25 step %c1_i32 iter_args(%arg19 = %0) -> (f32)  : i32 {
        %33 = arith.muli %arg18, %14 : i32
        %34 = arith.addi %33, %13 : i32
        %35 = arith.muli %arg18, %c16_i32 : i32
        %36 = arith.addi %12, %35 : i32
        %37 = arith.addi %16, %36 : i32
        %38 = arith.extsi %37 : i32 to i64
        %39 = llvm.getelementptr inbounds %arg8[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %40 = llvm.load %39 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %40, %19 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        %41 = arith.addi %21, %34 : i32
        %42 = arith.extsi %41 : i32 to i64
        %43 = llvm.getelementptr inbounds %arg9[%42] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %44 = llvm.load %43 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %44, %22 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %45 = scf.for %arg20 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg21 = %arg19) -> (f32)  : i32 {
          %46 = arith.extui %arg20 : i32 to i64
          %47 = llvm.getelementptr inbounds %5[0, %17, %46] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %48 = llvm.load %47 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %49 = llvm.getelementptr inbounds %6[0, %46, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %50 = llvm.load %49 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %51 = llvm.fmul %48, %50  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %52 = llvm.fadd %arg21, %51  {fastmathFlags = #llvm.fastmath<contract>} : f32
          scf.yield %52 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        scf.yield %45 : f32
      }
      %27 = arith.muli %14, %8 : i32
      %28 = arith.addi %13, %9 : i32
      %29 = arith.addi %28, %20 : i32
      %30 = arith.addi %29, %27 : i32
      %31 = arith.extsi %30 : i32 to i64
      %32 = llvm.getelementptr inbounds %arg7[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %26, %32 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: To Affine:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg11 : i32 to index
  %6 = arith.index_cast %arg10 : i32 to index
  %7 = arith.index_cast %arg10 : i32 to index
  %8 = arith.index_cast %arg11 : i32 to index
  %9 = arith.index_cast %arg11 : i32 to index
  %10 = arith.index_cast %arg10 : i32 to index
  %11 = arith.index_cast %arg1 : i64 to index
  %12 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%12), symbol(%11), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %13 = affine.for %arg18 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%10] iter_args(%arg19 = %0) -> (f32) {
        %15 = affine.vector_load %2[(%arg16 * symbol(%7)) * 4 + %arg15 * 4 + %arg18 * 64 + (%arg13 * (symbol(%6) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %15, %alloca[%arg16 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %16 = affine.vector_load %1[(%arg16 * symbol(%5)) * 4 + %arg15 * 4 + %arg12 * 64 + (%arg18 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %16, %alloca_0[%arg16 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %17 = affine.for %arg20 = 0 to 16 iter_args(%arg21 = %arg19) -> (f32) {
          %18 = affine.vector_load %alloca[%arg16 * 64 + %arg20 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %19 = llvm.bitcast %18 : vector<4xi8> to f32
          %20 = affine.vector_load %alloca_0[%arg20 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %21 = llvm.bitcast %20 : vector<4xi8> to f32
          %22 = llvm.fmul %19, %21  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %23 = llvm.fadd %arg21, %22  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %23 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        affine.yield %17 : f32
      }
      %14 = llvm.bitcast %13 : f32 to vector<4xi8>
      affine.vector_store %14, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%9)) * 4 + (%arg13 * (symbol(%8) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Distributed:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c1 = arith.constant 1 : index
  %c16 = arith.constant 16 : index
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg11 : i32 to index
  %6 = arith.index_cast %arg10 : i32 to index
  %7 = arith.index_cast %arg10 : i32 to index
  %8 = arith.index_cast %arg11 : i32 to index
  %9 = arith.index_cast %arg11 : i32 to index
  %10 = arith.index_cast %arg10 : i32 to index
  %11 = arith.index_cast %arg1 : i64 to index
  %12 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%12), symbol(%11), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    %alloca_1 = memref.alloca(%c16, %c16, %c1) : memref<?x?x?xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] : memref<?x?x?xf32, 16>
    } {gpu.par.block}
    affine.for %arg15 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%10] {
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %13 = affine.vector_load %2[(%arg17 * symbol(%7)) * 4 + %arg16 * 4 + %arg15 * 64 + (%arg13 * (symbol(%6) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %13, %alloca[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %14 = affine.vector_load %1[(%arg17 * symbol(%5)) * 4 + %arg16 * 4 + %arg12 * 64 + (%arg15 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %14, %alloca_0[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
      } {gpu.par.block}
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %13 = affine.load %alloca_1[%arg16, %arg17, %arg18] : memref<?x?x?xf32, 16>
        %14 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %13) -> (f32) {
          %15 = affine.vector_load %alloca[%arg17 * 64 + %arg19 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %16 = llvm.bitcast %15 : vector<4xi8> to f32
          %17 = affine.vector_load %alloca_0[%arg19 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %18 = llvm.bitcast %17 : vector<4xi8> to f32
          %19 = llvm.fmul %16, %18  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %20 = llvm.fadd %arg20, %19  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %20 : f32
        }
        affine.store %14, %alloca_1[%arg16, %arg17, %arg18] : memref<?x?x?xf32, 16>
      } {gpu.par.block}
    }
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %13 = affine.load %alloca_1[%arg15, %arg16, %arg17] : memref<?x?x?xf32, 16>
      %14 = llvm.bitcast %13 : f32 to vector<4xi8>
      affine.vector_store %14, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%9)) * 4 + (%arg13 * (symbol(%8) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Canonicalized:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg10 : i32 to index
  %6 = arith.index_cast %arg1 : i64 to index
  %7 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%7), symbol(%6), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    %alloca_1 = memref.alloca() : memref<16x16x1xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] : memref<16x16x1xf32, 16>
    } {gpu.par.block}
    affine.for %arg15 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%5] {
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %8 = affine.vector_load %2[(%arg17 * symbol(%5)) * 4 + %arg16 * 4 + %arg15 * 64 + (%arg13 * (symbol(%5) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %8, %alloca[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %9 = affine.vector_load %1[(%arg17 * symbol(%4)) * 4 + %arg16 * 4 + %arg12 * 64 + (%arg15 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %9, %alloca_0[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
      } {gpu.par.block}
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %8 = affine.load %alloca_1[%arg16, %arg17, %arg18] : memref<16x16x1xf32, 16>
        %9 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %8) -> (f32) {
          %10 = affine.vector_load %alloca[%arg17 * 64 + %arg19 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %11 = llvm.bitcast %10 : vector<4xi8> to f32
          %12 = affine.vector_load %alloca_0[%arg19 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %13 = llvm.bitcast %12 : vector<4xi8> to f32
          %14 = llvm.fmul %11, %13  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %15 = llvm.fadd %arg20, %14  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %15 : f32
        }
        affine.store %9, %alloca_1[%arg16, %arg17, %arg18] : memref<16x16x1xf32, 16>
      } {gpu.par.block}
    }
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %8 = affine.load %alloca_1[%arg15, %arg16, %arg17] : memref<16x16x1xf32, 16>
      %9 = llvm.bitcast %8 : f32 to vector<4xi8>
      affine.vector_store %9, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%4)) * 4 + (%arg13 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
Schedule:
domain: "[P0, P1, P2, P3] -> { S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S25_llvm_fadd[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S7_arith_index_cast[]; S32_affine_vector_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S18_affine_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S19_affine_store_var[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S31_llvm_bitcast[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S1_memref_ataddr[]; S21_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S23_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S24_llvm_fmul[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S5_arith_index_cast[]; S14_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S30_affine_load[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S22_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S16_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S11_affine_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S4_arith_index_cast[]; S27_affine_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S33_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S0_llvm_mlir_constant[]; S12_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S20_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S3_memref_ataddr[]; S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
child:
  sequence:
  - filter: "[P0, P1, P2, P3] -> { S0_llvm_mlir_constant[] }"
  - filter: "[P0, P1, P2, P3] -> { S1_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S2_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S3_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S4_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S5_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S6_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S7_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S10_memref_alloca[i0, i1, i2]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S30_affine_load[i0, i1, i2, i3, i4, i5]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S34_affine_yield[i0, i1, i2]; S8_memref_alloca[i0, i1, i2]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S11_affine_store[i0, i1, i2, i3, i4, i5]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S33_affine_yield[i0, i1, i2, i3, i4, i5]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S12_affine_yield[i0, i1, i2, i3, i4, i5]; S9_memref_alloca[i0, i1, i2]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
    child:
      schedule: "[P0, P1, P2, P3] -> L16.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i0)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i0)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i0)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S10_memref_alloca[i0, i1, i2] -> [(i0)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i0)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S34_affine_yield[i0, i1, i2] -> [(i0)]; S8_memref_alloca[i0, i1, i2] -> [(i0)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i0)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i0)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i0)]; S9_memref_alloca[i0, i1, i2] -> [(i0)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)] }]"
      permutable: 1
      child:
        schedule: "[P0, P1, P2, P3] -> L15.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i1)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i1)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i1)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S10_memref_alloca[i0, i1, i2] -> [(i1)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i1)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S34_affine_yield[i0, i1, i2] -> [(i1)]; S8_memref_alloca[i0, i1, i2] -> [(i1)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i1)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i1)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i1)]; S9_memref_alloca[i0, i1, i2] -> [(i1)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)] }]"
        permutable: 1
        child:
          schedule: "[P0, P1, P2, P3] -> L14.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i2)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i2)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i2)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S10_memref_alloca[i0, i1, i2] -> [(i2)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i2)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S34_affine_yield[i0, i1, i2] -> [(i2)]; S8_memref_alloca[i0, i1, i2] -> [(i2)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i2)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i2)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i2)]; S9_memref_alloca[i0, i1, i2] -> [(i2)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)] }]"
          permutable: 1
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S9_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S10_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S12_affine_yield[i0, i1, i2, i3, i4, i5]; S11_affine_store[i0, i1, i2, i3, i4, i5] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i3)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i3)] }]"
                permutable: 1
                child:
                  schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i4)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i4)] }]"
                  permutable: 1
                  child:
                    schedule: "[P0, P1, P2, P3] -> L0.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i5)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i5)] }]"
                    permutable: 1
                    child:
                      sequence:
                      - filter: "[P0, P1, P2, P3] -> { S11_affine_store[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S12_affine_yield[i0, i1, i2, i3, i4, i5] }"
            - filter: "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S29_affine_yield[i0, i1, i2, i3]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L10.affine.for[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S29_affine_yield[i0, i1, i2, i3] -> [(i3)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)] }]"
                child:
                  sequence:
                  - filter: "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                    child:
                      schedule: "[P0, P1, P2, P3] -> L5.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)] }]"
                      permutable: 1
                      child:
                        schedule: "[P0, P1, P2, P3] -> L4.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)] }]"
                        permutable: 1
                        child:
                          schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)] }]"
                          permutable: 1
                          child:
                            sequence:
                            - filter: "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                  - filter: "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] }"
                    child:
                      schedule: "[P0, P1, P2, P3] -> L9.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)] }]"
                      permutable: 1
                      child:
                        schedule: "[P0, P1, P2, P3] -> L8.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)] }]"
                        permutable: 1
                        child:
                          schedule: "[P0, P1, P2, P3] -> L7.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)] }]"
                          permutable: 1
                          child:
                            sequence:
                            - filter: "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] }"
                              child:
                                schedule: "[P0, P1, P2, P3] -> L6.affine.for[{ S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)] }]"
                                child:
                                  sequence:
                                  - filter: "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] }"
                            - filter: "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, i2, i3, i4, i5]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5]; S30_affine_load[i0, i1, i2, i3, i4, i5] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L13.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i3)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i3)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i3)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i3)] }]"
                permutable: 1
                child:
                  schedule: "[P0, P1, P2, P3] -> L12.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i4)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i4)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i4)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i4)] }]"
                  permutable: 1
                  child:
                    schedule: "[P0, P1, P2, P3] -> L11.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i5)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i5)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i5)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i5)] }]"
                    permutable: 1
                    child:
                      sequence:
                      - filter: "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, i2, i3, i4, i5] }"
            - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2] }"
Accesses:
domain: "[P0, P1, P2, P3] -> { S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S25_llvm_fadd[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S7_arith_index_cast[]; S32_affine_vector_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S18_affine_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S19_affine_store_var[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S31_llvm_bitcast[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S1_memref_ataddr[]; S21_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S23_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S24_llvm_fmul[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S5_arith_index_cast[]; S14_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S30_affine_load[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S22_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S16_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S11_affine_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S4_arith_index_cast[]; S27_affine_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S33_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S0_llvm_mlir_constant[]; S12_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S20_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S3_memref_ataddr[]; S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
accesses:
  - S0_llvm_mlir_constant:
  - S1_memref_ataddr:
  - S2_memref_ataddr:
  - S3_memref_ataddr:
  - S4_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[] }"
  - S5_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S5_arith_index_cast[] -> A_llvm_func_arg_10_1[] }"
  - S6_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }"
  - S7_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[] }"
  - S8_memref_alloca:
  - S9_memref_alloca:
  - S10_memref_alloca:
  - S11_affine_store:
        - must_write "[P0, P1, P2, P3] -> { S11_affine_store[i0, i1, i2, i3, i4, i5] -> A_memref_alloca_res_4[i3, i4, i5] }"
  - S12_affine_yield:
  - S13_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - must_write "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_6[] }"
  - S14_affine_vector_store:
        - must_write "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_7[4i4 + 64i5] }"
        - read "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_6[] }"
  - S15_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - must_write "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_9[] }"
  - S16_affine_vector_store:
        - must_write "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_10[4i4 + 64i5] }"
        - read "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_9[] }"
  - S17_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_vector_load_res_6[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_vector_load_res_9[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
  - S18_affine_load:
        - read "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_4[i4, i5, i6] }"
        - must_write "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_load_res_11[] }"
  - S19_affine_store_var:
        - read "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> A_affine_load_res_11[] }"
        - must_write "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> A_affine_for_res_12[] }"
  - S20_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_memref_alloca_res_7[64i5 + 4i7] }"
        - must_write "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_13[] }"
  - S21_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_14[] }"
        - read "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_13[] }"
  - S22_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_memref_alloca_res_10[4i4 + 64i7] }"
        - must_write "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_15[] }"
  - S23_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_16[] }"
        - read "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_15[] }"
  - S24_llvm_fmul:
        - must_write "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fmul_res_17[] }"
        - read "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_14[] }"
        - read "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_16[] }"
  - S25_llvm_fadd:
        - must_write "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fadd_res_18[] }"
        - read "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_for_res_12[] }"
        - read "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fmul_res_17[] }"
  - S26_affine_yield:
        - must_write "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_for_res_12[] }"
        - read "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fadd_res_18[] }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_affine_vector_load_res_13[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_bitcast_res_14[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_affine_vector_load_res_15[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_bitcast_res_16[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_fmul_res_17[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_fadd_res_18[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
  - S27_affine_store:
        - must_write "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_4[i4, i5, i6] }"
        - read "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_for_res_12[] }"
  - S28_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_load_res_11[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_for_res_12[] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
  - S29_affine_yield:
  - S30_affine_load:
        - read "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] -> A_memref_alloca_res_4[i3, i4, i5] }"
        - must_write "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] -> A_affine_load_res_19[] }"
  - S31_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> A_llvm_bitcast_res_20[] }"
        - read "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> A_affine_load_res_19[] }"
  - S32_affine_vector_store:
        - may_write "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, 0, i3, i4, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
        - read "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> A_llvm_bitcast_res_20[] }"
  - S33_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, 0, i3, i4, 0] -> A_affine_load_res_19[] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, 0, i3, i4, 0] -> A_llvm_bitcast_res_20[] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
  - S34_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
  - S35_llvm_return:
Schedule:
domain: "[P0, P1, P2, P3] -> { S4_arith_index_cast[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S1_memref_ataddr[]; RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S0_llvm_mlir_constant[]; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
child:
  sequence:
  - filter: "[P0, P1, P2, P3] -> { S0_llvm_mlir_constant[] }"
  - filter: "[P0, P1, P2, P3] -> { S1_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S2_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S3_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S4_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S5_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S6_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S7_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3]; S8_memref_alloca[i0, i1, i2]; RS3_affine_parallel[i0, i1, i2]; S29_affine_yield[i0, i1, i2, i3]; S10_memref_alloca[i0, i1, i2]; S9_memref_alloca[i0, i1, i2]; RS0_affine_parallel[i0, i1, i2] }"
    child:
      schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; S9_memref_alloca[i0, i1, i2] -> [(i0)]; S8_memref_alloca[i0, i1, i2] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; S29_affine_yield[i0, i1, i2, i3] -> [(i0)]; S34_affine_yield[i0, i1, i2] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; S10_memref_alloca[i0, i1, i2] -> [(i0)] }]"
      permutable: 1
      child:
        schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; S9_memref_alloca[i0, i1, i2] -> [(i1)]; S8_memref_alloca[i0, i1, i2] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; S29_affine_yield[i0, i1, i2, i3] -> [(i1)]; S34_affine_yield[i0, i1, i2] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; S10_memref_alloca[i0, i1, i2] -> [(i1)] }]"
        permutable: 1
        child:
          schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i2)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i2)]; S9_memref_alloca[i0, i1, i2] -> [(i2)]; S8_memref_alloca[i0, i1, i2] -> [(i2)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i2)]; S29_affine_yield[i0, i1, i2, i3] -> [(i2)]; S34_affine_yield[i0, i1, i2] -> [(i2)]; RS3_affine_parallel[i0, i1, i2] -> [(i2)]; S10_memref_alloca[i0, i1, i2] -> [(i2)] }]"
          permutable: 1
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S9_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S10_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L0.affine.for[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)]; S29_affine_yield[i0, i1, i2, i3] -> [(i3)] }]"
                child:
                  sequence:
                  - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
                  - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
                  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2] }"
Accesses:
domain: "[P0, P1, P2, P3] -> { S4_arith_index_cast[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S1_memref_ataddr[]; RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S0_llvm_mlir_constant[]; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
accesses:
  - S0_llvm_mlir_constant:
  - S1_memref_ataddr:
  - S2_memref_ataddr:
  - S3_memref_ataddr:
  - S4_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[] }"
  - S5_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S5_arith_index_cast[] -> A_llvm_func_arg_10_1[] }"
  - S6_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }"
  - S7_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[] }"
  - S8_memref_alloca:
  - S9_memref_alloca:
  - S10_memref_alloca:
  - S29_affine_yield:
  - S34_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
  - S35_llvm_return:
  - RS0_affine_parallel:
        - must_write "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
  - RS1_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
        - must_write "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - read "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
        - must_write "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
  - RS2_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - must_write "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
  - RS3_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
        - may_write "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
ReductionTagMap: [P0, P1, P2, P3] -> {  }
TaggedStmtDomain: [P2, P3, P0, P1] -> { [RS2_affine_parallel[i0, i1, i2, i3] -> S18_affine_load_Read0[]]; [RS0_affine_parallel[i0, i1, i2] -> S11_affine_store_Write0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S14_affine_vector_store_Write0[]]; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S27_affine_store_Write0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield2[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S20_affine_vector_load_Read0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield1[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S15_affine_vector_load_Read0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S22_affine_vector_load_Read0[]]; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]]; [RS3_affine_parallel[i0, i1, i2] -> S32_affine_vector_store_MayWrite0[]]; [RS3_affine_parallel[i0, i1, i2] -> S30_affine_load_Read0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S16_affine_vector_store_Write0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S13_affine_vector_load_Read0[]]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] }
dep_order for A_llvm_func_arg_11_0 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_10_1 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_1_2 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_0_3 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_4 [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, i2] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0); RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and o3 < i3) or (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 > i3 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and o3 < i3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and o1 > i1 and o1 < P2 and o3 > i3 and 16o3 < P0); RS2_affine_parallel[i0, i1, i2, i3] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2); RS3_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and o1 > i1 and o1 < P2) }
dep_order for A_memref_ataddr_res_5 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_6 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_7 [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0) }
dep_order for A_memref_ataddr_res_8 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_9 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_10 [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0) }
dep_order for A_affine_load_res_11 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_for_res_12 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_13 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_14 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_15 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_16 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_fmul_res_17 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_fadd_res_18 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_load_res_19 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_20 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_ataddr_res_21 [P2, P3, P0, P1] -> {  }
ReductionTagMap: [P0, P1, P2, P3] -> {  }
TaggedStmtDomain: [P2, P3, P0, P1] -> { [RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_8[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_10[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]]; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_5[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_7[]]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_ataddr_res_21[]]; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]]; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]]; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] }
dep_order for A_llvm_func_arg_11_0 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_10_1 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_1_2 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_func_arg_0_3 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_4 [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, i2] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0); RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and o3 < i3) or (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 > i3 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and o3 < i3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and o1 > i1 and o1 < P2 and o3 > i3 and 16o3 < P0); RS2_affine_parallel[i0, i1, i2, i3] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2); RS3_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and o1 > i1 and o1 < P2) }
dep_order for A_memref_ataddr_res_5 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_6 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_7 [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0) }
dep_order for A_memref_ataddr_res_8 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_9 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_alloca_res_10 [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P2 and i3 >= 0 and 16i3 < P0 and o0 > i0 and o0 < P3 and o1 >= 0 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and o1 > i1 and o1 < P2 and o3 >= 0 and 16o3 < P0) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P3 and i1 >= 0 and i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0) }
dep_order for A_affine_load_res_11 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_for_res_12 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_13 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_14 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_vector_load_res_15 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_16 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_fmul_res_17 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_fadd_res_18 [P2, P3, P0, P1] -> {  }
dep_order for A_affine_load_res_19 [P2, P3, P0, P1] -> {  }
dep_order for A_llvm_bitcast_res_20 [P2, P3, P0, P1] -> {  }
dep_order for A_memref_ataddr_res_21 [P2, P3, P0, P1] -> {  }
tagged_reads [P2, P3, P0, P1] -> { [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]] -> A_llvm_func_arg_0_3[]; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS1_affine_parallel[i0, i1, 0, i3] -> S15_affine_vector_load_Read0[]] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S13_affine_vector_load_Read0[]] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]] -> A_llvm_func_arg_11_0[]; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]] -> A_llvm_func_arg_1_2[]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] -> A_llvm_func_arg_10_1[] }
atagged_reads [P2, P3, P0, P1] -> { [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]] -> A_llvm_func_arg_0_3[]; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]] -> A_llvm_func_arg_10_1[]; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[]] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]] -> A_llvm_func_arg_11_0[]; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]] -> A_llvm_func_arg_1_2[]; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[]] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
reads [P2, P3, P0, P1] -> { RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]; S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]; RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
async_reads [P0, P2, P3, P1] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
tagged_may_writes [P2, P3, P0, P1] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }
atagged_may_writes [P2, P3, P0, P1] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[]] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
may_writes [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P2 > 0 and P3 > 0 and P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
tagged_must_writes [P0, P2, P3, P1] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
atagged_must_writes [P0, P2, P3, P1] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
must_writes [P0, P2, P3, P1] -> { RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
async_must_writes [P0, P2, P3, P1] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
tagged_must_kills [P0, P1, P2, P3] -> { [S34_affine_yield[i0, i1, 0] -> S34_affine_yield1[]] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; [S34_affine_yield[i0, i1, 0] -> S34_affine_yield0[]] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; [S34_affine_yield[i0, i1, 0] -> S34_affine_yield2[]] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2 }
atagged_must_kills [P0, P1, P2, P3] -> { [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2; [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }
must_kills [P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P3 and 0 <= i1 < P2; S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P3 and 0 <= i1 < P2; S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }
live_in [P0, P2, P3, P1] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]; S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]; S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
live_out [P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P3 and 0 <= i1 < P2 }
independence [P2, P3, P0, P1] -> { S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : o2 < i2 or o2 > i2; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, i1, i2] : o0 < i0 or o0 > i0; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, i2] : o1 < i1 or o1 > i1; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, o1, o2] : o2 > i2 or o2 < i2; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, i1, i2] : o0 > i0 or o0 < i0; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, o1, i2] : o1 > i1 or o1 < i1; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, i3] : o2 > i2 or o2 < i2; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[i0, i1, i2, o3] : o3 > i3 or o3 < i3; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, i2, i3] : o1 > i1 or o1 < i1; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, i1, i2, i3] : o0 > i0 or o0 < i0; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, i3] : o2 > i2 or o2 < i2; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[i0, i1, i2, o3] : o3 > i3 or o3 < i3; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, i2, i3] : o1 > i1 or o1 < i1; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, i1, i2, i3] : o0 > i0 or o0 < i0; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, o1, o2] : o2 < i2 or o2 > i2; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, i1, i2] : o0 < i0 or o0 > i0; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, o1, i2] : o1 < i1 or o1 > i1; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, o1, o2, i3] : o2 > i2 or o2 < i2; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[i0, i1, i2, o3] : o3 > i3 or o3 < i3; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, o1, i2, i3] : o1 > i1 or o1 < i1; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, i1, i2, i3] : o0 > i0 or o0 < i0 }
dep_flow [P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }
tagged_dep_flow [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0 }
atagged_dep_flow [P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> A_memref_alloca_res_4[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> A_memref_alloca_res_4[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
dep_false [P2, P3, P0, P1] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 <= -2 + P2 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, -1 + P2, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P2 > 0 and P0 > 0 and 0 <= i0 <= -2 + P3 and -16 + P0 <= 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 <= -2 + P2 and -16 + P0 <= 16i3 < P0; RS1_affine_parallel[i0, -1 + P2, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P2 > 0 and P0 > 0 and 0 <= i0 <= -2 + P3 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P3 and 0 <= i1 <= -2 + P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, -1 + P2, 0, i3] -> RS0_affine_parallel[1 + i0, 0, 0] : P2 > 0 and 0 <= i0 <= -2 + P3 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P3 and 0 <= i1 <= -2 + P2; RS3_affine_parallel[i0, -1 + P2, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P2 > 0 and 0 <= i0 <= -2 + P3; RS0_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 <= -2 + P2; RS0_affine_parallel[i0, -1 + P2, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P2 > 0 and P0 <= 0 and 0 <= i0 <= -2 + P3 }
dep_forced [P2, P3, P0, P1] -> {  }
dep_order [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 }
tagged_dep_order [P2, P3, P0, P1] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0 }
dep_async [P0, P2, P3, P1] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }
array_order [P2, P3, P0, P1] -> { RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and ((16i3 < P0 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P0)); RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and ((16i3 < P0 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P0)); RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 }
tagger [P0, P1, P2, P3] -> { [RS2_affine_parallel[i0, i1, i2, i3] -> S18_affine_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS0_affine_parallel[i0, i1, i2] -> S11_affine_store_Write0[]] -> RS0_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S14_affine_vector_store_Write0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]] -> S6_arith_index_cast[]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]] -> S4_arith_index_cast[]; [RS2_affine_parallel[i0, i1, i2, i3] -> S27_affine_store_Write0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS2_affine_parallel[i0, i1, i2, i3] -> S20_affine_vector_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield2[]] -> S34_affine_yield[(i0), (i1), (i2)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield1[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S15_affine_vector_load_Read0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield0[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> S22_affine_vector_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]] -> S7_arith_index_cast[]; [RS3_affine_parallel[i0, i1, i2] -> S32_affine_vector_store_MayWrite0[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS3_affine_parallel[i0, i1, i2] -> S30_affine_load_Read0[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S16_affine_vector_store_Write0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S13_affine_vector_load_Read0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] -> S5_arith_index_cast[] }
atagger [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]] -> RS0_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_8[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_4[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_10[]] -> S34_affine_yield[(i0), (i1), (i2)]; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]] -> S4_arith_index_cast[]; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]] -> S7_arith_index_cast[]; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]] -> S6_arith_index_cast[]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_7[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_5[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]] -> S5_arith_index_cast[]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_ataddr_res_21[]] -> RS3_affine_parallel[(i0), (i1), (i2)] }
schedule
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
child:
  schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; RS0_affine_parallel[i0, i1, i2] -> [(i0)] }]"
  permutable: 1
  child:
    schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; RS0_affine_parallel[i0, i1, i2] -> [(i1)] }]"
    permutable: 1
    child:
      schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(0)]; RS3_affine_parallel[i0, i1, i2] -> [(0)]; RS0_affine_parallel[i0, i1, i2] -> [(0)] }]"
      permutable: 1
      child:
        sequence:
        - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
        - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
          child:
            schedule: "[P0, P1, P2, P3] -> L0.affine.for[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
            child:
              sequence:
              - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
              - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
        - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
Schedule constraints:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
validity: "[P2, P3, P0, P1] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
coincidence: "[P2, P3, P0, P1] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
condition: "[P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0 }"
conditional_validity: "[P2, P3, P0, P1] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P2 and i0 < o0 < P3 and 0 <= o1 < P2; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P3 and i1 >= 0 and i1 < o1 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 and i0 < o0 < P3 and 0 <= o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and i1 >= 0 and i3 >= 0 and 16i3 < P0 and i1 < o1 < P2 and o3 >= 0 and 16o3 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and o3 > i3 and 16o3 < P0 }"
proximity: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P0 > 0 and 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and -16 + P0 <= 16i3 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 <= -17 + P0; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P0 <= 0 and 0 <= i0 < P3 and 0 <= i1 < P2 }"
anti_proximity: "[P0, P2, P3, P1] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
live_range_span: "[P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and (P0 >= 17 or P0 <= 0 or (0 < P0 <= 16)); [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0 }"
array_sizes: "[P0, P1, P2, P3] -> { A_memref_alloca_res_10[] -> [1024]; A_memref_alloca_res_4[] -> [1024]; A_memref_alloca_res_7[] -> [1024] }"
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i48 = i17 and i39 = i28 and i7 = i6 and i48 = i28 and i28 = i17 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i28 = i17 and i48 = i28 and i39 = i28 and i48 = i17 and i22 >= i21 and i27 >= i16 and i30 >= -i12 + i13 + i19 + i23 - i24 and i30 >= i19 and i29 >= -i14 + i15 + i18 + i25 - i26 and i29 >= i18 and i31 >= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 >= -i21 + i22 + 16i27 and i50 >= i30 and i49 >= -i25 + i26 + i29 + i45 - i46 and i49 >= i29 and i50 >= -i23 + i24 + i30 + i43 - i44 and i51 >= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i41 <= -i23 + i24 + i30 + i34 - i35 and i41 <= i30 and i40 <= -i25 + i26 + i29 + i36 - i37 and i40 <= i29 and 16i38 <= -i21 + i22 + 16i27 + i32 - i33 and i38 <= i27 and i42 <= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 <= i16 and i50 >= -i12 + i13 + i19 + i43 - i44 and i50 >= i19 and i49 >= -i14 + i15 + i18 + i45 - i46 and i49 >= i18 and i51 >= i18 + i19 + i20 - i49 - i50 and i27 <= i16 and i30 <= -i12 + i13 + i19 + i23 - i24 and i30 <= i19 and i29 <= -i14 + i15 + i18 + i25 - i26 and i29 <= i18 and i31 <= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 <= -i21 + i22 + 16i27 and i50 <= i30 and i49 <= -i25 + i26 + i29 + i45 - i46 and i49 <= i29 and i50 <= -i23 + i24 + i30 + i43 - i44 and i51 <= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i9 >= i8 and i11 >= i10 and i5 >= i4 and i22 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i21 and i41 >= -i23 + i24 + i30 + i34 - i35 and i41 >= i30 and i40 >= -i25 + i26 + i29 + i36 - i37 and i40 >= i29 and 16i38 >= -i21 + i22 + 16i27 + i32 - i33 and i38 >= i27 and i42 >= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 >= i16 and i50 <= -i12 + i13 + i19 + i43 - i44 and i50 <= i19 and i49 <= -i14 + i15 + i18 + i45 - i46 and i49 <= i18 and i51 <= i18 + i19 + i20 - i49 - i50 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[1,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i48 = i17 and i39 = i28 and i48 = i28 and i28 = i17 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i28 = i17 and i48 = i28 and i39 = i28 and i48 = i17 and i22 >= i21 and i27 >= i16 and i30 >= -i12 + i13 + i19 + i23 - i24 and i30 >= i19 and i29 >= -i14 + i15 + i18 + i25 - i26 and i29 >= i18 and i31 >= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 >= -i21 + i22 + 16i27 and i50 >= i30 and i49 >= -i25 + i26 + i29 + i45 - i46 and i49 >= i29 and i50 >= -i23 + i24 + i30 + i43 - i44 and i51 >= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i41 <= -i23 + i24 + i30 + i34 - i35 and i41 <= i30 and i40 <= -i25 + i26 + i29 + i36 - i37 and i40 <= i29 and 16i38 <= -i21 + i22 + 16i27 + i32 - i33 and i38 <= i27 and i42 <= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 <= i16 and i50 >= -i12 + i13 + i19 + i43 - i44 and i50 >= i19 and i49 >= -i14 + i15 + i18 + i45 - i46 and i49 >= i18 and i51 >= i18 + i19 + i20 - i49 - i50 and i27 <= i16 and i30 <= -i12 + i13 + i19 + i23 - i24 and i30 <= i19 and i29 <= -i14 + i15 + i18 + i25 - i26 and i29 <= i18 and i31 <= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 <= -i21 + i22 + 16i27 and i50 <= i30 and i49 <= -i25 + i26 + i29 + i45 - i46 and i49 <= i29 and i50 <= -i23 + i24 + i30 + i43 - i44 and i51 <= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i22 <= i21 and i41 >= -i23 + i24 + i30 + i34 - i35 and i41 >= i30 and i40 >= -i25 + i26 + i29 + i36 - i37 and i40 >= i29 and 16i38 >= -i21 + i22 + 16i27 + i32 - i33 and i38 >= i27 and i42 >= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 >= i16 and i50 <= -i12 + i13 + i19 + i43 - i44 and i50 <= i19 and i49 <= -i14 + i15 + i18 + i45 - i46 and i49 <= i18 and i51 <= i18 + i19 + i20 - i49 - i50 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[1,0,0,0,4,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i48 = i17 and i39 = i28 and i48 = i28 and i28 = i17 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i28 = i17 and i48 = i28 and i39 = i28 and i48 = i17 and i22 >= i21 and i27 >= i16 and i30 >= -i12 + i13 + i19 + i23 - i24 and i30 >= i19 and i29 >= -i14 + i15 + i18 + i25 - i26 and i29 >= i18 and i31 >= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 >= -i21 + i22 + 16i27 and i50 >= i30 and i49 >= -i25 + i26 + i29 + i45 - i46 and i49 >= i29 and i50 >= -i23 + i24 + i30 + i43 - i44 and i51 >= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i41 <= -i23 + i24 + i30 + i34 - i35 and i41 <= i30 and i40 <= -i25 + i26 + i29 + i36 - i37 and i40 <= i29 and 16i38 <= -i21 + i22 + 16i27 + i32 - i33 and i38 <= i27 and i42 <= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 <= i16 and i50 >= -i12 + i13 + i19 + i43 - i44 and i50 >= i19 and i49 >= -i14 + i15 + i18 + i45 - i46 and i49 >= i18 and i51 >= i18 + i19 + i20 - i49 - i50 and i27 <= i16 and i30 <= -i12 + i13 + i19 + i23 - i24 and i30 <= i19 and i29 <= -i14 + i15 + i18 + i25 - i26 and i29 <= i18 and i31 <= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 <= -i21 + i22 + 16i27 and i50 <= i30 and i49 <= -i25 + i26 + i29 + i45 - i46 and i49 <= i29 and i50 <= -i23 + i24 + i30 + i43 - i44 and i51 <= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i22 <= i21 and i41 >= -i23 + i24 + i30 + i34 - i35 and i41 >= i30 and i40 >= -i25 + i26 + i29 + i36 - i37 and i40 >= i29 and 16i38 >= -i21 + i22 + 16i27 + i32 - i33 and i38 >= i27 and i42 >= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 >= i16 and i50 <= -i12 + i13 + i19 + i43 - i44 and i50 <= i19 and i49 <= -i14 + i15 + i18 + i45 - i46 and i49 <= i18 and i51 <= i18 + i19 + i20 - i49 - i50 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i48 = i17 and i39 = i28 and i48 = i28 and i28 = i17 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i28 = i17 and i48 = i28 and i39 = i28 and i48 = i17 and i22 >= i21 and i27 >= i16 and i30 >= -i12 + i13 + i19 + i23 - i24 and i30 >= i19 and i29 >= -i14 + i15 + i18 + i25 - i26 and i29 >= i18 and i31 >= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 >= -i21 + i22 + 16i27 and i50 >= i30 and i49 >= -i25 + i26 + i29 + i45 - i46 and i49 >= i29 and i50 >= -i23 + i24 + i30 + i43 - i44 and i51 >= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i41 <= -i23 + i24 + i30 + i34 - i35 and i41 <= i30 and i40 <= -i25 + i26 + i29 + i36 - i37 and i40 <= i29 and 16i38 <= -i21 + i22 + 16i27 + i32 - i33 and i38 <= i27 and i42 <= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 <= i16 and i50 >= -i12 + i13 + i19 + i43 - i44 and i50 >= i19 and i49 >= -i14 + i15 + i18 + i45 - i46 and i49 >= i18 and i51 >= i18 + i19 + i20 - i49 - i50 and i27 <= i16 and i30 <= -i12 + i13 + i19 + i23 - i24 and i30 <= i19 and i29 <= -i14 + i15 + i18 + i25 - i26 and i29 <= i18 and i31 <= i16 + i18 + i19 + i20 - i27 - i29 - i30 and 16i47 <= -i21 + i22 + 16i27 and i50 <= i30 and i49 <= -i25 + i26 + i29 + i45 - i46 and i49 <= i29 and i50 <= -i23 + i24 + i30 + i43 - i44 and i51 <= i27 + i29 + i30 + i31 - i47 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i27 + 16i29 + 16i30 + 16i31 - 16i47 - 16i49 - 16i50 and i22 <= i21 and i41 >= -i23 + i24 + i30 + i34 - i35 and i41 >= i30 and i40 >= -i25 + i26 + i29 + i36 - i37 and i40 >= i29 and 16i38 >= -i21 + i22 + 16i27 + i32 - i33 and i38 >= i27 and i42 >= i27 + i29 + i30 + i31 - i38 - i40 - i41 and i47 >= i16 and i50 <= -i12 + i13 + i19 + i43 - i44 and i50 <= i19 and i49 <= -i14 + i15 + i18 + i45 - i46 and i49 <= i18 and i51 <= i18 + i19 + i20 - i49 - i50 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39] : i36 = i7 - i8 + i25 and i8 = i7 and i36 = i25 and i34 = i4 - i18 - i19 - i20 - i21 - i22 - i23 - i29 - i30 - i31 - i32 - i33 and i38 = i3 - i24 - i25 - i26 - i27 - i35 - i36 - i37 and i13 = 100000 - i0 and i12 = i1 - i5 - i6 - i7 - i8 - i9 - i10 - i11 and i17 = 1 + i15 and i16 = 1 + i14 and i36 = i25 and i36 = i25 and i36 = i25 and i38 <= -i20 + i21 + i27 + i31 - i32 and i38 <= i27 and i37 <= -i22 + i23 + i26 + i33 - i34 and i37 <= i26 and 16i35 <= -i18 + i19 + 16i24 + i29 - i30 and i35 <= i24 and i39 <= -i13 + i24 + i26 + i27 + i28 - i35 - i37 - i38 and i38 >= -i20 + i21 + i27 + i31 - i32 and i38 >= i27 and i37 >= -i22 + i23 + i26 + i33 - i34 and i37 >= i26 and 16i35 >= -i18 + i19 + 16i24 + i29 - i30 and i35 >= i24 and i39 >= -i14 + i24 + i26 + i27 + i28 - i35 - i37 - i38 and i38 >= -i20 + i21 + i27 + i31 - i32 and i38 >= i27 and i37 >= -i22 + i23 + i26 + i33 - i34 and i37 >= i26 and 16i35 >= -i18 + i19 + 16i24 + i29 - i30 and i35 >= i24 and i39 >= -i15 + i24 + i26 + i27 + i28 - i35 - i37 - i38 and 1024i17 <= 48000 - 1024i16 and i16 > 0 and i17 > 0 and i19 >= i18 and i38 <= -i20 + i21 + i27 + i31 - i32 and i38 <= i27 and i37 <= -i22 + i23 + i26 + i33 - i34 and i37 <= i26 and 16i35 <= -i18 + i19 + 16i24 + i29 - i30 and i35 <= i24 and i39 <= i24 + i26 + i27 + i28 - i35 - i37 - i38 and i10 >= i9 and i12 >= i11 and i6 >= i5 and i19 <= i2 - 17i5 + 17i6 - i9 + i10 - i11 + i12 + i18 and i38 >= i11 - i12 - i20 + i21 + i27 + i31 - i32 and i38 >= i11 - i12 + i27 and i37 >= i9 - i10 - i22 + i23 + i26 + i33 - i34 and i37 >= i9 - i10 + i26 and 16i35 >= 16i5 - 16i6 - i18 + i19 + 16i24 + i29 - i30 and i35 >= i5 - i6 + i24 and i39 >= -i2 + i5 - i6 + i9 - i10 + i11 - i12 + i24 + i26 + i27 + i28 - i35 - i37 - i38 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39] : i0 = 99978 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = -11 and i6 = 11 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 22 and i14 = 22 and i15 = 22 and i16 = 23 and i17 = 23 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 22 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 }
sol:
[1,99978,0,22,0,2,0,0,0,0,0,0,0,0,22,22,22,23,23,0,1,0,0,0,0,0,0,0,0,22,0,1,0,0,0,0,0,0,0,0,0]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i20 = i15 and i7 = i6 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i20 = i15 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i19 <= i14 and i21 <= i16 and i22 <= i17 and i23 <= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and i9 >= i8 and i11 >= i10 and i5 >= i4 and 22i13 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i12 and i19 >= i14 and i21 >= i16 and i22 >= i17 and i23 >= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i20 = i6 - i7 + i15 and i7 = i6 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i20 = i15 and 22i13 >= 22i12 and i13 >= i12 and i19 <= i14 and i21 <= i16 and i22 <= i17 and i23 <= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and i9 >= i8 and i11 >= i10 and i5 >= i4 and 22i13 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i12 and i19 >= i4 - i5 + i14 and i21 >= i8 - i9 + i16 and i22 >= i10 - i11 + i17 and i23 >= -i1 + i4 - i5 + i8 - i9 + i10 - i11 - 22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[1,0,22,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i20 = i15 and i7 = i6 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i20 = i15 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i19 <= i14 and i21 <= i16 and i22 <= i17 and i23 <= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and i9 >= i8 and i11 >= i10 and i5 >= i4 and 22i13 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i12 and i19 >= i14 and i21 >= i16 and i22 >= i17 and i23 >= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i20 = i6 - i7 + i15 and i7 = i6 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i20 = i15 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i19 <= i14 and i21 <= i16 and i22 <= i17 and i23 <= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and i9 >= i8 and i11 >= i10 and i5 >= i4 and 22i13 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i12 and i19 >= i4 - i5 + i14 and i21 >= i8 - i9 + i16 and i22 >= i10 - i11 + i17 and i23 >= -i1 + i4 - i5 + i8 - i9 + i10 - i11 - 22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i20 = i15 and i7 = i6 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i20 = i15 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and 16i19 >= -i12 + i13 + 16i14 and i22 >= i17 and i21 >= i16 and i23 >= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 16i23 >= -337i12 + 337i13 + 16i14 + 16i16 + 16i17 + 16i18 - 16i19 - 16i21 - 16i22 and i9 >= i8 and i11 >= i10 and i5 >= i4 and 22i13 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i12 and 16i19 <= -i12 + i13 + 16i14 and i22 <= i17 and i21 <= i16 and i23 <= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 16i23 <= -337i12 + 337i13 + 16i14 + 16i16 + 16i17 + 16i18 - 16i19 - 16i21 - 16i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i20 = -i6 + i7 + i15 and i7 = i6 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i20 = i15 and 22i13 >= 22i12 and i13 >= i12 and 16i19 >= -i12 + i13 + 16i14 and i22 >= i17 and i21 >= i16 and i23 >= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 16i23 >= -337i12 + 337i13 + 16i14 + 16i16 + 16i17 + 16i18 - 16i19 - 16i21 - 16i22 and i9 >= i8 and i11 >= i10 and i5 >= i4 and 22i13 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i12 and 16i19 <= -16i4 + 16i5 - i12 + i13 + 16i14 and i22 <= -i10 + i11 + i17 and i21 <= -i8 + i9 + i16 and i23 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 - 22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 16i23 <= 16i1 - 16i4 + 16i5 - 16i8 + 16i9 - 16i10 + 16i11 - 337i12 + 337i13 + 16i14 + 16i16 + 16i17 + 16i18 - 16i19 - 16i21 - 16i22 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[1,0,352,1,16,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,1,0,0,0,351]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i20 = i15 and i7 = i6 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i20 = i15 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and 16i19 >= -i12 + i13 + 16i14 and i22 >= i17 and i21 >= i16 and i23 >= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 16i23 >= -337i12 + 337i13 + 16i14 + 16i16 + 16i17 + 16i18 - 16i19 - 16i21 - 16i22 and i9 >= i8 and i11 >= i10 and i5 >= i4 and 22i13 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i12 and 16i19 <= -i12 + i13 + 16i14 and i22 <= i17 and i21 <= i16 and i23 <= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 16i23 <= -337i12 + 337i13 + 16i14 + 16i16 + 16i17 + 16i18 - 16i19 - 16i21 - 16i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i20 = -i6 + i7 + i15 and i7 = i6 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i20 = i15 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and 16i19 >= -i12 + i13 + 16i14 and i22 >= i17 and i21 >= i16 and i23 >= -22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 16i23 >= -337i12 + 337i13 + 16i14 + 16i16 + 16i17 + 16i18 - 16i19 - 16i21 - 16i22 and i9 >= i8 and i11 >= i10 and i5 >= i4 and 22i13 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - 17i4 + 17i5 - i8 + i9 - i10 + i11 + i12 and 16i19 <= -16i4 + 16i5 - i12 + i13 + 16i14 and i22 <= -i10 + i11 + i17 and i21 <= -i8 + i9 + i16 and i23 <= i1 - i4 + i5 - i8 + i9 - i10 + i11 - 22i12 + 22i13 + i14 + i16 + i17 + i18 - i19 - i21 - i22 and 16i23 <= 16i1 - 16i4 + 16i5 - 16i8 + 16i9 - 16i10 + 16i11 - 337i12 + 337i13 + 16i14 + 16i16 + 16i17 + 16i18 - 16i19 - 16i21 - 16i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
New Schedule:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
child:
  schedule: "[P0, P1, P2, P3] -> [{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)] }, { RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)] }]"
  permutable: 1
  coincident: [ 1, 1 ]
  child:
    sequence:
    - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
    - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
      child:
        schedule: "[P0, P1, P2, P3] -> [{ RS2_affine_parallel[i0, i1, i2, i3] -> [(22 + i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
        permutable: 1
        coincident: [ 1 ]
        child:
          sequence:
          - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
          - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
    - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
New Schedule Prepared for GPU:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2 }"
child:
  mark: "grid_parallel"
  child:
    schedule: "[P0, P1, P2, P3] -> [{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)] }, { RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)] }]"
    permutable: 1
    coincident: [ 1, 1 ]
    child:
      sequence:
      - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
      - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
        child:
          schedule: "[P0, P1, P2, P3] -> [{ RS2_affine_parallel[i0, i1, i2, i3] -> [(22 + i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
          permutable: 1
          coincident: [ 1 ]
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
      - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
New AST:
mark: grid_parallel@0x2
node:
  iterator:
    id: c0
  init:
    val: 0
  cond:
    op: lt
    args:
    - id: c0
    - id: P2@0x3a31e3d0
  inc:
    val: 1
  body:
    iterator:
      id: c1
    init:
      val: 0
    cond:
      op: lt
      args:
      - id: c1
      - id: P3@0x3a31e940
    inc:
      val: 1
    body:
    - user:
        op: call
        args:
        - id: RS0_affine_parallel@0x3a31eb20
        - id: c1
        - id: c0
        - val: 0
    - iterator:
        id: c2
      init:
        val: 0
      cond:
        op: le
        args:
        - id: c2
        - op: min
          args:
          - val: 21
          - op: fdiv_q
            args:
            - op: sub
              args:
              - id: P0@0x3a3065d0
              - val: 1
            - val: 16
      inc:
        val: 1
      body:
        user:
          op: call
          args:
          - id: RS1_affine_parallel@0x3a31b3f0
          - id: c1
          - id: c0
          - val: 0
          - id: c2
    - iterator:
        id: c2
      init:
        val: 22
      cond:
        op: le
        args:
        - id: c2
        - op: add
          args:
          - op: fdiv_q
            args:
            - op: sub
              args:
              - id: P0@0x3a3065d0
              - val: 1
            - val: 16
          - val: 22
      inc:
        val: 1
      body:
      - user:
          op: call
          args:
          - id: RS2_affine_parallel@0x3a3316f0
          - id: c1
          - id: c0
          - val: 0
          - op: sub
            args:
            - id: c2
            - val: 22
      - guard:
          op: ge
          args:
          - id: P0@0x3a3065d0
          - op: add
            args:
            - op: mul
              args:
              - val: 16
              - id: c2
            - val: 1
        then:
          user:
            op: call
            args:
            - id: RS1_affine_parallel@0x3a31b3f0
            - id: c1
            - id: c0
            - val: 0
            - id: c2
    - user:
        op: call
        args:
        - id: RS3_affine_parallel@0x3a331450
        - id: c1
        - id: c0
        - val: 0
New func:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %5 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %6 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %7 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
  %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
  %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S10_memref_alloca"} : () -> memref<16x16x1xf32, 16>
  %11 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %12 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %13 = "arith.index_cast"(%6) : (index) -> i64
  %14 = "arith.index_cast"(%11) : (i64) -> index
  %15 = "arith.index_cast"(%13) : (i64) -> index
  %16 = "arith.index_cast"(%12) : (i64) -> index
  %17 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %18 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %19 = "arith.index_cast"(%7) : (index) -> i64
  %20 = "arith.index_cast"(%17) : (i64) -> index
  %21 = "arith.index_cast"(%19) : (i64) -> index
  %22 = "arith.index_cast"(%18) : (i64) -> index
  "scf.parallel"(%14, %20, %15, %21, %16, %22) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %23 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg30: index, %arg31: index, %arg32: index):
      "affine.store"(%0, %10, %arg30, %arg31, %arg32) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S11_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    %24 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %25 = "arith.constant"() <{value = 21 : i64}> : () -> i64
    %26 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %27 = "arith.index_cast"(%5) : (index) -> i64
    %28 = "arith.subi"(%27, %26) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %29 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %30 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %31 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %32 = "arith.subi"(%28, %29) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %33 = "arith.addi"(%32, %30) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %34 = "arith.cmpi"(%28, %31) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %35 = "arith.select"(%34, %33, %28) : (i1, i64, i64) -> i64
    %36 = "arith.divsi"(%35, %29) : (i64, i64) -> i64
    %37 = "arith.minsi"(%36, %25) : (i64, i64) -> i64
    %38 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %39 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %40 = "arith.addi"(%37, %39) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%24, %40, %38) ({
    ^bb0(%arg26: i64):
      %81 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg27: index, %arg28: index, %arg29: index):
        %82 = "affine.vector_load"(%2, %arg28, %arg27, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%82, %8, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %83 = "affine.vector_load"(%1, %arg28, %arg27, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%83, %9, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %41 = "arith.constant"() <{value = 22 : i64}> : () -> i64
    %42 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %43 = "arith.index_cast"(%5) : (index) -> i64
    %44 = "arith.subi"(%43, %42) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %45 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %46 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %47 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %48 = "arith.subi"(%44, %45) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %49 = "arith.addi"(%48, %46) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %50 = "arith.cmpi"(%44, %47) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %51 = "arith.select"(%50, %49, %44) : (i1, i64, i64) -> i64
    %52 = "arith.divsi"(%51, %45) : (i64, i64) -> i64
    %53 = "arith.constant"() <{value = 22 : i64}> : () -> i64
    %54 = "arith.addi"(%52, %53) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %55 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %56 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %57 = "arith.addi"(%54, %56) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%41, %57, %55) ({
    ^bb0(%arg17: i64):
      %61 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %62 = "arith.constant"() <{value = 22 : i64}> : () -> i64
      %63 = "arith.subi"(%arg17, %62) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg21: index, %arg22: index, %arg23: index):
        %73 = "affine.load"(%10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S18_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
        %74 = "affine.for"(%73) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg24: index, %arg25: f32):
          %75 = "affine.vector_load"(%8, %arg22, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %76 = "llvm.bitcast"(%75) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %77 = "affine.vector_load"(%9, %arg24, %arg21) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %78 = "llvm.bitcast"(%77) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %79 = "llvm.fmul"(%76, %78) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %80 = "llvm.fadd"(%arg25, %79) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%80) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "affine.store"(%74, %10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S27_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S28_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"} : () -> ()
      %64 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %65 = "arith.muli"(%64, %arg17) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %66 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %67 = "arith.addi"(%65, %66) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %68 = "arith.index_cast"(%5) : (index) -> i64
      %69 = "arith.cmpi"(%68, %67) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%69) ({
        %70 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
        ^bb0(%arg18: index, %arg19: index, %arg20: index):
          %71 = "affine.vector_load"(%2, %arg19, %arg18, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%71, %8, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %72 = "affine.vector_load"(%1, %arg19, %arg18, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%72, %9, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
        }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %58 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %59 = "affine.load"(%10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S30_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
      %60 = "llvm.bitcast"(%59) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%60, %3, %arg13, %arg14, %arg15, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S33_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
/scr/ivan/src/transformer-llvm-project/polly/lib/External/isl/isl_ctx.c:295: isl_ctx not freed as some objects still reference it
gpu-affine-opt: After opt:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %5 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %6 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %7 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
  %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
  %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S10_memref_alloca"} : () -> memref<16x16x1xf32, 16>
  %11 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %12 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %13 = "arith.index_cast"(%6) : (index) -> i64
  %14 = "arith.index_cast"(%11) : (i64) -> index
  %15 = "arith.index_cast"(%13) : (i64) -> index
  %16 = "arith.index_cast"(%12) : (i64) -> index
  %17 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %18 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %19 = "arith.index_cast"(%7) : (index) -> i64
  %20 = "arith.index_cast"(%17) : (i64) -> index
  %21 = "arith.index_cast"(%19) : (i64) -> index
  %22 = "arith.index_cast"(%18) : (i64) -> index
  "scf.parallel"(%14, %20, %15, %21, %16, %22) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %23 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg30: index, %arg31: index, %arg32: index):
      "affine.store"(%0, %10, %arg30, %arg31, %arg32) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S11_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    %24 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %25 = "arith.constant"() <{value = 21 : i64}> : () -> i64
    %26 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %27 = "arith.index_cast"(%5) : (index) -> i64
    %28 = "arith.subi"(%27, %26) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %29 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %30 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %31 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %32 = "arith.subi"(%28, %29) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %33 = "arith.addi"(%32, %30) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %34 = "arith.cmpi"(%28, %31) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %35 = "arith.select"(%34, %33, %28) : (i1, i64, i64) -> i64
    %36 = "arith.divsi"(%35, %29) : (i64, i64) -> i64
    %37 = "arith.minsi"(%36, %25) : (i64, i64) -> i64
    %38 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %39 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %40 = "arith.addi"(%37, %39) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%24, %40, %38) ({
    ^bb0(%arg26: i64):
      %81 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg27: index, %arg28: index, %arg29: index):
        %82 = "affine.vector_load"(%2, %arg28, %arg27, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%82, %8, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %83 = "affine.vector_load"(%1, %arg28, %arg27, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%83, %9, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %41 = "arith.constant"() <{value = 22 : i64}> : () -> i64
    %42 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %43 = "arith.index_cast"(%5) : (index) -> i64
    %44 = "arith.subi"(%43, %42) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %45 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %46 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %47 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %48 = "arith.subi"(%44, %45) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %49 = "arith.addi"(%48, %46) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %50 = "arith.cmpi"(%44, %47) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %51 = "arith.select"(%50, %49, %44) : (i1, i64, i64) -> i64
    %52 = "arith.divsi"(%51, %45) : (i64, i64) -> i64
    %53 = "arith.constant"() <{value = 22 : i64}> : () -> i64
    %54 = "arith.addi"(%52, %53) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %55 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %56 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %57 = "arith.addi"(%54, %56) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%41, %57, %55) ({
    ^bb0(%arg17: i64):
      %61 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %62 = "arith.constant"() <{value = 22 : i64}> : () -> i64
      %63 = "arith.subi"(%arg17, %62) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg21: index, %arg22: index, %arg23: index):
        %73 = "affine.load"(%10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S18_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
        %74 = "affine.for"(%73) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg24: index, %arg25: f32):
          %75 = "affine.vector_load"(%8, %arg22, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %76 = "llvm.bitcast"(%75) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %77 = "affine.vector_load"(%9, %arg24, %arg21) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %78 = "llvm.bitcast"(%77) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %79 = "llvm.fmul"(%76, %78) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %80 = "llvm.fadd"(%arg25, %79) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%80) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "affine.store"(%74, %10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S27_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S28_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"} : () -> ()
      %64 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %65 = "arith.muli"(%64, %arg17) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %66 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %67 = "arith.addi"(%65, %66) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %68 = "arith.index_cast"(%5) : (index) -> i64
      %69 = "arith.cmpi"(%68, %67) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%69) ({
        %70 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
        ^bb0(%arg18: index, %arg19: index, %arg20: index):
          %71 = "affine.vector_load"(%2, %arg19, %arg18, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%71, %8, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %72 = "affine.vector_load"(%1, %arg19, %arg18, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%72, %9, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
        }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %58 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %59 = "affine.load"(%10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S30_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
      %60 = "llvm.bitcast"(%59) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%60, %3, %arg13, %arg14, %arg15, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S33_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
gpu-affine-opt: After lower affine:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c22_i64 = arith.constant 22 : i64
  %c64 = arith.constant 64 : index
  %c4 = arith.constant 4 : index
  %c16_i64 = arith.constant 16 : i64
  %c21_i64 = arith.constant 21 : i64
  %c1 = arith.constant 1 : index
  %c16 = arith.constant 16 : index
  %c0 = arith.constant 0 : index
  %c1_i64 = arith.constant 1 : i64
  %c0_i64 = arith.constant 0 : i64
  %0 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = arith.index_cast %arg11 {polymer.stmt.name = "S4_arith_index_cast"} : i32 to index
  %4 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
  %5 = arith.index_cast %arg1 {polymer.stmt.name = "S6_arith_index_cast"} : i64 to index
  %6 = arith.index_cast %arg0 {polymer.stmt.name = "S7_arith_index_cast"} : i64 to index
  %alloca = memref.alloca() {polymer.stmt.name = "S8_memref_alloca"} : memref<1024xi8, 3>
  %alloca_0 = memref.alloca() {polymer.stmt.name = "S9_memref_alloca"} : memref<1024xi8, 3>
  %alloca_1 = memref.alloca() {polymer.stmt.name = "S10_memref_alloca"} : memref<16x16x1xf32, 16>
  %7 = arith.index_cast %5 : index to i64
  %8 = arith.index_cast %7 : i64 to index
  %9 = arith.index_cast %6 : index to i64
  %10 = arith.index_cast %9 : i64 to index
  scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%8, %10) step (%c1, %c1) {
    scf.parallel (%arg14, %arg15, %arg16) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
      memref.store %0, %alloca_1[%arg14, %arg15, %arg16] {polymer.stmt.name = "S11_affine_store"} : memref<16x16x1xf32, 16>
      scf.reduce 
    } {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"}
    %11 = arith.index_cast %4 : index to i64
    %12 = arith.subi %11, %c1_i64 : i64
    %13 = arith.subi %12, %c16_i64 : i64
    %14 = arith.addi %13, %c1_i64 : i64
    %15 = arith.cmpi slt, %12, %c0_i64 : i64
    %16 = arith.select %15, %14, %12 : i64
    %17 = arith.divsi %16, %c16_i64 : i64
    %18 = arith.minsi %17, %c21_i64 : i64
    %19 = arith.addi %18, %c1_i64 : i64
    scf.for %arg14 = %c0_i64 to %19 step %c1_i64  : i64 {
      scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
        %29 = arith.muli %arg16, %4 : index
        %30 = arith.muli %29, %c4 : index
        %31 = arith.muli %arg15, %c4 : index
        %32 = arith.addi %30, %31 : index
        %33 = arith.muli %arg12, %c64 : index
        %34 = arith.addi %32, %33 : index
        %35 = arith.muli %4, %c16 : index
        %36 = arith.muli %arg13, %35 : index
        %37 = arith.muli %36, %c4 : index
        %38 = arith.addi %34, %37 : index
        %39 = vector.load %2[%38] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        %40 = arith.muli %arg16, %c64 : index
        %41 = arith.muli %arg15, %c4 : index
        %42 = arith.addi %40, %41 : index
        vector.store %39, %alloca[%42] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        %43 = arith.muli %arg16, %3 : index
        %44 = arith.muli %43, %c4 : index
        %45 = arith.muli %arg15, %c4 : index
        %46 = arith.addi %44, %45 : index
        %47 = arith.muli %arg13, %c64 : index
        %48 = arith.addi %46, %47 : index
        %49 = arith.muli %3, %c16 : index
        %50 = arith.muli %arg12, %49 : index
        %51 = arith.muli %50, %c4 : index
        %52 = arith.addi %48, %51 : index
        %53 = vector.load %1[%52] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        %54 = arith.muli %arg16, %c64 : index
        %55 = arith.muli %arg15, %c4 : index
        %56 = arith.addi %54, %55 : index
        vector.store %53, %alloca_0[%56] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        scf.reduce 
      } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
    }
    %20 = arith.index_cast %4 : index to i64
    %21 = arith.subi %20, %c1_i64 : i64
    %22 = arith.subi %21, %c16_i64 : i64
    %23 = arith.addi %22, %c1_i64 : i64
    %24 = arith.cmpi slt, %21, %c0_i64 : i64
    %25 = arith.select %24, %23, %21 : i64
    %26 = arith.divsi %25, %c16_i64 : i64
    %27 = arith.addi %26, %c22_i64 : i64
    %28 = arith.addi %27, %c1_i64 : i64
    scf.for %arg14 = %c22_i64 to %28 step %c1_i64  : i64 {
      scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
        %33 = memref.load %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S18_affine_load"} : memref<16x16x1xf32, 16>
        %34 = scf.for %arg18 = %c0 to %c16 step %c1 iter_args(%arg19 = %33) -> (f32) {
          %35 = arith.muli %arg16, %c64 : index
          %36 = arith.muli %arg18, %c4 : index
          %37 = arith.addi %35, %36 : index
          %38 = vector.load %alloca[%37] {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
          %39 = llvm.bitcast %38 {polymer.stmt.name = "S21_llvm_bitcast"} : vector<4xi8> to f32
          %40 = arith.muli %arg18, %c64 : index
          %41 = arith.muli %arg15, %c4 : index
          %42 = arith.addi %40, %41 : index
          %43 = vector.load %alloca_0[%42] {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
          %44 = llvm.bitcast %43 {polymer.stmt.name = "S23_llvm_bitcast"} : vector<4xi8> to f32
          %45 = llvm.fmul %39, %44  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
          %46 = llvm.fadd %arg19, %45  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
          scf.yield %46 : f32
        }
        memref.store %34, %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S27_affine_store"} : memref<16x16x1xf32, 16>
        scf.reduce 
      } {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"}
      %29 = arith.muli %arg14, %c16_i64 : i64
      %30 = arith.addi %29, %c1_i64 : i64
      %31 = arith.index_cast %4 : index to i64
      %32 = arith.cmpi sge, %31, %30 : i64
      scf.if %32 {
        scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
          %33 = arith.muli %arg16, %4 : index
          %34 = arith.muli %33, %c4 : index
          %35 = arith.muli %arg15, %c4 : index
          %36 = arith.addi %34, %35 : index
          %37 = arith.muli %arg12, %c64 : index
          %38 = arith.addi %36, %37 : index
          %39 = arith.muli %4, %c16 : index
          %40 = arith.muli %arg13, %39 : index
          %41 = arith.muli %40, %c4 : index
          %42 = arith.addi %38, %41 : index
          %43 = vector.load %2[%42] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
          %44 = arith.muli %arg16, %c64 : index
          %45 = arith.muli %arg15, %c4 : index
          %46 = arith.addi %44, %45 : index
          vector.store %43, %alloca[%46] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
          %47 = arith.muli %arg16, %3 : index
          %48 = arith.muli %47, %c4 : index
          %49 = arith.muli %arg15, %c4 : index
          %50 = arith.addi %48, %49 : index
          %51 = arith.muli %arg13, %c64 : index
          %52 = arith.addi %50, %51 : index
          %53 = arith.muli %3, %c16 : index
          %54 = arith.muli %arg12, %53 : index
          %55 = arith.muli %54, %c4 : index
          %56 = arith.addi %52, %55 : index
          %57 = vector.load %1[%56] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
          %58 = arith.muli %arg16, %c64 : index
          %59 = arith.muli %arg15, %c4 : index
          %60 = arith.addi %58, %59 : index
          vector.store %57, %alloca_0[%60] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
          scf.reduce 
        } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
      }
    }
    scf.parallel (%arg14, %arg15, %arg16) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
      %29 = memref.load %alloca_1[%arg14, %arg15, %arg16] {polymer.stmt.name = "S30_affine_load"} : memref<16x16x1xf32, 16>
      llvm.store %29, %arg7 : f32, !llvm.ptr
      scf.reduce 
    } {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"}
    scf.reduce 
  } {gpu.par.grid}
  llvm.return {polymer.stmt.name = "S35_llvm_return"}
}
gpu-affine-opt: After gpuify:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c22_i64 = arith.constant 22 : i64
  %c64 = arith.constant 64 : index
  %c4 = arith.constant 4 : index
  %c16_i64 = arith.constant 16 : i64
  %c21_i64 = arith.constant 21 : i64
  %c1 = arith.constant 1 : index
  %c16 = arith.constant 16 : index
  %c0 = arith.constant 0 : index
  %c1_i64 = arith.constant 1 : i64
  %c0_i64 = arith.constant 0 : i64
  %0 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = arith.index_cast %arg11 {polymer.stmt.name = "S4_arith_index_cast"} : i32 to index
  %4 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
  %5 = arith.index_cast %arg1 {polymer.stmt.name = "S6_arith_index_cast"} : i64 to index
  %6 = arith.index_cast %arg0 {polymer.stmt.name = "S7_arith_index_cast"} : i64 to index
  %alloca = memref.alloca() {polymer.stmt.name = "S8_memref_alloca"} : memref<1024xi8, 3>
  %alloca_0 = memref.alloca() {polymer.stmt.name = "S9_memref_alloca"} : memref<1024xi8, 3>
  %alloca_1 = memref.alloca() {polymer.stmt.name = "S10_memref_alloca"} : memref<16x16x1xf32, 16>
  %7 = arith.index_cast %5 : index to i64
  %8 = arith.index_cast %7 : i64 to index
  %9 = arith.index_cast %6 : index to i64
  %10 = arith.index_cast %9 : i64 to index
  scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%8, %10) step (%c1, %c1) {
    scf.parallel (%arg14, %arg15, %arg16) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
      memref.store %0, %alloca_1[%arg14, %arg15, %arg16] {polymer.stmt.name = "S11_affine_store"} : memref<16x16x1xf32, 16>
      scf.reduce 
    } {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"}
    %11 = arith.index_cast %4 : index to i64
    %12 = arith.subi %11, %c1_i64 : i64
    %13 = arith.subi %12, %c16_i64 : i64
    %14 = arith.addi %13, %c1_i64 : i64
    %15 = arith.cmpi slt, %12, %c0_i64 : i64
    %16 = arith.select %15, %14, %12 : i64
    %17 = arith.divsi %16, %c16_i64 : i64
    %18 = arith.minsi %17, %c21_i64 : i64
    %19 = arith.addi %18, %c1_i64 : i64
    scf.for %arg14 = %c0_i64 to %19 step %c1_i64  : i64 {
      scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
        %29 = arith.muli %arg16, %4 : index
        %30 = arith.muli %29, %c4 : index
        %31 = arith.muli %arg15, %c4 : index
        %32 = arith.addi %30, %31 : index
        %33 = arith.muli %arg12, %c64 : index
        %34 = arith.addi %32, %33 : index
        %35 = arith.muli %4, %c16 : index
        %36 = arith.muli %arg13, %35 : index
        %37 = arith.muli %36, %c4 : index
        %38 = arith.addi %34, %37 : index
        %39 = vector.load %2[%38] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        %40 = arith.muli %arg16, %c64 : index
        %41 = arith.muli %arg15, %c4 : index
        %42 = arith.addi %40, %41 : index
        vector.store %39, %alloca[%42] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        %43 = arith.muli %arg16, %3 : index
        %44 = arith.muli %43, %c4 : index
        %45 = arith.muli %arg15, %c4 : index
        %46 = arith.addi %44, %45 : index
        %47 = arith.muli %arg13, %c64 : index
        %48 = arith.addi %46, %47 : index
        %49 = arith.muli %3, %c16 : index
        %50 = arith.muli %arg12, %49 : index
        %51 = arith.muli %50, %c4 : index
        %52 = arith.addi %48, %51 : index
        %53 = vector.load %1[%52] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        %54 = arith.muli %arg16, %c64 : index
        %55 = arith.muli %arg15, %c4 : index
        %56 = arith.addi %54, %55 : index
        vector.store %53, %alloca_0[%56] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        scf.reduce 
      } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
    }
    %20 = arith.index_cast %4 : index to i64
    %21 = arith.subi %20, %c1_i64 : i64
    %22 = arith.subi %21, %c16_i64 : i64
    %23 = arith.addi %22, %c1_i64 : i64
    %24 = arith.cmpi slt, %21, %c0_i64 : i64
    %25 = arith.select %24, %23, %21 : i64
    %26 = arith.divsi %25, %c16_i64 : i64
    %27 = arith.addi %26, %c22_i64 : i64
    %28 = arith.addi %27, %c1_i64 : i64
    scf.for %arg14 = %c22_i64 to %28 step %c1_i64  : i64 {
      scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
        %33 = memref.load %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S18_affine_load"} : memref<16x16x1xf32, 16>
        %34 = scf.for %arg18 = %c0 to %c16 step %c1 iter_args(%arg19 = %33) -> (f32) {
          %35 = arith.muli %arg16, %c64 : index
          %36 = arith.muli %arg18, %c4 : index
          %37 = arith.addi %35, %36 : index
          %38 = vector.load %alloca[%37] {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
          %39 = llvm.bitcast %38 {polymer.stmt.name = "S21_llvm_bitcast"} : vector<4xi8> to f32
          %40 = arith.muli %arg18, %c64 : index
          %41 = arith.muli %arg15, %c4 : index
          %42 = arith.addi %40, %41 : index
          %43 = vector.load %alloca_0[%42] {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
          %44 = llvm.bitcast %43 {polymer.stmt.name = "S23_llvm_bitcast"} : vector<4xi8> to f32
          %45 = llvm.fmul %39, %44  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
          %46 = llvm.fadd %arg19, %45  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
          scf.yield %46 : f32
        }
        memref.store %34, %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S27_affine_store"} : memref<16x16x1xf32, 16>
        scf.reduce 
      } {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"}
      %29 = arith.muli %arg14, %c16_i64 : i64
      %30 = arith.addi %29, %c1_i64 : i64
      %31 = arith.index_cast %4 : index to i64
      %32 = arith.cmpi sge, %31, %30 : i64
      scf.if %32 {
        scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
          %33 = arith.muli %arg16, %4 : index
          %34 = arith.muli %33, %c4 : index
          %35 = arith.muli %arg15, %c4 : index
          %36 = arith.addi %34, %35 : index
          %37 = arith.muli %arg12, %c64 : index
          %38 = arith.addi %36, %37 : index
          %39 = arith.muli %4, %c16 : index
          %40 = arith.muli %arg13, %39 : index
          %41 = arith.muli %40, %c4 : index
          %42 = arith.addi %38, %41 : index
          %43 = vector.load %2[%42] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
          %44 = arith.muli %arg16, %c64 : index
          %45 = arith.muli %arg15, %c4 : index
          %46 = arith.addi %44, %45 : index
          vector.store %43, %alloca[%46] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
          %47 = arith.muli %arg16, %3 : index
          %48 = arith.muli %47, %c4 : index
          %49 = arith.muli %arg15, %c4 : index
          %50 = arith.addi %48, %49 : index
          %51 = arith.muli %arg13, %c64 : index
          %52 = arith.addi %50, %51 : index
          %53 = arith.muli %3, %c16 : index
          %54 = arith.muli %arg12, %53 : index
          %55 = arith.muli %54, %c4 : index
          %56 = arith.addi %52, %55 : index
          %57 = vector.load %1[%56] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
          %58 = arith.muli %arg16, %c64 : index
          %59 = arith.muli %arg15, %c4 : index
          %60 = arith.addi %58, %59 : index
          vector.store %57, %alloca_0[%60] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
          scf.reduce 
        } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
      }
    }
    scf.parallel (%arg14, %arg15, %arg16) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
      %29 = memref.load %alloca_1[%arg14, %arg15, %arg16] {polymer.stmt.name = "S30_affine_load"} : memref<16x16x1xf32, 16>
      llvm.store %29, %arg7 : f32, !llvm.ptr
      scf.reduce 
    } {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"}
    scf.reduce 
  } {gpu.par.grid}
  llvm.return {polymer.stmt.name = "S35_llvm_return"}
}
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi64>>, #dlti.dl_entry<i128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi64>>, #dlti.dl_entry<i64, dense<64> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f16, dense<16> : vector<2xi64>>, #dlti.dl_entry<f64, dense<64> : vector<2xi64>>, #dlti.dl_entry<i16, dense<16> : vector<2xi64>>, #dlti.dl_entry<i32, dense<32> : vector<2xi64>>, #dlti.dl_entry<i1, dense<8> : vector<2xi64>>, #dlti.dl_entry<i8, dense<8> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi64>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i64>, #dlti.dl_entry<"dlti.endianness", "little">>, gpu.container_module} {
  gpu.module @__mlir_gpu_module [#nvvm.target<chip = "sm_80">]  {
    llvm.comdat @__llvm_global_comdat {
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs any
      llvm.comdat_selector @_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii any
      llvm.comdat_selector @_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii any
    }
    llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
      %c22_i64 = arith.constant 22 : i64
      %c64 = arith.constant 64 : index
      %c4 = arith.constant 4 : index
      %c16_i64 = arith.constant 16 : i64
      %c21_i64 = arith.constant 21 : i64
      %c1 = arith.constant 1 : index
      %c16 = arith.constant 16 : index
      %c0 = arith.constant 0 : index
      %c1_i64 = arith.constant 1 : i64
      %c0_i64 = arith.constant 0 : i64
      %0 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
      %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
      %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
      %3 = arith.index_cast %arg11 {polymer.stmt.name = "S4_arith_index_cast"} : i32 to index
      %4 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
      %5 = arith.index_cast %arg1 {polymer.stmt.name = "S6_arith_index_cast"} : i64 to index
      %6 = arith.index_cast %arg0 {polymer.stmt.name = "S7_arith_index_cast"} : i64 to index
      %alloca = memref.alloca() {polymer.stmt.name = "S8_memref_alloca"} : memref<1024xi8, 3>
      %alloca_0 = memref.alloca() {polymer.stmt.name = "S9_memref_alloca"} : memref<1024xi8, 3>
      %alloca_1 = memref.alloca() {polymer.stmt.name = "S10_memref_alloca"} : memref<16x16x1xf32, 16>
      %7 = arith.index_cast %5 : index to i64
      %8 = arith.index_cast %7 : i64 to index
      %9 = arith.index_cast %6 : index to i64
      %10 = arith.index_cast %9 : i64 to index
      scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%8, %10) step (%c1, %c1) {
        scf.parallel (%arg14, %arg15, %arg16) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
          memref.store %0, %alloca_1[%arg14, %arg15, %arg16] {polymer.stmt.name = "S11_affine_store"} : memref<16x16x1xf32, 16>
          scf.reduce 
        } {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"}
        %11 = arith.index_cast %4 : index to i64
        %12 = arith.subi %11, %c1_i64 : i64
        %13 = arith.subi %12, %c16_i64 : i64
        %14 = arith.addi %13, %c1_i64 : i64
        %15 = arith.cmpi slt, %12, %c0_i64 : i64
        %16 = arith.select %15, %14, %12 : i64
        %17 = arith.divsi %16, %c16_i64 : i64
        %18 = arith.minsi %17, %c21_i64 : i64
        %19 = arith.addi %18, %c1_i64 : i64
        scf.for %arg14 = %c0_i64 to %19 step %c1_i64  : i64 {
          scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
            %29 = arith.muli %arg16, %4 : index
            %30 = arith.muli %29, %c4 : index
            %31 = arith.muli %arg15, %c4 : index
            %32 = arith.addi %30, %31 : index
            %33 = arith.muli %arg12, %c64 : index
            %34 = arith.addi %32, %33 : index
            %35 = arith.muli %4, %c16 : index
            %36 = arith.muli %arg13, %35 : index
            %37 = arith.muli %36, %c4 : index
            %38 = arith.addi %34, %37 : index
            %39 = vector.load %2[%38] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
            %40 = arith.muli %arg16, %c64 : index
            %41 = arith.muli %arg15, %c4 : index
            %42 = arith.addi %40, %41 : index
            vector.store %39, %alloca[%42] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
            %43 = arith.muli %arg16, %3 : index
            %44 = arith.muli %43, %c4 : index
            %45 = arith.muli %arg15, %c4 : index
            %46 = arith.addi %44, %45 : index
            %47 = arith.muli %arg13, %c64 : index
            %48 = arith.addi %46, %47 : index
            %49 = arith.muli %3, %c16 : index
            %50 = arith.muli %arg12, %49 : index
            %51 = arith.muli %50, %c4 : index
            %52 = arith.addi %48, %51 : index
            %53 = vector.load %1[%52] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
            %54 = arith.muli %arg16, %c64 : index
            %55 = arith.muli %arg15, %c4 : index
            %56 = arith.addi %54, %55 : index
            vector.store %53, %alloca_0[%56] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
            scf.reduce 
          } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
        }
        %20 = arith.index_cast %4 : index to i64
        %21 = arith.subi %20, %c1_i64 : i64
        %22 = arith.subi %21, %c16_i64 : i64
        %23 = arith.addi %22, %c1_i64 : i64
        %24 = arith.cmpi slt, %21, %c0_i64 : i64
        %25 = arith.select %24, %23, %21 : i64
        %26 = arith.divsi %25, %c16_i64 : i64
        %27 = arith.addi %26, %c22_i64 : i64
        %28 = arith.addi %27, %c1_i64 : i64
        scf.for %arg14 = %c22_i64 to %28 step %c1_i64  : i64 {
          scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
            %33 = memref.load %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S18_affine_load"} : memref<16x16x1xf32, 16>
            %34 = scf.for %arg18 = %c0 to %c16 step %c1 iter_args(%arg19 = %33) -> (f32) {
              %35 = arith.muli %arg16, %c64 : index
              %36 = arith.muli %arg18, %c4 : index
              %37 = arith.addi %35, %36 : index
              %38 = vector.load %alloca[%37] {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
              %39 = llvm.bitcast %38 {polymer.stmt.name = "S21_llvm_bitcast"} : vector<4xi8> to f32
              %40 = arith.muli %arg18, %c64 : index
              %41 = arith.muli %arg15, %c4 : index
              %42 = arith.addi %40, %41 : index
              %43 = vector.load %alloca_0[%42] {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
              %44 = llvm.bitcast %43 {polymer.stmt.name = "S23_llvm_bitcast"} : vector<4xi8> to f32
              %45 = llvm.fmul %39, %44  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
              %46 = llvm.fadd %arg19, %45  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
              scf.yield %46 : f32
            }
            memref.store %34, %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S27_affine_store"} : memref<16x16x1xf32, 16>
            scf.reduce 
          } {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"}
          %29 = arith.muli %arg14, %c16_i64 : i64
          %30 = arith.addi %29, %c1_i64 : i64
          %31 = arith.index_cast %4 : index to i64
          %32 = arith.cmpi sge, %31, %30 : i64
          scf.if %32 {
            scf.parallel (%arg15, %arg16, %arg17) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
              %33 = arith.muli %arg16, %4 : index
              %34 = arith.muli %33, %c4 : index
              %35 = arith.muli %arg15, %c4 : index
              %36 = arith.addi %34, %35 : index
              %37 = arith.muli %arg12, %c64 : index
              %38 = arith.addi %36, %37 : index
              %39 = arith.muli %4, %c16 : index
              %40 = arith.muli %arg13, %39 : index
              %41 = arith.muli %40, %c4 : index
              %42 = arith.addi %38, %41 : index
              %43 = vector.load %2[%42] {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
              %44 = arith.muli %arg16, %c64 : index
              %45 = arith.muli %arg15, %c4 : index
              %46 = arith.addi %44, %45 : index
              vector.store %43, %alloca[%46] {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
              %47 = arith.muli %arg16, %3 : index
              %48 = arith.muli %47, %c4 : index
              %49 = arith.muli %arg15, %c4 : index
              %50 = arith.addi %48, %49 : index
              %51 = arith.muli %arg13, %c64 : index
              %52 = arith.addi %50, %51 : index
              %53 = arith.muli %3, %c16 : index
              %54 = arith.muli %arg12, %53 : index
              %55 = arith.muli %54, %c4 : index
              %56 = arith.addi %52, %55 : index
              %57 = vector.load %1[%56] {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
              %58 = arith.muli %arg16, %c64 : index
              %59 = arith.muli %arg15, %c4 : index
              %60 = arith.addi %58, %59 : index
              vector.store %57, %alloca_0[%60] {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
              scf.reduce 
            } {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"}
          }
        }
        scf.parallel (%arg14, %arg15, %arg16) = (%c0, %c0, %c0) to (%c16, %c16, %c1) step (%c1, %c1, %c1) {
          %29 = memref.load %alloca_1[%arg14, %arg15, %arg16] {polymer.stmt.name = "S30_affine_load"} : memref<16x16x1xf32, 16>
          llvm.store %29, %arg7 : f32, !llvm.ptr
          scf.reduce 
        } {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"}
        scf.reduce 
      } {gpu.par.grid}
      llvm.return {polymer.stmt.name = "S35_llvm_return"}
    }
  }
}

Eliminated dead instances: [P0, P1, P2, P3] -> { S4_arith_index_cast[]; S1_memref_ataddr[]; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S0_llvm_mlir_constant[] }
Eliminated dead instances: [P0, P1, P2, P3] -> { S4_arith_index_cast[]; S1_memref_ataddr[]; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P3 and 0 <= i1 < P2 and i3 >= 0 and 16i3 < P0; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P3 and 0 <= i1 < P2; S0_llvm_mlir_constant[] }
