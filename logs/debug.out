gpu-affine-opt: Before opt:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c4_i32 = arith.constant 4 : i32
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %c16_i32 = arith.constant 16 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %1 = arith.index_cast %arg1 : i64 to index
  %2 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%2), symbol(%1), 1) {
    %3 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    %4 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %5 = llvm.addrspacecast %3 : !llvm.ptr<3> to !llvm.ptr
      %6 = llvm.addrspacecast %4 : !llvm.ptr<3> to !llvm.ptr
      %7 = arith.index_cast %arg12 : index to i32
      %8 = arith.index_cast %arg13 : index to i32
      %9 = arith.index_cast %arg15 : index to i32
      %10 = arith.index_cast %arg16 : index to i32
      %11 = arith.shli %arg10, %c4_i32 : i32
      %12 = arith.muli %11, %8 : i32
      %13 = arith.addi %12, %arg10 : i32
      %14 = arith.shli %7, %c4_i32 : i32
      %15 = arith.shli %arg11, %c4_i32 : i32
      %16 = arith.muli %10, %arg10 : i32
      %17 = arith.addi %16, %9 : i32
      %18 = arith.extui %10 : i32 to i64
      %19 = arith.extui %9 : i32 to i64
      %20 = llvm.getelementptr inbounds %5[0, %18, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %21 = arith.muli %10, %arg11 : i32
      %22 = arith.addi %21, %9 : i32
      %23 = llvm.getelementptr inbounds %6[0, %18, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %24:2 = scf.for %arg18 = %12 to %13 step %c16_i32 iter_args(%arg19 = %14, %arg20 = %0) -> (i32, f32)  : i32 {
        %31 = arith.addi %17, %arg18 : i32
        %32 = arith.extsi %31 : i32 to i64
        %33 = llvm.getelementptr inbounds %arg8[%32] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %34 = llvm.load %33 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %34, %20 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        %35 = arith.addi %22, %arg19 : i32
        %36 = arith.extsi %35 : i32 to i64
        %37 = llvm.getelementptr inbounds %arg9[%36] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %38 = llvm.load %37 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %38, %23 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %39 = scf.for %arg21 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg22 = %arg20) -> (f32)  : i32 {
          %41 = arith.extui %arg21 : i32 to i64
          %42 = llvm.getelementptr inbounds %5[0, %18, %41] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %43 = llvm.load %42 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %44 = llvm.getelementptr inbounds %6[0, %41, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %45 = llvm.load %44 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %46 = llvm.fmul %43, %45  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %47 = llvm.fadd %arg22, %46  {fastmathFlags = #llvm.fastmath<contract>} : f32
          scf.yield %47 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %40 = arith.addi %arg19, %15 : i32
        scf.yield %40, %39 : i32, f32
      }
      %25 = arith.muli %15, %8 : i32
      %26 = arith.addi %14, %9 : i32
      %27 = arith.addi %26, %21 : i32
      %28 = arith.addi %27, %25 : i32
      %29 = arith.extsi %28 : i32 to i64
      %30 = llvm.getelementptr inbounds %arg7[%29] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %24#1, %30 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Removed IVs:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c4_i32 = arith.constant 4 : i32
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %c16_i32 = arith.constant 16 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %1 = arith.index_cast %arg1 : i64 to index
  %2 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%2), symbol(%1), 1) {
    %3 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    %4 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %5 = llvm.addrspacecast %3 : !llvm.ptr<3> to !llvm.ptr
      %6 = llvm.addrspacecast %4 : !llvm.ptr<3> to !llvm.ptr
      %7 = arith.index_cast %arg12 : index to i32
      %8 = arith.index_cast %arg13 : index to i32
      %9 = arith.index_cast %arg15 : index to i32
      %10 = arith.index_cast %arg16 : index to i32
      %11 = arith.shli %arg10, %c4_i32 : i32
      %12 = arith.muli %11, %8 : i32
      %13 = arith.shli %7, %c4_i32 : i32
      %14 = arith.shli %arg11, %c4_i32 : i32
      %15 = arith.muli %10, %arg10 : i32
      %16 = arith.addi %15, %9 : i32
      %17 = arith.extui %10 : i32 to i64
      %18 = arith.extui %9 : i32 to i64
      %19 = llvm.getelementptr inbounds %5[0, %17, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %20 = arith.muli %10, %arg11 : i32
      %21 = arith.addi %20, %9 : i32
      %22 = llvm.getelementptr inbounds %6[0, %17, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %23 = arith.subi %arg10, %c1_i32 : i32
      %24 = arith.divui %23, %c16_i32 : i32
      %25 = arith.addi %24, %c1_i32 : i32
      %26 = scf.for %arg18 = %c0_i32 to %25 step %c1_i32 iter_args(%arg19 = %0) -> (f32)  : i32 {
        %33 = arith.muli %arg18, %14 : i32
        %34 = arith.addi %33, %13 : i32
        %35 = arith.muli %arg18, %c16_i32 : i32
        %36 = arith.addi %12, %35 : i32
        %37 = arith.addi %16, %36 : i32
        %38 = arith.extsi %37 : i32 to i64
        %39 = llvm.getelementptr inbounds %arg8[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %40 = llvm.load %39 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %40, %19 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        %41 = arith.addi %21, %34 : i32
        %42 = arith.extsi %41 : i32 to i64
        %43 = llvm.getelementptr inbounds %arg9[%42] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %44 = llvm.load %43 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %44, %22 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %45 = scf.for %arg20 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg21 = %arg19) -> (f32)  : i32 {
          %46 = arith.extui %arg20 : i32 to i64
          %47 = llvm.getelementptr inbounds %5[0, %17, %46] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %48 = llvm.load %47 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %49 = llvm.getelementptr inbounds %6[0, %46, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %50 = llvm.load %49 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %51 = llvm.fmul %48, %50  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %52 = llvm.fadd %arg21, %51  {fastmathFlags = #llvm.fastmath<contract>} : f32
          scf.yield %52 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        scf.yield %45 : f32
      }
      %27 = arith.muli %14, %8 : i32
      %28 = arith.addi %13, %9 : i32
      %29 = arith.addi %28, %20 : i32
      %30 = arith.addi %29, %27 : i32
      %31 = arith.extsi %30 : i32 to i64
      %32 = llvm.getelementptr inbounds %arg7[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %26, %32 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: To Affine:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg11 : i32 to index
  %6 = arith.index_cast %arg10 : i32 to index
  %7 = arith.index_cast %arg10 : i32 to index
  %8 = arith.index_cast %arg11 : i32 to index
  %9 = arith.index_cast %arg11 : i32 to index
  %10 = arith.index_cast %arg10 : i32 to index
  %11 = arith.index_cast %arg1 : i64 to index
  %12 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%12), symbol(%11), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %13 = affine.for %arg18 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%10] iter_args(%arg19 = %0) -> (f32) {
        %15 = affine.vector_load %2[(%arg16 * symbol(%7)) * 4 + %arg15 * 4 + %arg18 * 64 + (%arg13 * (symbol(%6) * 16)) * 4] : memref<?xi8>, vector<4xi8>
        affine.vector_store %15, %alloca[%arg16 * 64 + %arg15 * 4] : memref<1024xi8, 3>, vector<4xi8>
        %16 = affine.vector_load %1[(%arg16 * symbol(%5)) * 4 + %arg15 * 4 + %arg12 * 64 + (%arg18 * (symbol(%4) * 16)) * 4] : memref<?xi8>, vector<4xi8>
        affine.vector_store %16, %alloca_0[%arg16 * 64 + %arg15 * 4] : memref<1024xi8, 3>, vector<4xi8>
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %17 = affine.for %arg20 = 0 to 16 iter_args(%arg21 = %arg19) -> (f32) {
          %18 = affine.vector_load %alloca[%arg16 * 64 + %arg20 * 4] : memref<1024xi8, 3>, vector<4xi8>
          %19 = llvm.bitcast %18 : vector<4xi8> to f32
          %20 = affine.vector_load %alloca_0[%arg20 * 64 + %arg15 * 4] : memref<1024xi8, 3>, vector<4xi8>
          %21 = llvm.bitcast %20 : vector<4xi8> to f32
          %22 = llvm.fmul %19, %21  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %23 = llvm.fadd %arg21, %22  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %23 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        affine.yield %17 : f32
      }
      %14 = llvm.bitcast %13 : f32 to vector<4xi8>
      affine.vector_store %14, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%9)) * 4 + (%arg13 * (symbol(%8) * 16)) * 4] : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Distributed:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c1 = arith.constant 1 : index
  %c16 = arith.constant 16 : index
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg11 : i32 to index
  %6 = arith.index_cast %arg10 : i32 to index
  %7 = arith.index_cast %arg10 : i32 to index
  %8 = arith.index_cast %arg11 : i32 to index
  %9 = arith.index_cast %arg11 : i32 to index
  %10 = arith.index_cast %arg10 : i32 to index
  %11 = arith.index_cast %arg1 : i64 to index
  %12 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%12), symbol(%11), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    %alloca_1 = memref.alloca(%c16, %c16, %c1) : memref<?x?x?xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] : memref<?x?x?xf32, 16>
    } {gpu.par.block}
    affine.for %arg15 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%10] {
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %13 = affine.vector_load %2[(%arg17 * symbol(%7)) * 4 + %arg16 * 4 + %arg15 * 64 + (%arg13 * (symbol(%6) * 16)) * 4] : memref<?xi8>, vector<4xi8>
        affine.vector_store %13, %alloca[%arg17 * 64 + %arg16 * 4] : memref<1024xi8, 3>, vector<4xi8>
        %14 = affine.vector_load %1[(%arg17 * symbol(%5)) * 4 + %arg16 * 4 + %arg12 * 64 + (%arg15 * (symbol(%4) * 16)) * 4] : memref<?xi8>, vector<4xi8>
        affine.vector_store %14, %alloca_0[%arg17 * 64 + %arg16 * 4] : memref<1024xi8, 3>, vector<4xi8>
      } {gpu.par.block}
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %13 = affine.load %alloca_1[%arg16, %arg17, %arg18] : memref<?x?x?xf32, 16>
        %14 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %13) -> (f32) {
          %15 = affine.vector_load %alloca[%arg17 * 64 + %arg19 * 4] : memref<1024xi8, 3>, vector<4xi8>
          %16 = llvm.bitcast %15 : vector<4xi8> to f32
          %17 = affine.vector_load %alloca_0[%arg19 * 64 + %arg16 * 4] : memref<1024xi8, 3>, vector<4xi8>
          %18 = llvm.bitcast %17 : vector<4xi8> to f32
          %19 = llvm.fmul %16, %18  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %20 = llvm.fadd %arg20, %19  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %20 : f32
        }
        affine.store %14, %alloca_1[%arg16, %arg17, %arg18] : memref<?x?x?xf32, 16>
      } {gpu.par.block}
    }
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %13 = affine.load %alloca_1[%arg15, %arg16, %arg17] : memref<?x?x?xf32, 16>
      %14 = llvm.bitcast %13 : f32 to vector<4xi8>
      affine.vector_store %14, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%9)) * 4 + (%arg13 * (symbol(%8) * 16)) * 4] : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Canonicalized:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg10 : i32 to index
  %6 = arith.index_cast %arg1 : i64 to index
  %7 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%7), symbol(%6), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    %alloca_1 = memref.alloca() : memref<16x16x1xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] : memref<16x16x1xf32, 16>
    } {gpu.par.block}
    affine.for %arg15 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%5] {
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %8 = affine.vector_load %2[(%arg17 * symbol(%5)) * 4 + %arg16 * 4 + %arg15 * 64 + (%arg13 * (symbol(%5) * 16)) * 4] : memref<?xi8>, vector<4xi8>
        affine.vector_store %8, %alloca[%arg17 * 64 + %arg16 * 4] : memref<1024xi8, 3>, vector<4xi8>
        %9 = affine.vector_load %1[(%arg17 * symbol(%4)) * 4 + %arg16 * 4 + %arg12 * 64 + (%arg15 * (symbol(%4) * 16)) * 4] : memref<?xi8>, vector<4xi8>
        affine.vector_store %9, %alloca_0[%arg17 * 64 + %arg16 * 4] : memref<1024xi8, 3>, vector<4xi8>
      } {gpu.par.block}
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %8 = affine.load %alloca_1[%arg16, %arg17, %arg18] : memref<16x16x1xf32, 16>
        %9 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %8) -> (f32) {
          %10 = affine.vector_load %alloca[%arg17 * 64 + %arg19 * 4] : memref<1024xi8, 3>, vector<4xi8>
          %11 = llvm.bitcast %10 : vector<4xi8> to f32
          %12 = affine.vector_load %alloca_0[%arg19 * 64 + %arg16 * 4] : memref<1024xi8, 3>, vector<4xi8>
          %13 = llvm.bitcast %12 : vector<4xi8> to f32
          %14 = llvm.fmul %11, %13  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %15 = llvm.fadd %arg20, %14  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %15 : f32
        }
        affine.store %9, %alloca_1[%arg16, %arg17, %arg18] : memref<16x16x1xf32, 16>
      } {gpu.par.block}
    }
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %8 = affine.load %alloca_1[%arg15, %arg16, %arg17] : memref<16x16x1xf32, 16>
      %9 = llvm.bitcast %8 : f32 to vector<4xi8>
      affine.vector_store %9, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%4)) * 4 + (%arg13 * (symbol(%4) * 16)) * 4] : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
Schedule:
domain: "[P0, P1, P2, P3] -> { S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S25_llvm_fadd[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S7_arith_index_cast[]; S32_affine_vector_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S18_affine_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S19_affine_store_var[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S31_llvm_bitcast[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S1_memref_ataddr[]; S21_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S23_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S24_llvm_fmul[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S5_arith_index_cast[]; S14_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S30_affine_load[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S22_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S16_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S11_affine_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S4_arith_index_cast[]; S27_affine_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S33_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S0_llvm_mlir_constant[]; S12_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S20_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S3_memref_ataddr[]; S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
child:
  sequence:
  - filter: "[P0, P1, P2, P3] -> { S0_llvm_mlir_constant[] }"
  - filter: "[P0, P1, P2, P3] -> { S1_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S2_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S3_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S4_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S5_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S6_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S7_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S10_memref_alloca[i0, i1, i2]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S30_affine_load[i0, i1, i2, i3, i4, i5]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S34_affine_yield[i0, i1, i2]; S8_memref_alloca[i0, i1, i2]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S11_affine_store[i0, i1, i2, i3, i4, i5]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S33_affine_yield[i0, i1, i2, i3, i4, i5]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S12_affine_yield[i0, i1, i2, i3, i4, i5]; S9_memref_alloca[i0, i1, i2]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
    child:
      schedule: "[P0, P1, P2, P3] -> L16.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i0)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i0)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i0)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S10_memref_alloca[i0, i1, i2] -> [(i0)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i0)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S34_affine_yield[i0, i1, i2] -> [(i0)]; S8_memref_alloca[i0, i1, i2] -> [(i0)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i0)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i0)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i0)]; S9_memref_alloca[i0, i1, i2] -> [(i0)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)] }]"
      permutable: 1
      child:
        schedule: "[P0, P1, P2, P3] -> L15.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i1)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i1)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i1)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S10_memref_alloca[i0, i1, i2] -> [(i1)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i1)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S34_affine_yield[i0, i1, i2] -> [(i1)]; S8_memref_alloca[i0, i1, i2] -> [(i1)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i1)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i1)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i1)]; S9_memref_alloca[i0, i1, i2] -> [(i1)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)] }]"
        permutable: 1
        child:
          schedule: "[P0, P1, P2, P3] -> L14.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i2)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i2)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i2)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S10_memref_alloca[i0, i1, i2] -> [(i2)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i2)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S34_affine_yield[i0, i1, i2] -> [(i2)]; S8_memref_alloca[i0, i1, i2] -> [(i2)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i2)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i2)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i2)]; S9_memref_alloca[i0, i1, i2] -> [(i2)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)] }]"
          permutable: 1
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S9_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S10_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S12_affine_yield[i0, i1, i2, i3, i4, i5]; S11_affine_store[i0, i1, i2, i3, i4, i5] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i3)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i3)] }]"
                permutable: 1
                child:
                  schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i4)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i4)] }]"
                  permutable: 1
                  child:
                    schedule: "[P0, P1, P2, P3] -> L0.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i5)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i5)] }]"
                    permutable: 1
                    child:
                      sequence:
                      - filter: "[P0, P1, P2, P3] -> { S11_affine_store[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S12_affine_yield[i0, i1, i2, i3, i4, i5] }"
            - filter: "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S29_affine_yield[i0, i1, i2, i3]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L10.affine.for[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S29_affine_yield[i0, i1, i2, i3] -> [(i3)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)] }]"
                child:
                  sequence:
                  - filter: "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                    child:
                      schedule: "[P0, P1, P2, P3] -> L5.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)] }]"
                      permutable: 1
                      child:
                        schedule: "[P0, P1, P2, P3] -> L4.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)] }]"
                        permutable: 1
                        child:
                          schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)] }]"
                          permutable: 1
                          child:
                            sequence:
                            - filter: "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                  - filter: "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] }"
                    child:
                      schedule: "[P0, P1, P2, P3] -> L9.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)] }]"
                      permutable: 1
                      child:
                        schedule: "[P0, P1, P2, P3] -> L8.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)] }]"
                        permutable: 1
                        child:
                          schedule: "[P0, P1, P2, P3] -> L7.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)] }]"
                          permutable: 1
                          child:
                            sequence:
                            - filter: "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] }"
                              child:
                                schedule: "[P0, P1, P2, P3] -> L6.affine.for[{ S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)] }]"
                                child:
                                  sequence:
                                  - filter: "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] }"
                            - filter: "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, i2, i3, i4, i5]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5]; S30_affine_load[i0, i1, i2, i3, i4, i5] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L13.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i3)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i3)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i3)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i3)] }]"
                permutable: 1
                child:
                  schedule: "[P0, P1, P2, P3] -> L12.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i4)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i4)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i4)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i4)] }]"
                  permutable: 1
                  child:
                    schedule: "[P0, P1, P2, P3] -> L11.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i5)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i5)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i5)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i5)] }]"
                    permutable: 1
                    child:
                      sequence:
                      - filter: "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, i2, i3, i4, i5] }"
            - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2] }"
Accesses:
domain: "[P0, P1, P2, P3] -> { S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S25_llvm_fadd[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S7_arith_index_cast[]; S32_affine_vector_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S18_affine_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S19_affine_store_var[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S31_llvm_bitcast[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S1_memref_ataddr[]; S21_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S23_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S24_llvm_fmul[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S5_arith_index_cast[]; S14_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S30_affine_load[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S22_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S16_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S11_affine_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S4_arith_index_cast[]; S27_affine_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S33_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S0_llvm_mlir_constant[]; S12_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S20_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S3_memref_ataddr[]; S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
accesses:
  - S0_llvm_mlir_constant:
  - S1_memref_ataddr:
  - S2_memref_ataddr:
  - S3_memref_ataddr:
  - S4_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[] }"
  - S5_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S5_arith_index_cast[] -> A_llvm_func_arg_10_1[] }"
  - S6_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }"
  - S7_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[] }"
  - S8_memref_alloca:
  - S9_memref_alloca:
  - S10_memref_alloca:
  - S11_affine_store:
        - must_write "[P0, P1, P2, P3] -> { S11_affine_store[i0, i1, i2, i3, i4, i5] -> A_memref_alloca_res_4[i3, i4, i5] }"
  - S12_affine_yield:
  - S13_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - must_write "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_6[] }"
  - S14_affine_vector_store:
        - must_write "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_7[4i4 + 64i5] }"
        - read "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_6[] }"
  - S15_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - must_write "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_9[] }"
  - S16_affine_vector_store:
        - must_write "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_10[4i4 + 64i5] }"
        - read "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_9[] }"
  - S17_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_vector_load_res_6[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_vector_load_res_9[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
  - S18_affine_load:
        - read "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_4[i4, i5, i6] }"
        - must_write "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_load_res_11[] }"
  - S19_affine_store_var:
        - read "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> A_affine_load_res_11[] }"
        - must_write "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> A_affine_for_res_12[] }"
  - S20_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_memref_alloca_res_7[64i5 + 4i7] }"
        - must_write "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_13[] }"
  - S21_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_14[] }"
        - read "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_13[] }"
  - S22_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_memref_alloca_res_10[4i4 + 64i7] }"
        - must_write "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_15[] }"
  - S23_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_16[] }"
        - read "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_15[] }"
  - S24_llvm_fmul:
        - must_write "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fmul_res_17[] }"
        - read "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_14[] }"
        - read "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_16[] }"
  - S25_llvm_fadd:
        - must_write "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fadd_res_18[] }"
        - read "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_for_res_12[] }"
        - read "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fmul_res_17[] }"
  - S26_affine_yield:
        - must_write "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_for_res_12[] }"
        - read "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fadd_res_18[] }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_affine_vector_load_res_13[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_bitcast_res_14[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_affine_vector_load_res_15[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_bitcast_res_16[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_fmul_res_17[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_fadd_res_18[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
  - S27_affine_store:
        - must_write "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_4[i4, i5, i6] }"
        - read "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_for_res_12[] }"
  - S28_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_load_res_11[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_for_res_12[] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
  - S29_affine_yield:
  - S30_affine_load:
        - read "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] -> A_memref_alloca_res_4[i3, i4, i5] }"
        - must_write "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] -> A_affine_load_res_19[] }"
  - S31_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> A_llvm_bitcast_res_20[] }"
        - read "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> A_affine_load_res_19[] }"
  - S32_affine_vector_store:
        - may_write "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, 0, i3, i4, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
        - read "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> A_llvm_bitcast_res_20[] }"
  - S33_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, 0, i3, i4, 0] -> A_affine_load_res_19[] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, 0, i3, i4, 0] -> A_llvm_bitcast_res_20[] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
  - S34_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
  - S35_llvm_return:
Schedule:
domain: "[P0, P1, P2, P3] -> { S4_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S1_memref_ataddr[]; RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S7_arith_index_cast[]; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S0_llvm_mlir_constant[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
child:
  sequence:
  - filter: "[P0, P1, P2, P3] -> { S0_llvm_mlir_constant[] }"
  - filter: "[P0, P1, P2, P3] -> { S1_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S2_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S3_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S4_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S5_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S6_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S7_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2]; RS2_affine_parallel[i0, i1, i2, i3]; S8_memref_alloca[i0, i1, i2]; RS1_affine_parallel[i0, i1, i2, i3]; RS3_affine_parallel[i0, i1, i2]; S29_affine_yield[i0, i1, i2, i3]; S10_memref_alloca[i0, i1, i2]; S9_memref_alloca[i0, i1, i2]; RS0_affine_parallel[i0, i1, i2] }"
    child:
      schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; S9_memref_alloca[i0, i1, i2] -> [(i0)]; S8_memref_alloca[i0, i1, i2] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; S29_affine_yield[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; S10_memref_alloca[i0, i1, i2] -> [(i0)]; S34_affine_yield[i0, i1, i2] -> [(i0)] }]"
      permutable: 1
      child:
        schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; S9_memref_alloca[i0, i1, i2] -> [(i1)]; S8_memref_alloca[i0, i1, i2] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; S29_affine_yield[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; S10_memref_alloca[i0, i1, i2] -> [(i1)]; S34_affine_yield[i0, i1, i2] -> [(i1)] }]"
        permutable: 1
        child:
          schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i2)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i2)]; S9_memref_alloca[i0, i1, i2] -> [(i2)]; S8_memref_alloca[i0, i1, i2] -> [(i2)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i2)]; S29_affine_yield[i0, i1, i2, i3] -> [(i2)]; RS3_affine_parallel[i0, i1, i2] -> [(i2)]; S10_memref_alloca[i0, i1, i2] -> [(i2)]; S34_affine_yield[i0, i1, i2] -> [(i2)] }]"
          permutable: 1
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S9_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S10_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L0.affine.for[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)]; S29_affine_yield[i0, i1, i2, i3] -> [(i3)] }]"
                child:
                  sequence:
                  - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
                  - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
                  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2] }"
Accesses:
domain: "[P0, P1, P2, P3] -> { S4_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S1_memref_ataddr[]; RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S7_arith_index_cast[]; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S0_llvm_mlir_constant[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
accesses:
  - S0_llvm_mlir_constant:
  - S1_memref_ataddr:
  - S2_memref_ataddr:
  - S3_memref_ataddr:
  - S4_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[] }"
  - S5_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S5_arith_index_cast[] -> A_llvm_func_arg_10_1[] }"
  - S6_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }"
  - S7_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[] }"
  - S8_memref_alloca:
  - S9_memref_alloca:
  - S10_memref_alloca:
  - S29_affine_yield:
  - S34_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
  - S35_llvm_return:
  - RS0_affine_parallel:
        - must_write "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P1 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
  - RS1_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }"
        - must_write "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - read "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }"
        - must_write "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
  - RS2_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P1 > 0 and P2 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - must_write "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P1 > 0 and P2 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
  - RS3_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P1 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
        - may_write "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
ReductionTagMap: [P0, P1, P2, P3] -> {  }
TaggedStmtDomain: [P0, P1, P2, P3] -> { [RS2_affine_parallel[i0, i1, i2, i3] -> S18_affine_load_Read0[]]; [RS0_affine_parallel[i0, i1, i2] -> S11_affine_store_Write0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S14_affine_vector_store_Write0[]]; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S27_affine_store_Write0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S20_affine_vector_load_Read0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield2[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield1[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S15_affine_vector_load_Read0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S22_affine_vector_load_Read0[]]; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]]; [RS3_affine_parallel[i0, i1, i2] -> S32_affine_vector_store_MayWrite0[]]; [RS3_affine_parallel[i0, i1, i2] -> S30_affine_load_Read0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S16_affine_vector_store_Write0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S13_affine_vector_load_Read0[]]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] }
dep_order for A_llvm_func_arg_11_0 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_func_arg_10_1 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_func_arg_1_2 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_func_arg_0_3 [P0, P1, P2, P3] -> {  }
dep_order for A_memref_alloca_res_4 [P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and o1 > i1 and o1 < P0 and o3 >= 0 and 16o3 < P2); RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and 16i3 < P2 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 >= 0 and o3 < i3) or (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and i3 >= 0 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 > i3 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and 16i3 < P2 and o1 > i1 and o1 < P0 and o3 >= 0 and o3 < i3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i3 >= 0 and o1 > i1 and o1 < P0 and o3 > i3 and 16o3 < P2); RS2_affine_parallel[i0, i1, i2, i3] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and i3 >= 0 and 16i3 < P2 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and o1 > i1 and o1 < P0); RS3_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and o1 > i1 and o1 < P0) }
dep_order for A_memref_ataddr_res_5 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_vector_load_res_6 [P0, P1, P2, P3] -> {  }
dep_order for A_memref_alloca_res_7 [P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and i3 >= 0 and 16i3 < P2 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and o1 > i1 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2) }
dep_order for A_memref_ataddr_res_8 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_vector_load_res_9 [P0, P1, P2, P3] -> {  }
dep_order for A_memref_alloca_res_10 [P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and i3 >= 0 and 16i3 < P2 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and o1 > i1 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2) }
dep_order for A_affine_load_res_11 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_for_res_12 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_vector_load_res_13 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_bitcast_res_14 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_vector_load_res_15 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_bitcast_res_16 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_fmul_res_17 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_fadd_res_18 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_load_res_19 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_bitcast_res_20 [P0, P1, P2, P3] -> {  }
dep_order for A_memref_ataddr_res_21 [P0, P1, P2, P3] -> {  }
ReductionTagMap: [P0, P1, P2, P3] -> {  }
TaggedStmtDomain: [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_8[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_10[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]]; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_ataddr_res_21[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_7[]]; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]]; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]]; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_5[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] }
dep_order for A_llvm_func_arg_11_0 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_func_arg_10_1 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_func_arg_1_2 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_func_arg_0_3 [P0, P1, P2, P3] -> {  }
dep_order for A_memref_alloca_res_4 [P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and o1 > i1 and o1 < P0 and o3 >= 0 and 16o3 < P2); RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and 16i3 < P2 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 >= 0 and o3 < i3) or (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and i3 >= 0 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 > i3 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and 16i3 < P2 and o1 > i1 and o1 < P0 and o3 >= 0 and o3 < i3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i3 >= 0 and o1 > i1 and o1 < P0 and o3 > i3 and 16o3 < P2); RS2_affine_parallel[i0, i1, i2, i3] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and i3 >= 0 and 16i3 < P2 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and o1 > i1 and o1 < P0); RS3_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and o1 > i1 and o1 < P0) }
dep_order for A_memref_ataddr_res_5 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_vector_load_res_6 [P0, P1, P2, P3] -> {  }
dep_order for A_memref_alloca_res_7 [P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and i3 >= 0 and 16i3 < P2 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and o1 > i1 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2) }
dep_order for A_memref_ataddr_res_8 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_vector_load_res_9 [P0, P1, P2, P3] -> {  }
dep_order for A_memref_alloca_res_10 [P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P0 and i3 >= 0 and 16i3 < P2 and o0 > i0 and o0 < P1 and o1 >= 0 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and o1 > i1 and o1 < P0 and o3 >= 0 and 16o3 < P2) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P1 and i1 >= 0 and i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2) }
dep_order for A_affine_load_res_11 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_for_res_12 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_vector_load_res_13 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_bitcast_res_14 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_vector_load_res_15 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_bitcast_res_16 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_fmul_res_17 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_fadd_res_18 [P0, P1, P2, P3] -> {  }
dep_order for A_affine_load_res_19 [P0, P1, P2, P3] -> {  }
dep_order for A_llvm_bitcast_res_20 [P0, P1, P2, P3] -> {  }
dep_order for A_memref_ataddr_res_21 [P0, P1, P2, P3] -> {  }
tagged_reads [P0, P1, P2, P3] -> { [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] -> A_llvm_func_arg_10_1[]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]] -> A_llvm_func_arg_11_0[]; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P1 > 0 and P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]] -> A_llvm_func_arg_0_3[]; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P1 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]] -> A_llvm_func_arg_1_2[]; [RS1_affine_parallel[i0, i1, 0, i3] -> S15_affine_vector_load_Read0[]] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> S13_affine_vector_load_Read0[]] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }
atagged_reads [P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[]] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]] -> A_llvm_func_arg_1_2[]; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[]] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]] -> A_llvm_func_arg_10_1[]; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]] -> A_llvm_func_arg_0_3[]; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P1 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]] -> A_llvm_func_arg_11_0[] }
reads [P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]; RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : P0 > 0 and P1 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P0 > 0 and P1 > 0 and P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]; S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }
async_reads [P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }
tagged_may_writes [P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P1 and 0 <= i1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
atagged_may_writes [P0, P1, P2, P3] -> { [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[]] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P1 and 0 <= i1 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
may_writes [P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }
tagged_must_writes [P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
atagged_must_writes [P0, P1, P2, P3] -> { [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
must_writes [P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
async_must_writes [P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
tagged_must_kills [P0, P1, P2, P3] -> { [S34_affine_yield[i0, i1, 0] -> S34_affine_yield1[]] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P1 and 0 <= i1 < P0; [S34_affine_yield[i0, i1, 0] -> S34_affine_yield0[]] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P1 and 0 <= i1 < P0; [S34_affine_yield[i0, i1, 0] -> S34_affine_yield2[]] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P1 and 0 <= i1 < P0 }
atagged_must_kills [P0, P1, P2, P3] -> { [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P1 and 0 <= i1 < P0; [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P1 and 0 <= i1 < P0; [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }
must_kills [P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P1 and 0 <= i1 < P0; S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P1 and 0 <= i1 < P0; S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }
live_in [P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]; S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]; S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }
live_out [P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P1 and 0 <= i1 < P0 }
independence [P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : o2 < i2 or o2 > i2; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, i1, i2] : o0 < i0 or o0 > i0; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, i2] : o1 < i1 or o1 > i1; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, o1, o2] : o2 > i2 or o2 < i2; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, i1, i2] : o0 > i0 or o0 < i0; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, o1, i2] : o1 > i1 or o1 < i1; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, i3] : o2 > i2 or o2 < i2; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[i0, i1, i2, o3] : o3 > i3 or o3 < i3; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, i2, i3] : o1 > i1 or o1 < i1; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, i1, i2, i3] : o0 > i0 or o0 < i0; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, i3] : o2 > i2 or o2 < i2; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[i0, i1, i2, o3] : o3 > i3 or o3 < i3; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, i2, i3] : o1 > i1 or o1 < i1; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, i1, i2, i3] : o0 > i0 or o0 < i0; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, o1, o2] : o2 < i2 or o2 > i2; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, i1, i2] : o0 < i0 or o0 > i0; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, o1, i2] : o1 < i1 or o1 > i1; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, o1, o2, i3] : o2 > i2 or o2 < i2; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[i0, i1, i2, o3] : o3 > i3 or o3 < i3; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, o1, i2, i3] : o1 > i1 or o1 < i1; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, i1, i2, i3] : o0 > i0 or o0 < i0 }
dep_flow [P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 < P0 }
tagged_dep_flow [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2 }
atagged_dep_flow [P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> A_memref_alloca_res_4[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> A_memref_alloca_res_4[]] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }
dep_false [P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 <= -2 + P0 and -16 + P2 <= 16i3 < P2; RS2_affine_parallel[i0, -1 + P0, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P0 > 0 and P2 > 0 and 0 <= i0 <= -2 + P1 and -16 + P2 <= 16i3 < P2; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 <= -2 + P0 and -16 + P2 <= 16i3 < P2; RS1_affine_parallel[i0, -1 + P0, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P0 > 0 and P2 > 0 and 0 <= i0 <= -2 + P1 and -16 + P2 <= 16i3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P1 and 0 <= i1 <= -2 + P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; RS2_affine_parallel[i0, -1 + P0, 0, i3] -> RS0_affine_parallel[1 + i0, 0, 0] : P0 > 0 and 0 <= i0 <= -2 + P1 and i3 >= 0 and -16 + P2 <= 16i3 < P2; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P1 and 0 <= i1 <= -2 + P0; RS3_affine_parallel[i0, -1 + P0, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P0 > 0 and 0 <= i0 <= -2 + P1; RS0_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 <= -2 + P0; RS0_affine_parallel[i0, -1 + P0, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P0 > 0 and P2 <= 0 and 0 <= i0 <= -2 + P1 }
dep_forced [P0, P1, P2, P3] -> {  }
dep_order [P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 }
tagged_dep_order [P0, P1, P2, P3] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2 }
dep_async [P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }
array_order [P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0 and ((16i3 < P2 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P2)); RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0 and ((16i3 < P2 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P2)); RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 }
tagger [P0, P1, P2, P3] -> { [RS2_affine_parallel[i0, i1, i2, i3] -> S18_affine_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS0_affine_parallel[i0, i1, i2] -> S11_affine_store_Write0[]] -> RS0_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S14_affine_vector_store_Write0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]] -> S6_arith_index_cast[]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]] -> S4_arith_index_cast[]; [RS2_affine_parallel[i0, i1, i2, i3] -> S27_affine_store_Write0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS2_affine_parallel[i0, i1, i2, i3] -> S20_affine_vector_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield2[]] -> S34_affine_yield[(i0), (i1), (i2)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield1[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S15_affine_vector_load_Read0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield0[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> S22_affine_vector_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]] -> S7_arith_index_cast[]; [RS3_affine_parallel[i0, i1, i2] -> S32_affine_vector_store_MayWrite0[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS3_affine_parallel[i0, i1, i2] -> S30_affine_load_Read0[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S16_affine_vector_store_Write0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S13_affine_vector_load_Read0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] -> S5_arith_index_cast[] }
atagger [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]] -> RS0_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_8[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_4[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_10[]] -> S34_affine_yield[(i0), (i1), (i2)]; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]] -> S4_arith_index_cast[]; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]] -> S7_arith_index_cast[]; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]] -> S6_arith_index_cast[]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_7[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_5[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]] -> S5_arith_index_cast[]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_ataddr_res_21[]] -> RS3_affine_parallel[(i0), (i1), (i2)] }
schedule
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
child:
  schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; RS0_affine_parallel[i0, i1, i2] -> [(i0)] }]"
  permutable: 1
  child:
    schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; RS0_affine_parallel[i0, i1, i2] -> [(i1)] }]"
    permutable: 1
    child:
      schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(0)]; RS3_affine_parallel[i0, i1, i2] -> [(0)]; RS0_affine_parallel[i0, i1, i2] -> [(0)] }]"
      permutable: 1
      child:
        sequence:
        - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
        - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
          child:
            schedule: "[P0, P1, P2, P3] -> L0.affine.for[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
            child:
              sequence:
              - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
              - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
        - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
Schedule constraints:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
validity: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 < P0; RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2 }"
proximity: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P1 and 0 <= i1 <= -2 + P0; RS3_affine_parallel[i0, -1 + P0, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P0 > 0 and 0 <= i0 <= -2 + P1; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 <= -2 + P0 and -16 + P2 <= 16i3 < P2; RS2_affine_parallel[i0, -1 + P0, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P0 > 0 and P2 > 0 and 0 <= i0 <= -2 + P1 and -16 + P2 <= 16i3 < P2; RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P1 and 0 <= i1 <= -2 + P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; RS2_affine_parallel[i0, -1 + P0, 0, i3] -> RS0_affine_parallel[1 + i0, 0, 0] : P0 > 0 and 0 <= i0 <= -2 + P1 and i3 >= 0 and -16 + P2 <= 16i3 < P2; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 <= -2 + P0 and -16 + P2 <= 16i3 < P2; RS1_affine_parallel[i0, -1 + P0, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P0 > 0 and P2 > 0 and 0 <= i0 <= -2 + P1 and -16 + P2 <= 16i3 < P2; RS0_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 <= -2 + P0; RS0_affine_parallel[i0, -1 + P0, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P0 > 0 and P2 <= 0 and 0 <= i0 <= -2 + P1; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0 }"
anti_proximity: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }"
live_range_span: "[P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> A_memref_alloca_res_4[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and o3 > 0 and 16o3 < P2; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> A_memref_alloca_res_4[]] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> A_memref_alloca_res_4[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2 and o3 > i3 and o3 > 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and 16i3 < P2 and ((P2 > 0 and 16i3 >= -16 + P2) or (i3 >= 0 and 16i3 <= -17 + P2)); [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and (P2 <= 0 or P2 >= 17 or (0 < P2 <= 16)); [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 }"
coincidence: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0 and ((16i3 < P2 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P2)); RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0 and ((16i3 < P2 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P2)); RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 }"
condition: "[P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P2 <= 0 and 0 <= i0 < P1 and 0 <= i1 < P0; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P2 > 0 and 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and -16 + P2 <= 16i3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 <= -17 + P2 }"
conditional_validity: "[P0, P1, P2, P3] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P0 and i0 < o0 < P1 and 0 <= o1 < P0; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P1 and i1 >= 0 and i1 < o1 < P0; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2 and i0 < o0 < P1 and 0 <= o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P1 and i1 >= 0 and i3 >= 0 and 16i3 < P2 and i1 < o1 < P0 and o3 >= 0 and 16o3 < P2; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and o3 > i3 and 16o3 < P2 }"
New Schedule:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 }"
child:
  schedule: "[P0, P1, P2, P3] -> [{ RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)] }]"
  permutable: 1
  coincident: [ 1 ]
  child:
    schedule: "[P0, P1, P2, P3] -> [{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)] }]"
    permutable: 1
    coincident: [ 1 ]
    child:
      sequence:
      - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
      - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
        child:
          schedule: "[P0, P1, P2, P3] -> [{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
      - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
New AST:
iterator:
  id: c0
init:
  val: 0
cond:
  op: lt
  args:
  - id: c0
  - id: P1@0x3f2e7fb0
inc:
  val: 1
body:
  iterator:
    id: c1
  init:
    val: 0
  cond:
    op: lt
    args:
    - id: c1
    - id: P0@0x3f2e7ec0
  inc:
    val: 1
  body:
  - user:
      op: call
      args:
      - id: RS0_affine_parallel@0x3f2faf40
      - id: c0
      - id: c1
      - val: 0
  - iterator:
      id: c2
    init:
      val: 0
    cond:
      op: le
      args:
      - id: c2
      - op: fdiv_q
        args:
        - op: sub
          args:
          - id: P2@0x3f31fed0
          - val: 1
        - val: 16
    inc:
      val: 1
    body:
    - user:
        op: call
        args:
        - id: RS1_affine_parallel@0x3f2e45e0
        - id: c0
        - id: c1
        - val: 0
        - id: c2
    - user:
        op: call
        args:
        - id: RS2_affine_parallel@0x3f2fb1e0
        - id: c0
        - id: c1
        - val: 0
        - id: c2
  - user:
      op: call
      args:
      - id: RS3_affine_parallel@0x3f31e2e0
      - id: c0
      - id: c1
      - val: 0
/scr/ivan/src/transformer-llvm-project/polly/lib/External/isl/isl_ctx.c:295: isl_ctx not freed as some objects still reference it
gpu-affine-opt: After opt:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %5 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %6 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %7 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  "affine.parallel"(%7, %6) <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<()[s0, s1] -> (s0, s1, 1)>}> ({
  ^bb0(%arg12: index, %arg13: index, %arg14: index):
    %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
    %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
    %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S10_memref_alloca"} : () -> memref<16x16x1xf32, 16>
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg27: index, %arg28: index, %arg29: index):
      "affine.store"(%0, %10, %arg27, %arg28, %arg29) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S11_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    "affine.for"(%5) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 1, 0>, step = 1 : index, upperBoundMap = affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>}> ({
    ^bb0(%arg18: index):
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg24: index, %arg25: index, %arg26: index):
        %21 = "affine.vector_load"(%2, %arg25, %arg24, %arg13, %arg18, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%21, %8, %arg25, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %22 = "affine.vector_load"(%1, %arg25, %arg24, %arg18, %arg12, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%22, %9, %arg25, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg19: index, %arg20: index, %arg21: index):
        %13 = "affine.load"(%10, %arg19, %arg20, %arg21) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S18_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
        "affine.store_var"(%13, %14) <{type = "for.iv.init"}> {polymer.stmt.name = "S19_affine_store_var"} : (f32, f32) -> ()
        %14 = "affine.for"(%13) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg22: index, %arg23: f32):
          %15 = "affine.vector_load"(%8, %arg20, %arg22) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %16 = "llvm.bitcast"(%15) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %17 = "affine.vector_load"(%9, %arg22, %arg19) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %18 = "llvm.bitcast"(%17) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %19 = "llvm.fmul"(%16, %18) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %20 = "llvm.fadd"(%arg23, %19) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%20) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "affine.store"(%14, %10, %arg19, %arg20, %arg21) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S27_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S28_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"} : () -> ()
      "affine.yield"() {polymer.stmt.name = "S29_affine_yield"} : () -> ()
    }) : (index) -> ()
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg15: index, %arg16: index, %arg17: index):
      %11 = "affine.load"(%10, %arg15, %arg16, %arg17) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S30_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
      %12 = "llvm.bitcast"(%11) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%12, %3, %arg12, %arg15, %arg16, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S33_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"} : () -> ()
    "affine.yield"() {polymer.stmt.name = "S34_affine_yield"} : () -> ()
  }) {gpu.par.grid} : (index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
gpu-affine-opt: After gpuify:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 {polymer.stmt.name = "S4_arith_index_cast"} : i32 to index
  %5 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
  %6 = arith.index_cast %arg1 {polymer.stmt.name = "S6_arith_index_cast"} : i64 to index
  %7 = arith.index_cast %arg0 {polymer.stmt.name = "S7_arith_index_cast"} : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%7), symbol(%6), 1) {
    %alloca = memref.alloca() {polymer.stmt.name = "S8_memref_alloca"} : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() {polymer.stmt.name = "S9_memref_alloca"} : memref<1024xi8, 3>
    %alloca_1 = memref.alloca() {polymer.stmt.name = "S10_memref_alloca"} : memref<16x16x1xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S11_affine_store"} : memref<16x16x1xf32, 16>
      "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
      affine.for %arg18 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%5] {
        %10 = affine.vector_load %2[(%arg16 * symbol(%5)) * 4 + %arg15 * 4 + %arg18 * 64 + (%arg13 * (symbol(%5) * 16)) * 4] {polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        affine.vector_store %10, %alloca[%arg16 * 64 + %arg15 * 4] {polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        %11 = affine.vector_load %1[(%arg16 * symbol(%4)) * 4 + %arg15 * 4 + %arg12 * 64 + (%arg18 * (symbol(%4) * 16)) * 4] {polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
        affine.vector_store %11, %alloca_0[%arg16 * 64 + %arg15 * 4] {polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %12 = affine.load %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S18_affine_load"} : memref<16x16x1xf32, 16>
        %13 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %12) -> (f32) {
          %14 = affine.vector_load %alloca[%arg16 * 64 + %arg19 * 4] {polymer.stmt.name = "S20_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
          %15 = llvm.bitcast %14 {polymer.stmt.name = "S21_llvm_bitcast"} : vector<4xi8> to f32
          %16 = affine.vector_load %alloca_0[%arg19 * 64 + %arg15 * 4] {polymer.stmt.name = "S22_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
          %17 = llvm.bitcast %16 {polymer.stmt.name = "S23_llvm_bitcast"} : vector<4xi8> to f32
          %18 = llvm.fmul %15, %17  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
          %19 = llvm.fadd %arg20, %18  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
          affine.yield {polymer.stmt.name = "S26_affine_yield"} %19 : f32
        }
        affine.store %13, %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S27_affine_store"} : memref<16x16x1xf32, 16>
      }
      "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
      %8 = affine.load %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S30_affine_load"} : memref<16x16x1xf32, 16>
      %9 = llvm.bitcast %8 {polymer.stmt.name = "S31_llvm_bitcast"} : f32 to vector<4xi8>
      affine.vector_store %9, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%4)) * 4 + (%arg13 * (symbol(%4) * 16)) * 4] {polymer.stmt.name = "S32_affine_vector_store"} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"}
  } {gpu.par.grid}
  llvm.return {polymer.stmt.name = "S35_llvm_return"}
}
#map = affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi64>>, #dlti.dl_entry<i128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi64>>, #dlti.dl_entry<i64, dense<64> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f16, dense<16> : vector<2xi64>>, #dlti.dl_entry<f64, dense<64> : vector<2xi64>>, #dlti.dl_entry<i16, dense<16> : vector<2xi64>>, #dlti.dl_entry<i32, dense<32> : vector<2xi64>>, #dlti.dl_entry<i1, dense<8> : vector<2xi64>>, #dlti.dl_entry<i8, dense<8> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi64>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i64>, #dlti.dl_entry<"dlti.endianness", "little">>, gpu.container_module} {
  gpu.module @__mlir_gpu_module [#nvvm.target<chip = "sm_80">]  {
    llvm.comdat @__llvm_global_comdat {
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs any
      llvm.comdat_selector @_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii any
      llvm.comdat_selector @_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii any
    }
    llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
      %0 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
      %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
      %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
      %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
      %4 = arith.index_cast %arg11 {polymer.stmt.name = "S4_arith_index_cast"} : i32 to index
      %5 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
      %6 = arith.index_cast %arg1 {polymer.stmt.name = "S6_arith_index_cast"} : i64 to index
      %7 = arith.index_cast %arg0 {polymer.stmt.name = "S7_arith_index_cast"} : i64 to index
      affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%7), symbol(%6), 1) {
        %alloca = memref.alloca() {polymer.stmt.name = "S8_memref_alloca"} : memref<1024xi8, 3>
        %alloca_0 = memref.alloca() {polymer.stmt.name = "S9_memref_alloca"} : memref<1024xi8, 3>
        %alloca_1 = memref.alloca() {polymer.stmt.name = "S10_memref_alloca"} : memref<16x16x1xf32, 16>
        affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
          affine.store %0, %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S11_affine_store"} : memref<16x16x1xf32, 16>
          "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
          affine.for %arg18 = 0 to #map()[%5] {
            %10 = affine.vector_load %2[(%arg16 * symbol(%5)) * 4 + %arg15 * 4 + %arg18 * 64 + (%arg13 * (symbol(%5) * 16)) * 4] {polymer.stmt.name = "S13_affine_vector_load"} : memref<?xi8>, vector<4xi8>
            affine.vector_store %10, %alloca[%arg16 * 64 + %arg15 * 4] {polymer.stmt.name = "S14_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
            %11 = affine.vector_load %1[(%arg16 * symbol(%4)) * 4 + %arg15 * 4 + %arg12 * 64 + (%arg18 * (symbol(%4) * 16)) * 4] {polymer.stmt.name = "S15_affine_vector_load"} : memref<?xi8>, vector<4xi8>
            affine.vector_store %11, %alloca_0[%arg16 * 64 + %arg15 * 4] {polymer.stmt.name = "S16_affine_vector_store"} : memref<1024xi8, 3>, vector<4xi8>
            "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
            %12 = affine.load %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S18_affine_load"} : memref<16x16x1xf32, 16>
            %13 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %12) -> (f32) {
              %14 = affine.vector_load %alloca[%arg16 * 64 + %arg19 * 4] {polymer.stmt.name = "S20_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
              %15 = llvm.bitcast %14 {polymer.stmt.name = "S21_llvm_bitcast"} : vector<4xi8> to f32
              %16 = affine.vector_load %alloca_0[%arg19 * 64 + %arg15 * 4] {polymer.stmt.name = "S22_affine_vector_load"} : memref<1024xi8, 3>, vector<4xi8>
              %17 = llvm.bitcast %16 {polymer.stmt.name = "S23_llvm_bitcast"} : vector<4xi8> to f32
              %18 = llvm.fmul %15, %17  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
              %19 = llvm.fadd %arg20, %18  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
              affine.yield {polymer.stmt.name = "S26_affine_yield"} %19 : f32
            }
            affine.store %13, %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S27_affine_store"} : memref<16x16x1xf32, 16>
          }
          "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
          %8 = affine.load %alloca_1[%arg15, %arg16, %arg17] {polymer.stmt.name = "S30_affine_load"} : memref<16x16x1xf32, 16>
          %9 = llvm.bitcast %8 {polymer.stmt.name = "S31_llvm_bitcast"} : f32 to vector<4xi8>
          affine.vector_store %9, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%4)) * 4 + (%arg13 * (symbol(%4) * 16)) * 4] {polymer.stmt.name = "S32_affine_vector_store"} : memref<?xi8>, vector<4xi8>
        } {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"}
      } {gpu.par.grid}
      llvm.return {polymer.stmt.name = "S35_llvm_return"}
    }
  }
}

Eliminated dead instances: [P0, P1, P2, P3] -> { S4_arith_index_cast[]; S1_memref_ataddr[]; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S0_llvm_mlir_constant[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 }
Eliminated dead instances: [P0, P1, P2, P3] -> { S4_arith_index_cast[]; S1_memref_ataddr[]; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P1 and 0 <= i1 < P0 and i3 >= 0 and 16i3 < P2; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0; S0_llvm_mlir_constant[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P1 and 0 <= i1 < P0 }
