gpu-affine-opt: Before opt:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c4_i32 = arith.constant 4 : i32
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %c16_i32 = arith.constant 16 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %1 = arith.index_cast %arg1 : i64 to index
  %2 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%2), symbol(%1), 1) {
    %3 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    %4 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %5 = llvm.addrspacecast %3 : !llvm.ptr<3> to !llvm.ptr
      %6 = llvm.addrspacecast %4 : !llvm.ptr<3> to !llvm.ptr
      %7 = arith.index_cast %arg12 : index to i32
      %8 = arith.index_cast %arg13 : index to i32
      %9 = arith.index_cast %arg15 : index to i32
      %10 = arith.index_cast %arg16 : index to i32
      %11 = arith.shli %arg10, %c4_i32 : i32
      %12 = arith.muli %11, %8 : i32
      %13 = arith.addi %12, %arg10 : i32
      %14 = arith.shli %7, %c4_i32 : i32
      %15 = arith.shli %arg11, %c4_i32 : i32
      %16 = arith.muli %10, %arg10 : i32
      %17 = arith.addi %16, %9 : i32
      %18 = arith.extui %10 : i32 to i64
      %19 = arith.extui %9 : i32 to i64
      %20 = llvm.getelementptr inbounds %5[0, %18, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %21 = arith.muli %10, %arg11 : i32
      %22 = arith.addi %21, %9 : i32
      %23 = llvm.getelementptr inbounds %6[0, %18, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %24:2 = scf.for %arg18 = %12 to %13 step %c16_i32 iter_args(%arg19 = %14, %arg20 = %0) -> (i32, f32)  : i32 {
        %31 = arith.addi %17, %arg18 : i32
        %32 = arith.extsi %31 : i32 to i64
        %33 = llvm.getelementptr inbounds %arg8[%32] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %34 = llvm.load %33 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %34, %20 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        %35 = arith.addi %22, %arg19 : i32
        %36 = arith.extsi %35 : i32 to i64
        %37 = llvm.getelementptr inbounds %arg9[%36] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %38 = llvm.load %37 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %38, %23 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %39 = scf.for %arg21 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg22 = %arg20) -> (f32)  : i32 {
          %41 = arith.extui %arg21 : i32 to i64
          %42 = llvm.getelementptr inbounds %5[0, %18, %41] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %43 = llvm.load %42 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %44 = llvm.getelementptr inbounds %6[0, %41, %19] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %45 = llvm.load %44 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %46 = llvm.fmul %43, %45  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %47 = llvm.fadd %arg22, %46  {fastmathFlags = #llvm.fastmath<contract>} : f32
          scf.yield %47 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %40 = arith.addi %arg19, %15 : i32
        scf.yield %40, %39 : i32, f32
      }
      %25 = arith.muli %15, %8 : i32
      %26 = arith.addi %14, %9 : i32
      %27 = arith.addi %26, %21 : i32
      %28 = arith.addi %27, %25 : i32
      %29 = arith.extsi %28 : i32 to i64
      %30 = llvm.getelementptr inbounds %arg7[%29] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %24#1, %30 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Removed IVs:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c4_i32 = arith.constant 4 : i32
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %c16_i32 = arith.constant 16 : i32
  %c0_i32 = arith.constant 0 : i32
  %c1_i32 = arith.constant 1 : i32
  %1 = arith.index_cast %arg1 : i64 to index
  %2 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%2), symbol(%1), 1) {
    %3 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    %4 = llvm.alloca %c1_i32 x !llvm.array<16 x array<16 x f32>> : (i32) -> !llvm.ptr<3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %5 = llvm.addrspacecast %3 : !llvm.ptr<3> to !llvm.ptr
      %6 = llvm.addrspacecast %4 : !llvm.ptr<3> to !llvm.ptr
      %7 = arith.index_cast %arg12 : index to i32
      %8 = arith.index_cast %arg13 : index to i32
      %9 = arith.index_cast %arg15 : index to i32
      %10 = arith.index_cast %arg16 : index to i32
      %11 = arith.shli %arg10, %c4_i32 : i32
      %12 = arith.muli %11, %8 : i32
      %13 = arith.shli %7, %c4_i32 : i32
      %14 = arith.shli %arg11, %c4_i32 : i32
      %15 = arith.muli %10, %arg10 : i32
      %16 = arith.addi %15, %9 : i32
      %17 = arith.extui %10 : i32 to i64
      %18 = arith.extui %9 : i32 to i64
      %19 = llvm.getelementptr inbounds %5[0, %17, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %20 = arith.muli %10, %arg11 : i32
      %21 = arith.addi %20, %9 : i32
      %22 = llvm.getelementptr inbounds %6[0, %17, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
      %23 = arith.subi %arg10, %c1_i32 : i32
      %24 = arith.divui %23, %c16_i32 : i32
      %25 = arith.addi %24, %c1_i32 : i32
      %26 = scf.for %arg18 = %c0_i32 to %25 step %c1_i32 iter_args(%arg19 = %0) -> (f32)  : i32 {
        %33 = arith.muli %arg18, %14 : i32
        %34 = arith.addi %33, %13 : i32
        %35 = arith.muli %arg18, %c16_i32 : i32
        %36 = arith.addi %12, %35 : i32
        %37 = arith.addi %16, %36 : i32
        %38 = arith.extsi %37 : i32 to i64
        %39 = llvm.getelementptr inbounds %arg8[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %40 = llvm.load %39 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %40, %19 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        %41 = arith.addi %21, %34 : i32
        %42 = arith.extsi %41 : i32 to i64
        %43 = llvm.getelementptr inbounds %arg9[%42] : (!llvm.ptr, i64) -> !llvm.ptr, f32
        %44 = llvm.load %43 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
        llvm.store %44, %22 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %45 = scf.for %arg20 = %c0_i32 to %c16_i32 step %c1_i32 iter_args(%arg21 = %arg19) -> (f32)  : i32 {
          %46 = arith.extui %arg20 : i32 to i64
          %47 = llvm.getelementptr inbounds %5[0, %17, %46] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %48 = llvm.load %47 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %49 = llvm.getelementptr inbounds %6[0, %46, %18] : (!llvm.ptr, i64, i64) -> !llvm.ptr, !llvm.array<16 x array<16 x f32>>
          %50 = llvm.load %49 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : !llvm.ptr -> f32
          %51 = llvm.fmul %48, %50  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %52 = llvm.fadd %arg21, %51  {fastmathFlags = #llvm.fastmath<contract>} : f32
          scf.yield %52 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        scf.yield %45 : f32
      }
      %27 = arith.muli %14, %8 : i32
      %28 = arith.addi %13, %9 : i32
      %29 = arith.addi %28, %20 : i32
      %30 = arith.addi %29, %27 : i32
      %31 = arith.extsi %30 : i32 to i64
      %32 = llvm.getelementptr inbounds %arg7[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      llvm.store %26, %32 {alignment = 4 : i64, tbaa = [#llvm.tbaa_tag<base_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, access_type = <id = "float", members = {<#llvm.tbaa_type_desc<id = "omnipotent char", members = {<#llvm.tbaa_root<id = "Simple C++ TBAA">, 0>}>, 0>}>, offset = 0>]} : f32, !llvm.ptr
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: To Affine:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg11 : i32 to index
  %6 = arith.index_cast %arg10 : i32 to index
  %7 = arith.index_cast %arg10 : i32 to index
  %8 = arith.index_cast %arg11 : i32 to index
  %9 = arith.index_cast %arg11 : i32 to index
  %10 = arith.index_cast %arg10 : i32 to index
  %11 = arith.index_cast %arg1 : i64 to index
  %12 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%12), symbol(%11), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %13 = affine.for %arg18 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%10] iter_args(%arg19 = %0) -> (f32) {
        %15 = affine.vector_load %2[(%arg16 * symbol(%7)) * 4 + %arg15 * 4 + %arg18 * 64 + (%arg13 * (symbol(%6) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %15, %alloca[%arg16 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %16 = affine.vector_load %1[(%arg16 * symbol(%5)) * 4 + %arg15 * 4 + %arg12 * 64 + (%arg18 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %16, %alloca_0[%arg16 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        %17 = affine.for %arg20 = 0 to 16 iter_args(%arg21 = %arg19) -> (f32) {
          %18 = affine.vector_load %alloca[%arg16 * 64 + %arg20 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %19 = llvm.bitcast %18 : vector<4xi8> to f32
          %20 = affine.vector_load %alloca_0[%arg20 * 64 + %arg15 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %21 = llvm.bitcast %20 : vector<4xi8> to f32
          %22 = llvm.fmul %19, %21  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %23 = llvm.fadd %arg21, %22  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %23 : f32
        }
        "affine.barrier"(%arg15, %arg16, %arg17) : (index, index, index) -> ()
        affine.yield %17 : f32
      }
      %14 = llvm.bitcast %13 : f32 to vector<4xi8>
      affine.vector_store %14, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%9)) * 4 + (%arg13 * (symbol(%8) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Distributed:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c1 = arith.constant 1 : index
  %c16 = arith.constant 16 : index
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg11 : i32 to index
  %6 = arith.index_cast %arg10 : i32 to index
  %7 = arith.index_cast %arg10 : i32 to index
  %8 = arith.index_cast %arg11 : i32 to index
  %9 = arith.index_cast %arg11 : i32 to index
  %10 = arith.index_cast %arg10 : i32 to index
  %11 = arith.index_cast %arg1 : i64 to index
  %12 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%12), symbol(%11), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    %alloca_1 = memref.alloca(%c16, %c16, %c1) : memref<?x?x?xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] : memref<?x?x?xf32, 16>
    } {gpu.par.block}
    affine.for %arg15 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%10] {
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %13 = affine.vector_load %2[(%arg17 * symbol(%7)) * 4 + %arg16 * 4 + %arg15 * 64 + (%arg13 * (symbol(%6) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %13, %alloca[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %14 = affine.vector_load %1[(%arg17 * symbol(%5)) * 4 + %arg16 * 4 + %arg12 * 64 + (%arg15 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %14, %alloca_0[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
      } {gpu.par.block}
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %13 = affine.load %alloca_1[%arg16, %arg17, %arg18] : memref<?x?x?xf32, 16>
        %14 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %13) -> (f32) {
          %15 = affine.vector_load %alloca[%arg17 * 64 + %arg19 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %16 = llvm.bitcast %15 : vector<4xi8> to f32
          %17 = affine.vector_load %alloca_0[%arg19 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %18 = llvm.bitcast %17 : vector<4xi8> to f32
          %19 = llvm.fmul %16, %18  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %20 = llvm.fadd %arg20, %19  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %20 : f32
        }
        affine.store %14, %alloca_1[%arg16, %arg17, %arg18] : memref<?x?x?xf32, 16>
      } {gpu.par.block}
    }
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %13 = affine.load %alloca_1[%arg15, %arg16, %arg17] : memref<?x?x?xf32, 16>
      %14 = llvm.bitcast %13 : f32 to vector<4xi8>
      affine.vector_store %14, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%9)) * 4 + (%arg13 * (symbol(%8) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
gpu-affine-opt: Canonicalized:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %1 = "memref.ataddr"(%arg9) : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) : (!llvm.ptr) -> memref<?xi8>
  %4 = arith.index_cast %arg11 : i32 to index
  %5 = arith.index_cast %arg10 : i32 to index
  %6 = arith.index_cast %arg1 : i64 to index
  %7 = arith.index_cast %arg0 : i64 to index
  affine.parallel (%arg12, %arg13, %arg14) = (0, 0, 0) to (symbol(%7), symbol(%6), 1) {
    %alloca = memref.alloca() : memref<1024xi8, 3>
    %alloca_0 = memref.alloca() : memref<1024xi8, 3>
    %alloca_1 = memref.alloca() : memref<16x16x1xf32, 16>
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      affine.store %0, %alloca_1[%arg15, %arg16, %arg17] : memref<16x16x1xf32, 16>
    } {gpu.par.block}
    affine.for %arg15 = 0 to affine_map<()[s0] -> ((s0 - 1) floordiv 16 + 1)>()[%5] {
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %8 = affine.vector_load %2[(%arg17 * symbol(%5)) * 4 + %arg16 * 4 + %arg15 * 64 + (%arg13 * (symbol(%5) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %8, %alloca[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
        %9 = affine.vector_load %1[(%arg17 * symbol(%4)) * 4 + %arg16 * 4 + %arg12 * 64 + (%arg15 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
        affine.vector_store %9, %alloca_0[%arg17 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
      } {gpu.par.block}
      affine.parallel (%arg16, %arg17, %arg18) = (0, 0, 0) to (16, 16, 1) {
        %8 = affine.load %alloca_1[%arg16, %arg17, %arg18] : memref<16x16x1xf32, 16>
        %9 = affine.for %arg19 = 0 to 16 iter_args(%arg20 = %8) -> (f32) {
          %10 = affine.vector_load %alloca[%arg17 * 64 + %arg19 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %11 = llvm.bitcast %10 : vector<4xi8> to f32
          %12 = affine.vector_load %alloca_0[%arg19 * 64 + %arg16 * 4] {polymer.access.type = f32} : memref<1024xi8, 3>, vector<4xi8>
          %13 = llvm.bitcast %12 : vector<4xi8> to f32
          %14 = llvm.fmul %11, %13  {fastmathFlags = #llvm.fastmath<contract>} : f32
          %15 = llvm.fadd %arg20, %14  {fastmathFlags = #llvm.fastmath<contract>} : f32
          affine.yield %15 : f32
        }
        affine.store %9, %alloca_1[%arg16, %arg17, %arg18] : memref<16x16x1xf32, 16>
      } {gpu.par.block}
    }
    affine.parallel (%arg15, %arg16, %arg17) = (0, 0, 0) to (16, 16, 1) {
      %8 = affine.load %alloca_1[%arg15, %arg16, %arg17] : memref<16x16x1xf32, 16>
      %9 = llvm.bitcast %8 : f32 to vector<4xi8>
      affine.vector_store %9, %3[%arg12 * 64 + %arg15 * 4 + (%arg16 * symbol(%4)) * 4 + (%arg13 * (symbol(%4) * 16)) * 4] {polymer.access.type = f32} : memref<?xi8>, vector<4xi8>
    } {gpu.par.block}
  } {gpu.par.grid}
  llvm.return
}
Schedule:
domain: "[P0, P1, P2, P3] -> { S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S25_llvm_fadd[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S7_arith_index_cast[]; S32_affine_vector_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S18_affine_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S19_affine_store_var[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S31_llvm_bitcast[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S1_memref_ataddr[]; S21_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S23_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S24_llvm_fmul[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S5_arith_index_cast[]; S14_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S30_affine_load[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S22_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S16_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S11_affine_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S4_arith_index_cast[]; S27_affine_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S33_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S0_llvm_mlir_constant[]; S12_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S20_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S3_memref_ataddr[]; S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
child:
  sequence:
  - filter: "[P0, P1, P2, P3] -> { S0_llvm_mlir_constant[] }"
  - filter: "[P0, P1, P2, P3] -> { S1_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S2_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S3_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S4_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S5_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S6_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S7_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S10_memref_alloca[i0, i1, i2]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S30_affine_load[i0, i1, i2, i3, i4, i5]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S34_affine_yield[i0, i1, i2]; S8_memref_alloca[i0, i1, i2]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S11_affine_store[i0, i1, i2, i3, i4, i5]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S33_affine_yield[i0, i1, i2, i3, i4, i5]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S12_affine_yield[i0, i1, i2, i3, i4, i5]; S9_memref_alloca[i0, i1, i2]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
    child:
      schedule: "[P0, P1, P2, P3] -> L16.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i0)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i0)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i0)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S10_memref_alloca[i0, i1, i2] -> [(i0)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i0)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S34_affine_yield[i0, i1, i2] -> [(i0)]; S8_memref_alloca[i0, i1, i2] -> [(i0)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i0)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i0)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i0)]; S9_memref_alloca[i0, i1, i2] -> [(i0)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i0)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i0)] }]"
      permutable: 1
      child:
        schedule: "[P0, P1, P2, P3] -> L15.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i1)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i1)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i1)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S10_memref_alloca[i0, i1, i2] -> [(i1)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i1)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S34_affine_yield[i0, i1, i2] -> [(i1)]; S8_memref_alloca[i0, i1, i2] -> [(i1)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i1)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i1)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i1)]; S9_memref_alloca[i0, i1, i2] -> [(i1)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i1)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i1)] }]"
        permutable: 1
        child:
          schedule: "[P0, P1, P2, P3] -> L14.affine.parallel[{ S29_affine_yield[i0, i1, i2, i3] -> [(i2)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i2)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i2)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S10_memref_alloca[i0, i1, i2] -> [(i2)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i2)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S34_affine_yield[i0, i1, i2] -> [(i2)]; S8_memref_alloca[i0, i1, i2] -> [(i2)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i2)]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i2)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)]; S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i2)]; S9_memref_alloca[i0, i1, i2] -> [(i2)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i2)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i2)] }]"
          permutable: 1
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S9_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S10_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S12_affine_yield[i0, i1, i2, i3, i4, i5]; S11_affine_store[i0, i1, i2, i3, i4, i5] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i3)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i3)] }]"
                permutable: 1
                child:
                  schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i4)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i4)] }]"
                  permutable: 1
                  child:
                    schedule: "[P0, P1, P2, P3] -> L0.affine.parallel[{ S12_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i5)]; S11_affine_store[i0, i1, i2, i3, i4, i5] -> [(i5)] }]"
                    permutable: 1
                    child:
                      sequence:
                      - filter: "[P0, P1, P2, P3] -> { S11_affine_store[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S12_affine_yield[i0, i1, i2, i3, i4, i5] }"
            - filter: "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S29_affine_yield[i0, i1, i2, i3]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L10.affine.for[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S29_affine_yield[i0, i1, i2, i3] -> [(i3)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i3)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i3)] }]"
                child:
                  sequence:
                  - filter: "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6]; S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                    child:
                      schedule: "[P0, P1, P2, P3] -> L5.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)] }]"
                      permutable: 1
                      child:
                        schedule: "[P0, P1, P2, P3] -> L4.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)] }]"
                        permutable: 1
                        child:
                          schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)] }]"
                          permutable: 1
                          child:
                            sequence:
                            - filter: "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                  - filter: "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S27_affine_store[i0, i1, i2, i3, i4, i5, i6]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] }"
                    child:
                      schedule: "[P0, P1, P2, P3] -> L9.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i4)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i4)] }]"
                      permutable: 1
                      child:
                        schedule: "[P0, P1, P2, P3] -> L8.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i5)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i5)] }]"
                        permutable: 1
                        child:
                          schedule: "[P0, P1, P2, P3] -> L7.affine.parallel[{ S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)]; S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] -> [(i6)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i6)] }]"
                          permutable: 1
                          child:
                            sequence:
                            - filter: "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] }"
                              child:
                                schedule: "[P0, P1, P2, P3] -> L6.affine.for[{ S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)]; S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> [(i7)] }]"
                                child:
                                  sequence:
                                  - filter: "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] }"
                                  - filter: "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] }"
                            - filter: "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] }"
                            - filter: "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, i2, i3, i4, i5, i6] }"
                  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, i2, i3, i4, i5]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5]; S30_affine_load[i0, i1, i2, i3, i4, i5] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L13.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i3)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i3)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i3)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i3)] }]"
                permutable: 1
                child:
                  schedule: "[P0, P1, P2, P3] -> L12.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i4)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i4)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i4)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i4)] }]"
                  permutable: 1
                  child:
                    schedule: "[P0, P1, P2, P3] -> L11.affine.parallel[{ S30_affine_load[i0, i1, i2, i3, i4, i5] -> [(i5)]; S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> [(i5)]; S33_affine_yield[i0, i1, i2, i3, i4, i5] -> [(i5)]; S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> [(i5)] }]"
                    permutable: 1
                    child:
                      sequence:
                      - filter: "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, i2, i3, i4, i5] }"
                      - filter: "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, i2, i3, i4, i5] }"
            - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2] }"
Accesses:
domain: "[P0, P1, P2, P3] -> { S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S25_llvm_fadd[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S7_arith_index_cast[]; S32_affine_vector_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S18_affine_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S19_affine_store_var[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S31_llvm_bitcast[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S1_memref_ataddr[]; S21_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S23_llvm_bitcast[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S24_llvm_fmul[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S5_arith_index_cast[]; S14_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S30_affine_load[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S22_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S16_affine_vector_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S11_affine_store[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S4_arith_index_cast[]; S27_affine_store[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S33_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15; S0_llvm_mlir_constant[]; S12_affine_yield[i0, i1, 0, i3, i4, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S20_affine_vector_load[i0, i1, 0, i3, i4, i5, 0, i7] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15; S3_memref_ataddr[]; S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
accesses:
  - S0_llvm_mlir_constant:
  - S1_memref_ataddr:
  - S2_memref_ataddr:
  - S3_memref_ataddr:
  - S4_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[] }"
  - S5_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S5_arith_index_cast[] -> A_llvm_func_arg_10_1[] }"
  - S6_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }"
  - S7_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[] }"
  - S8_memref_alloca:
  - S9_memref_alloca:
  - S10_memref_alloca:
  - S11_affine_store:
        - must_write "[P0, P1, P2, P3] -> { S11_affine_store[i0, i1, i2, i3, i4, i5] -> A_memref_alloca_res_4[i3, i4, i5] }"
  - S12_affine_yield:
  - S13_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - must_write "[P0, P1, P2, P3] -> { S13_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_6[] }"
  - S14_affine_vector_store:
        - must_write "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_7[4i4 + 64i5] }"
        - read "[P0, P1, P2, P3] -> { S14_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_6[] }"
  - S15_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, 0, i3, i4, i5, 0] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - must_write "[P0, P1, P2, P3] -> { S15_affine_vector_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_9[] }"
  - S16_affine_vector_store:
        - must_write "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_10[4i4 + 64i5] }"
        - read "[P0, P1, P2, P3] -> { S16_affine_vector_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_vector_load_res_9[] }"
  - S17_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_vector_load_res_6[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S17_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_vector_load_res_9[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
  - S18_affine_load:
        - read "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_4[i4, i5, i6] }"
        - must_write "[P0, P1, P2, P3] -> { S18_affine_load[i0, i1, i2, i3, i4, i5, i6] -> A_affine_load_res_11[] }"
  - S19_affine_store_var:
        - read "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> A_affine_load_res_11[] }"
        - must_write "[P0, P1, P2, P3] -> { S19_affine_store_var[i0, i1, i2, i3, i4, i5, i6] -> A_affine_for_res_12[] }"
  - S20_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_memref_alloca_res_7[64i5 + 4i7] }"
        - must_write "[P0, P1, P2, P3] -> { S20_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_13[] }"
  - S21_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_14[] }"
        - read "[P0, P1, P2, P3] -> { S21_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_13[] }"
  - S22_affine_vector_load:
        - read "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_memref_alloca_res_10[4i4 + 64i7] }"
        - must_write "[P0, P1, P2, P3] -> { S22_affine_vector_load[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_15[] }"
  - S23_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_16[] }"
        - read "[P0, P1, P2, P3] -> { S23_llvm_bitcast[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_vector_load_res_15[] }"
  - S24_llvm_fmul:
        - must_write "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fmul_res_17[] }"
        - read "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_14[] }"
        - read "[P0, P1, P2, P3] -> { S24_llvm_fmul[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_bitcast_res_16[] }"
  - S25_llvm_fadd:
        - must_write "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fadd_res_18[] }"
        - read "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_for_res_12[] }"
        - read "[P0, P1, P2, P3] -> { S25_llvm_fadd[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fmul_res_17[] }"
  - S26_affine_yield:
        - must_write "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> A_affine_for_res_12[] }"
        - read "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, i2, i3, i4, i5, i6, i7] -> A_llvm_fadd_res_18[] }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_affine_vector_load_res_13[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_bitcast_res_14[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_affine_vector_load_res_15[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_bitcast_res_16[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_fmul_res_17[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S26_affine_yield[i0, i1, 0, i3, i4, i5, 0, i7] -> A_llvm_fadd_res_18[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 and 0 <= i7 <= 15 }"
  - S27_affine_store:
        - must_write "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> A_memref_alloca_res_4[i4, i5, i6] }"
        - read "[P0, P1, P2, P3] -> { S27_affine_store[i0, i1, i2, i3, i4, i5, i6] -> A_affine_for_res_12[] }"
  - S28_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_load_res_11[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S28_affine_yield[i0, i1, 0, i3, i4, i5, 0] -> A_affine_for_res_12[] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= i4 <= 15 and 0 <= i5 <= 15 }"
  - S29_affine_yield:
  - S30_affine_load:
        - read "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] -> A_memref_alloca_res_4[i3, i4, i5] }"
        - must_write "[P0, P1, P2, P3] -> { S30_affine_load[i0, i1, i2, i3, i4, i5] -> A_affine_load_res_19[] }"
  - S31_llvm_bitcast:
        - must_write "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> A_llvm_bitcast_res_20[] }"
        - read "[P0, P1, P2, P3] -> { S31_llvm_bitcast[i0, i1, i2, i3, i4, i5] -> A_affine_load_res_19[] }"
  - S32_affine_vector_store:
        - may_write "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, 0, i3, i4, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
        - read "[P0, P1, P2, P3] -> { S32_affine_vector_store[i0, i1, i2, i3, i4, i5] -> A_llvm_bitcast_res_20[] }"
  - S33_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, 0, i3, i4, 0] -> A_affine_load_res_19[] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
        - kill "[P0, P1, P2, P3] -> { S33_affine_yield[i0, i1, 0, i3, i4, 0] -> A_llvm_bitcast_res_20[] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= i3 <= 15 and 0 <= i4 <= 15 }"
  - S34_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
  - S35_llvm_return:
Schedule:
domain: "[P0, P1, P2, P3] -> { S4_arith_index_cast[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S1_memref_ataddr[]; RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S0_llvm_mlir_constant[]; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
child:
  sequence:
  - filter: "[P0, P1, P2, P3] -> { S0_llvm_mlir_constant[] }"
  - filter: "[P0, P1, P2, P3] -> { S1_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S2_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S3_memref_ataddr[] }"
  - filter: "[P0, P1, P2, P3] -> { S4_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S5_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S6_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S7_arith_index_cast[] }"
  - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3]; S8_memref_alloca[i0, i1, i2]; RS3_affine_parallel[i0, i1, i2]; S29_affine_yield[i0, i1, i2, i3]; S10_memref_alloca[i0, i1, i2]; S9_memref_alloca[i0, i1, i2]; RS0_affine_parallel[i0, i1, i2] }"
    child:
      schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; S9_memref_alloca[i0, i1, i2] -> [(i0)]; S8_memref_alloca[i0, i1, i2] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; S29_affine_yield[i0, i1, i2, i3] -> [(i0)]; S34_affine_yield[i0, i1, i2] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; S10_memref_alloca[i0, i1, i2] -> [(i0)] }]"
      permutable: 1
      child:
        schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; S9_memref_alloca[i0, i1, i2] -> [(i1)]; S8_memref_alloca[i0, i1, i2] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; S29_affine_yield[i0, i1, i2, i3] -> [(i1)]; S34_affine_yield[i0, i1, i2] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; S10_memref_alloca[i0, i1, i2] -> [(i1)] }]"
        permutable: 1
        child:
          schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ RS0_affine_parallel[i0, i1, i2] -> [(i2)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i2)]; S9_memref_alloca[i0, i1, i2] -> [(i2)]; S8_memref_alloca[i0, i1, i2] -> [(i2)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i2)]; S29_affine_yield[i0, i1, i2, i3] -> [(i2)]; S34_affine_yield[i0, i1, i2] -> [(i2)]; RS3_affine_parallel[i0, i1, i2] -> [(i2)]; S10_memref_alloca[i0, i1, i2] -> [(i2)] }]"
          permutable: 1
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { S8_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S9_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S10_memref_alloca[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3]; RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
              child:
                schedule: "[P0, P1, P2, P3] -> L0.affine.for[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)]; S29_affine_yield[i0, i1, i2, i3] -> [(i3)] }]"
                child:
                  sequence:
                  - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
                  - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
                  - filter: "[P0, P1, P2, P3] -> { S29_affine_yield[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
            - filter: "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, i2] }"
Accesses:
domain: "[P0, P1, P2, P3] -> { S4_arith_index_cast[]; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S1_memref_ataddr[]; RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S0_llvm_mlir_constant[]; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
accesses:
  - S0_llvm_mlir_constant:
  - S1_memref_ataddr:
  - S2_memref_ataddr:
  - S3_memref_ataddr:
  - S4_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[] }"
  - S5_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S5_arith_index_cast[] -> A_llvm_func_arg_10_1[] }"
  - S6_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S6_arith_index_cast[] -> A_llvm_func_arg_1_2[] }"
  - S7_arith_index_cast:
        - read "[P0, P1, P2, P3] -> { S7_arith_index_cast[] -> A_llvm_func_arg_0_3[] }"
  - S8_memref_alloca:
  - S9_memref_alloca:
  - S10_memref_alloca:
  - S29_affine_yield:
  - S34_affine_yield:
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
        - kill "[P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
  - S35_llvm_return:
  - RS0_affine_parallel:
        - must_write "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
  - RS1_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }"
        - must_write "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - read "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }"
        - must_write "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
  - RS2_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - read "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }"
        - must_write "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and P3 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
  - RS3_affine_parallel:
        - read "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }"
        - may_write "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
ReductionTagMap: [P0, P1, P2, P3] -> {  }
TaggedStmtDomain: [P1, P2, P0, P3] -> { [RS2_affine_parallel[i0, i1, i2, i3] -> S18_affine_load_Read0[]]; [RS0_affine_parallel[i0, i1, i2] -> S11_affine_store_Write0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S14_affine_vector_store_Write0[]]; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S27_affine_store_Write0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield2[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S20_affine_vector_load_Read0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield1[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S15_affine_vector_load_Read0[]]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield0[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> S22_affine_vector_load_Read0[]]; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]]; [RS3_affine_parallel[i0, i1, i2] -> S32_affine_vector_store_MayWrite0[]]; [RS3_affine_parallel[i0, i1, i2] -> S30_affine_load_Read0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S16_affine_vector_store_Write0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> S13_affine_vector_load_Read0[]]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] }
dep_order for A_llvm_func_arg_11_0 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_func_arg_10_1 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_func_arg_1_2 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_func_arg_0_3 [P1, P2, P3, P0] -> {  }
dep_order for A_memref_alloca_res_4 [P1, P2, P3, P0] -> { RS3_affine_parallel[i0, i1, i2] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and o1 > i1 and o1 < P1 and o3 >= 0 and 16o3 < P3); RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and 16i3 < P3 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 >= 0 and o3 < i3) or (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and i3 >= 0 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 > i3 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and 16i3 < P3 and o1 > i1 and o1 < P1 and o3 >= 0 and o3 < i3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i3 >= 0 and o1 > i1 and o1 < P1 and o3 > i3 and 16o3 < P3); RS2_affine_parallel[i0, i1, i2, i3] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and i3 >= 0 and 16i3 < P3 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and o1 > i1 and o1 < P1); RS3_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and o1 > i1 and o1 < P1) }
dep_order for A_memref_ataddr_res_5 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_vector_load_res_6 [P1, P2, P3, P0] -> {  }
dep_order for A_memref_alloca_res_7 [P1, P2, P3, P0] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and i3 >= 0 and 16i3 < P3 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and o1 > i1 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3) }
dep_order for A_memref_ataddr_res_8 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_vector_load_res_9 [P1, P2, P3, P0] -> {  }
dep_order for A_memref_alloca_res_10 [P1, P2, P3, P0] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and i3 >= 0 and 16i3 < P3 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and o1 > i1 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3) }
dep_order for A_affine_load_res_11 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_for_res_12 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_vector_load_res_13 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_bitcast_res_14 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_vector_load_res_15 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_bitcast_res_16 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_fmul_res_17 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_fadd_res_18 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_load_res_19 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_bitcast_res_20 [P1, P2, P3, P0] -> {  }
dep_order for A_memref_ataddr_res_21 [P1, P2, P3, P0] -> {  }
ReductionTagMap: [P0, P1, P2, P3] -> {  }
TaggedStmtDomain: [P1, P2, P0, P3] -> { [RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_8[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_10[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]]; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_5[]]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_7[]]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_ataddr_res_21[]]; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]]; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]]; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] }
dep_order for A_llvm_func_arg_11_0 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_func_arg_10_1 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_func_arg_1_2 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_func_arg_0_3 [P1, P2, P3, P0] -> {  }
dep_order for A_memref_alloca_res_4 [P1, P2, P3, P0] -> { RS3_affine_parallel[i0, i1, i2] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and o1 > i1 and o1 < P1 and o3 >= 0 and 16o3 < P3); RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and 16i3 < P3 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 >= 0 and o3 < i3) or (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and i3 >= 0 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 > i3 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and 16i3 < P3 and o1 > i1 and o1 < P1 and o3 >= 0 and o3 < i3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i3 >= 0 and o1 > i1 and o1 < P1 and o3 > i3 and 16o3 < P3); RS2_affine_parallel[i0, i1, i2, i3] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and i3 >= 0 and 16i3 < P3 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and o1 > i1 and o1 < P1); RS3_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and o1 > i1 and o1 < P1) }
dep_order for A_memref_ataddr_res_5 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_vector_load_res_6 [P1, P2, P3, P0] -> {  }
dep_order for A_memref_alloca_res_7 [P1, P2, P3, P0] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and i3 >= 0 and 16i3 < P3 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and o1 > i1 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3) }
dep_order for A_memref_ataddr_res_8 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_vector_load_res_9 [P1, P2, P3, P0] -> {  }
dep_order for A_memref_alloca_res_10 [P1, P2, P3, P0] -> { RS2_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, o3] : (i2 = 0 and o2 = 0 and i0 >= 0 and i1 >= 0 and i1 < P1 and i3 >= 0 and 16i3 < P3 and o0 > i0 and o0 < P2 and o1 >= 0 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and o1 > i1 and o1 < P1 and o3 >= 0 and 16o3 < P3) or (i2 = 0 and o0 = i0 and o1 = i1 and o2 = 0 and i0 >= 0 and i0 < P2 and i1 >= 0 and i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3) }
dep_order for A_affine_load_res_11 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_for_res_12 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_vector_load_res_13 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_bitcast_res_14 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_vector_load_res_15 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_bitcast_res_16 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_fmul_res_17 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_fadd_res_18 [P1, P2, P3, P0] -> {  }
dep_order for A_affine_load_res_19 [P1, P2, P3, P0] -> {  }
dep_order for A_llvm_bitcast_res_20 [P1, P2, P3, P0] -> {  }
dep_order for A_memref_ataddr_res_21 [P1, P2, P3, P0] -> {  }
tagged_reads [P1, P2, P0, P3] -> { [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]] -> A_llvm_func_arg_0_3[]; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS1_affine_parallel[i0, i1, 0, i3] -> S15_affine_vector_load_Read0[]] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [RS1_affine_parallel[i0, i1, 0, i3] -> S13_affine_vector_load_Read0[]] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]] -> A_llvm_func_arg_11_0[]; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]] -> A_llvm_func_arg_1_2[]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] -> A_llvm_func_arg_10_1[] }
atagged_reads [P1, P2, P0, P3] -> { [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]] -> A_llvm_func_arg_0_3[]; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]] -> A_llvm_func_arg_10_1[]; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[]] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]] -> A_llvm_func_arg_11_0[]; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]] -> A_llvm_func_arg_1_2[]; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[]] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
reads [P1, P2, P0, P3] -> { RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]; S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]; RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15; S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }
async_reads [P1, P2, P3, P0] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }
tagged_may_writes [P1, P2, P0, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }
atagged_may_writes [P1, P2, P0, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[]] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P2 and 0 <= i1 < P1; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
may_writes [P1, P2, P0, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : P1 > 0 and P2 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
tagged_must_writes [P1, P2, P3, P0] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
atagged_must_writes [P1, P2, P3, P0] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
must_writes [P1, P2, P3, P0] -> { RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and 0 <= o0 <= 15 and 0 <= o1 <= 15; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 and 0 <= o0 <= 15 and 0 <= o1 <= 15 }
async_must_writes [P1, P2, P3, P0] -> { RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[o0] : (o0) mod 4 = 0 and P1 > 0 and P2 > 0 and P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and -3 <= o0 <= 1020 and 64*floor((3 + o0)/64) <= o0 }
tagged_must_kills [P0, P1, P2, P3] -> { [S34_affine_yield[i0, i1, 0] -> S34_affine_yield1[]] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P2 and 0 <= i1 < P1; [S34_affine_yield[i0, i1, 0] -> S34_affine_yield0[]] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P2 and 0 <= i1 < P1; [S34_affine_yield[i0, i1, 0] -> S34_affine_yield2[]] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P2 and 0 <= i1 < P1 }
atagged_must_kills [P0, P1, P2, P3] -> { [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[]] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P2 and 0 <= i1 < P1; [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[]] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P2 and 0 <= i1 < P1; [S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[]] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }
must_kills [P0, P1, P2, P3] -> { S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_10[o0] : 0 <= i0 < P2 and 0 <= i1 < P1; S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_4[o0, o1, o2] : 0 <= i0 < P2 and 0 <= i1 < P1; S34_affine_yield[i0, i1, 0] -> A_memref_alloca_res_7[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }
live_in [P1, P2, P3, P0] -> { S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]; S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_8[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]; S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]; RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_ataddr_res_5[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }
live_out [P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, 0] -> A_memref_ataddr_res_21[o0] : 0 <= i0 < P2 and 0 <= i1 < P1 }
independence [P1, P2, P3, P0] -> { S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S8_memref_alloca[i0, i1, i2] -> S8_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, o2] : o2 < i2 or o2 > i2; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, i1, i2] : o0 < i0 or o0 > i0; RS0_affine_parallel[i0, i1, i2] -> RS0_affine_parallel[o0, o1, i2] : o1 < i1 or o1 > i1; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, o1, o2] : o2 > i2 or o2 < i2; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, i1, i2] : o0 > i0 or o0 < i0; RS3_affine_parallel[i0, i1, i2] -> RS3_affine_parallel[o0, o1, i2] : o1 > i1 or o1 < i1; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S10_memref_alloca[i0, i1, i2] -> S10_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, o1, o2] : o2 < i2 or o2 > i2; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, i1, i2] : o0 < i0 or o0 > i0; S9_memref_alloca[i0, i1, i2] -> S9_memref_alloca[o0, o1, i2] : o1 < i1 or o1 > i1; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, o2, i3] : o2 > i2 or o2 < i2; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[i0, i1, i2, o3] : o3 > i3 or o3 < i3; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, o1, i2, i3] : o1 > i1 or o1 < i1; RS1_affine_parallel[i0, i1, i2, i3] -> RS1_affine_parallel[o0, i1, i2, i3] : o0 > i0 or o0 < i0; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, o2, i3] : o2 > i2 or o2 < i2; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[i0, i1, i2, o3] : o3 > i3 or o3 < i3; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, o1, i2, i3] : o1 > i1 or o1 < i1; RS2_affine_parallel[i0, i1, i2, i3] -> RS2_affine_parallel[o0, i1, i2, i3] : o0 > i0 or o0 < i0; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, o1, o2] : o2 < i2 or o2 > i2; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, i1, i2] : o0 < i0 or o0 > i0; S34_affine_yield[i0, i1, i2] -> S34_affine_yield[o0, o1, i2] : o1 < i1 or o1 > i1; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, o1, o2, i3] : o2 > i2 or o2 < i2; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[i0, i1, i2, o3] : o3 > i3 or o3 < i3; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, o1, i2, i3] : o1 > i1 or o1 < i1; S29_affine_yield[i0, i1, i2, i3] -> S29_affine_yield[o0, i1, i2, i3] : o0 > i0 or o0 < i0 }
dep_flow [P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and -16 + P3 <= 16i3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P3 <= 0 and 0 <= i0 < P2 and 0 <= i1 < P1 }
tagged_dep_flow [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P3 <= 0 and 0 <= i0 < P2 and 0 <= i1 < P1; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and -16 + P3 <= 16i3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3 }
atagged_dep_flow [P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and -16 + P3 <= 16i3 < P3; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : P3 <= 0 and 0 <= i0 < P2 and 0 <= i1 < P1; [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> A_memref_alloca_res_4[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> A_memref_alloca_res_4[]] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1; [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }
dep_false [P1, P2, P0, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 <= -2 + P1 and -16 + P3 <= 16i3 < P3; RS2_affine_parallel[i0, -1 + P1, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P1 > 0 and P3 > 0 and 0 <= i0 <= -2 + P2 and -16 + P3 <= 16i3 < P3; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3; RS1_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, 1 + i1, 0, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 <= -2 + P1 and -16 + P3 <= 16i3 < P3; RS1_affine_parallel[i0, -1 + P1, 0, i3] -> RS1_affine_parallel[1 + i0, 0, 0, 0] : P1 > 0 and P3 > 0 and 0 <= i0 <= -2 + P2 and -16 + P3 <= 16i3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P2 and 0 <= i1 <= -2 + P1 and i3 >= 0 and -16 + P3 <= 16i3 < P3; RS2_affine_parallel[i0, -1 + P1, 0, i3] -> RS0_affine_parallel[1 + i0, 0, 0] : P1 > 0 and 0 <= i0 <= -2 + P2 and i3 >= 0 and -16 + P3 <= 16i3 < P3; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : 0 <= i0 < P2 and 0 <= i1 <= -2 + P1; RS3_affine_parallel[i0, -1 + P1, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P1 > 0 and 0 <= i0 <= -2 + P2; RS0_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, 1 + i1, 0] : P3 <= 0 and 0 <= i0 < P2 and 0 <= i1 <= -2 + P1; RS0_affine_parallel[i0, -1 + P1, 0] -> RS0_affine_parallel[1 + i0, 0, 0] : P1 > 0 and P3 <= 0 and 0 <= i0 <= -2 + P2 }
dep_forced [P1, P2, P0, P3] -> {  }
dep_order [P1, P2, P0, P3] -> { RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1; RS3_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, o1, 0] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 }
tagged_dep_order [P1, P2, P0, P3] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3 }
dep_async [P1, P2, P3, P0] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }
array_order [P1, P2, P3, P0] -> { RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; RS3_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1 and ((16i3 < P3 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P3)); RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1 and ((16i3 < P3 and 0 <= o3 < i3) or (i3 >= 0 and o3 > i3 and 16o3 < P3)); RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[o0, o1, 0, o3] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, o1, 0, o3] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS1_affine_parallel[i0, i1, 0, o3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[o0, o1, 0] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1; RS3_affine_parallel[i0, i1, 0] -> RS0_affine_parallel[i0, o1, 0] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1 }
tagger [P0, P1, P2, P3] -> { [RS2_affine_parallel[i0, i1, i2, i3] -> S18_affine_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS0_affine_parallel[i0, i1, i2] -> S11_affine_store_Write0[]] -> RS0_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S14_affine_vector_store_Write0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S6_arith_index_cast[] -> S6_arith_index_cast_Read0[]] -> S6_arith_index_cast[]; [S4_arith_index_cast[] -> S4_arith_index_cast_Read0[]] -> S4_arith_index_cast[]; [RS2_affine_parallel[i0, i1, i2, i3] -> S27_affine_store_Write0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS2_affine_parallel[i0, i1, i2, i3] -> S20_affine_vector_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield2[]] -> S34_affine_yield[(i0), (i1), (i2)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield1[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S15_affine_vector_load_Read0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> S34_affine_yield0[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> S22_affine_vector_load_Read0[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S7_arith_index_cast[] -> S7_arith_index_cast_Read0[]] -> S7_arith_index_cast[]; [RS3_affine_parallel[i0, i1, i2] -> S32_affine_vector_store_MayWrite0[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS3_affine_parallel[i0, i1, i2] -> S30_affine_load_Read0[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S16_affine_vector_store_Write0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS1_affine_parallel[i0, i1, i2, i3] -> S13_affine_vector_load_Read0[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S5_arith_index_cast[] -> S5_arith_index_cast_Read0[]] -> S5_arith_index_cast[] }
atagger [P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]] -> RS0_affine_parallel[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_8[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_4[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_alloca_res_4[]] -> RS3_affine_parallel[(i0), (i1), (i2)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_4[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_10[]] -> S34_affine_yield[(i0), (i1), (i2)]; [S4_arith_index_cast[] -> A_llvm_func_arg_11_0[]] -> S4_arith_index_cast[]; [S7_arith_index_cast[] -> A_llvm_func_arg_0_3[]] -> S7_arith_index_cast[]; [S6_arith_index_cast[] -> A_llvm_func_arg_1_2[]] -> S6_arith_index_cast[]; [S34_affine_yield[i0, i1, i2] -> A_memref_alloca_res_7[]] -> S34_affine_yield[(i0), (i1), (i2)]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_ataddr_res_5[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS2_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_7[]] -> RS2_affine_parallel[(i0), (i1), (i2), (i3)]; [S5_arith_index_cast[] -> A_llvm_func_arg_10_1[]] -> S5_arith_index_cast[]; [RS1_affine_parallel[i0, i1, i2, i3] -> A_memref_alloca_res_10[]] -> RS1_affine_parallel[(i0), (i1), (i2), (i3)]; [RS3_affine_parallel[i0, i1, i2] -> A_memref_ataddr_res_21[]] -> RS3_affine_parallel[(i0), (i1), (i2)] }
schedule
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
child:
  schedule: "[P0, P1, P2, P3] -> L3.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)]; RS0_affine_parallel[i0, i1, i2] -> [(i0)] }]"
  permutable: 1
  child:
    schedule: "[P0, P1, P2, P3] -> L2.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)]; RS0_affine_parallel[i0, i1, i2] -> [(i1)] }]"
    permutable: 1
    child:
      schedule: "[P0, P1, P2, P3] -> L1.affine.parallel[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(0)]; RS3_affine_parallel[i0, i1, i2] -> [(0)]; RS0_affine_parallel[i0, i1, i2] -> [(0)] }]"
      permutable: 1
      child:
        sequence:
        - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
        - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
          child:
            schedule: "[P0, P1, P2, P3] -> L0.affine.for[{ RS2_affine_parallel[i0, i1, i2, i3] -> [(i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
            child:
              sequence:
              - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
              - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
        - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
Schedule constraints:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
validity: "[P1, P2, P0, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and -16 + P3 <= 16i3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P3 <= 0 and 0 <= i0 < P2 and 0 <= i1 < P1 }"
coincidence: "[P1, P2, P3, P0] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and -16 + P3 <= 16i3 < P3; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P3 <= 0 and 0 <= i0 < P2 and 0 <= i1 < P1 }"
condition: "[P0, P1, P2, P3] -> { [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 0] -> S18_affine_load_Read0[]] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1; [RS0_affine_parallel[i0, i1, 0] -> S11_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P3 <= 0 and 0 <= i0 < P2 and 0 <= i1 < P1; [RS1_affine_parallel[i0, i1, 0, i3] -> S16_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [RS1_affine_parallel[i0, i1, 0, i3] -> S14_affine_vector_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and -16 + P3 <= 16i3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S27_affine_store_Write0[]] -> [RS2_affine_parallel[i0, i1, 0, 1 + i3] -> S18_affine_load_Read0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3 }"
conditional_validity: "[P1, P2, P0, P3] -> { [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[o0, o1, 0, o3] -> S27_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, o1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS2_affine_parallel[i0, i1, 0, o3] -> S27_affine_store_Write0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1; [RS3_affine_parallel[i0, i1, 0] -> S30_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S20_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S14_affine_vector_store_Write0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[o0, o1, 0] -> S11_affine_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1; [RS2_affine_parallel[i0, i1, 0, i3] -> S18_affine_load_Read0[]] -> [RS0_affine_parallel[i0, o1, 0] -> S11_affine_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[o0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : i0 >= 0 and 0 <= i1 < P1 and i0 < o0 < P2 and 0 <= o1 < P1; [RS3_affine_parallel[i0, i1, 0] -> S32_affine_vector_store_MayWrite0[]] -> [RS3_affine_parallel[i0, o1, 0] -> S32_affine_vector_store_MayWrite0[]] : 0 <= i0 < P2 and i1 >= 0 and i1 < o1 < P1; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[o0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : i0 >= 0 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 and i0 < o0 < P2 and 0 <= o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, o1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P2 and i1 >= 0 and i3 >= 0 and 16i3 < P3 and i1 < o1 < P1 and o3 >= 0 and 16o3 < P3; [RS2_affine_parallel[i0, i1, 0, i3] -> S22_affine_vector_load_Read0[]] -> [RS1_affine_parallel[i0, i1, 0, o3] -> S16_affine_vector_store_Write0[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and o3 > i3 and 16o3 < P3 }"
proximity: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] -> RS2_affine_parallel[i0, i1, 0, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] -> RS3_affine_parallel[i0, i1, 0] : P3 > 0 and 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and -16 + P3 <= 16i3 < P3; RS2_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, 1 + i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 <= -17 + P3; RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS0_affine_parallel[i0, i1, 0] -> RS3_affine_parallel[i0, i1, 0] : P3 <= 0 and 0 <= i0 < P2 and 0 <= i1 < P1 }"
anti_proximity: "[P1, P2, P3, P0] -> { RS1_affine_parallel[i0, i1, 0, i3] -> RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }"
live_range_span: "[P0, P1, P2, P3] -> { [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_7[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; [RS0_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] -> [RS3_affine_parallel[i0, i1, 0] -> A_memref_alloca_res_4[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and (P3 >= 17 or P3 <= 0 or (0 < P3 <= 16)); [RS1_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] -> [RS2_affine_parallel[i0, i1, 0, i3] -> A_memref_alloca_res_10[]] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3 }"
array_sizes: "[P0, P1, P2, P3] -> { A_memref_alloca_res_10[] -> [1024]; A_memref_alloca_res_4[] -> [1024]; A_memref_alloca_res_7[] -> [1024] }"
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i47 = i16 and i38 = i27 and i5 = i4 and i47 = i27 and i27 = i16 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i27 = i16 and i47 = i27 and i38 = i27 and i47 = i16 and i22 >= i21 and i30 >= i19 and i29 >= -i12 + i13 + i18 + i23 - i24 and i29 >= i18 and i28 >= -i14 + i15 + i17 + i25 - i26 and i28 >= i17 and i31 >= i17 + i18 + i19 + i20 - i28 - i29 - i30 and 16i50 >= -i21 + i22 + 16i30 and i49 >= i29 and i48 >= -i25 + i26 + i28 + i45 - i46 and i48 >= i28 and i49 >= -i23 + i24 + i29 + i43 - i44 and i51 >= i28 + i29 + i30 + i31 - i48 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i28 + 16i29 + 16i30 + 16i31 - 16i48 - 16i49 - 16i50 and i40 <= -i23 + i24 + i29 + i34 - i35 and i40 <= i29 and i39 <= -i25 + i26 + i28 + i36 - i37 and i39 <= i28 and 16i41 <= -i21 + i22 + 16i30 + i32 - i33 and i41 <= i30 and i42 <= i28 + i29 + i30 + i31 - i39 - i40 - i41 and i50 <= i19 and i49 >= -i12 + i13 + i18 + i43 - i44 and i49 >= i18 and i48 >= -i14 + i15 + i17 + i45 - i46 and i48 >= i17 and i51 >= i17 + i18 + i20 - i48 - i49 and i30 <= i19 and i29 <= -i12 + i13 + i18 + i23 - i24 and i29 <= i18 and i28 <= -i14 + i15 + i17 + i25 - i26 and i28 <= i17 and i31 <= i17 + i18 + i19 + i20 - i28 - i29 - i30 and 16i50 <= -i21 + i22 + 16i30 and i49 <= i29 and i48 <= -i25 + i26 + i28 + i45 - i46 and i48 <= i28 and i49 <= -i23 + i24 + i29 + i43 - i44 and i51 <= i28 + i29 + i30 + i31 - i48 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i28 + 16i29 + 16i30 + 16i31 - 16i48 - 16i49 - 16i50 and i7 >= i6 and i9 >= i8 and i11 >= i10 and i22 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i21 and i40 >= -i23 + i24 + i29 + i34 - i35 and i40 >= i29 and i39 >= -i25 + i26 + i28 + i36 - i37 and i39 >= i28 and 16i41 >= -i21 + i22 + 16i30 + i32 - i33 and i41 >= i30 and i42 >= i28 + i29 + i30 + i31 - i39 - i40 - i41 and i50 >= i19 and i49 <= -i12 + i13 + i18 + i43 - i44 and i49 <= i18 and i48 <= -i14 + i15 + i17 + i45 - i46 and i48 <= i17 and i51 <= i17 + i18 + i20 - i48 - i49 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[1,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i47 = i16 and i38 = i27 and i47 = i27 and i27 = i16 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i27 = i16 and i47 = i27 and i38 = i27 and i47 = i16 and i22 >= i21 and i30 >= i19 and i29 >= -i12 + i13 + i18 + i23 - i24 and i29 >= i18 and i28 >= -i14 + i15 + i17 + i25 - i26 and i28 >= i17 and i31 >= i17 + i18 + i19 + i20 - i28 - i29 - i30 and 16i50 >= -i21 + i22 + 16i30 and i49 >= i29 and i48 >= -i25 + i26 + i28 + i45 - i46 and i48 >= i28 and i49 >= -i23 + i24 + i29 + i43 - i44 and i51 >= i28 + i29 + i30 + i31 - i48 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i28 + 16i29 + 16i30 + 16i31 - 16i48 - 16i49 - 16i50 and i40 <= -i23 + i24 + i29 + i34 - i35 and i40 <= i29 and i39 <= -i25 + i26 + i28 + i36 - i37 and i39 <= i28 and 16i41 <= -i21 + i22 + 16i30 + i32 - i33 and i41 <= i30 and i42 <= i28 + i29 + i30 + i31 - i39 - i40 - i41 and i50 <= i19 and i49 >= -i12 + i13 + i18 + i43 - i44 and i49 >= i18 and i48 >= -i14 + i15 + i17 + i45 - i46 and i48 >= i17 and i51 >= i17 + i18 + i20 - i48 - i49 and i30 <= i19 and i29 <= -i12 + i13 + i18 + i23 - i24 and i29 <= i18 and i28 <= -i14 + i15 + i17 + i25 - i26 and i28 <= i17 and i31 <= i17 + i18 + i19 + i20 - i28 - i29 - i30 and 16i50 <= -i21 + i22 + 16i30 and i49 <= i29 and i48 <= -i25 + i26 + i28 + i45 - i46 and i48 <= i28 and i49 <= -i23 + i24 + i29 + i43 - i44 and i51 <= i28 + i29 + i30 + i31 - i48 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i28 + 16i29 + 16i30 + 16i31 - 16i48 - 16i49 - 16i50 and i22 <= i21 and i40 >= -i23 + i24 + i29 + i34 - i35 and i40 >= i29 and i39 >= -i25 + i26 + i28 + i36 - i37 and i39 >= i28 and 16i41 >= -i21 + i22 + 16i30 + i32 - i33 and i41 >= i30 and i42 >= i28 + i29 + i30 + i31 - i39 - i40 - i41 and i50 >= i19 and i49 <= -i12 + i13 + i18 + i43 - i44 and i49 <= i18 and i48 <= -i14 + i15 + i17 + i45 - i46 and i48 <= i17 and i51 <= i17 + i18 + i20 - i48 - i49 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[1,0,0,0,4,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i47 = i16 and i38 = i27 and i47 = i27 and i27 = i16 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i27 = i16 and i47 = i27 and i38 = i27 and i47 = i16 and i22 >= i21 and i30 >= i19 and i29 >= -i12 + i13 + i18 + i23 - i24 and i29 >= i18 and i28 >= -i14 + i15 + i17 + i25 - i26 and i28 >= i17 and i31 >= i17 + i18 + i19 + i20 - i28 - i29 - i30 and 16i50 >= -i21 + i22 + 16i30 and i49 >= i29 and i48 >= -i25 + i26 + i28 + i45 - i46 and i48 >= i28 and i49 >= -i23 + i24 + i29 + i43 - i44 and i51 >= i28 + i29 + i30 + i31 - i48 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i28 + 16i29 + 16i30 + 16i31 - 16i48 - 16i49 - 16i50 and i40 <= -i23 + i24 + i29 + i34 - i35 and i40 <= i29 and i39 <= -i25 + i26 + i28 + i36 - i37 and i39 <= i28 and 16i41 <= -i21 + i22 + 16i30 + i32 - i33 and i41 <= i30 and i42 <= i28 + i29 + i30 + i31 - i39 - i40 - i41 and i50 <= i19 and i49 >= -i12 + i13 + i18 + i43 - i44 and i49 >= i18 and i48 >= -i14 + i15 + i17 + i45 - i46 and i48 >= i17 and i51 >= i17 + i18 + i20 - i48 - i49 and i30 <= i19 and i29 <= -i12 + i13 + i18 + i23 - i24 and i29 <= i18 and i28 <= -i14 + i15 + i17 + i25 - i26 and i28 <= i17 and i31 <= i17 + i18 + i19 + i20 - i28 - i29 - i30 and 16i50 <= -i21 + i22 + 16i30 and i49 <= i29 and i48 <= -i25 + i26 + i28 + i45 - i46 and i48 <= i28 and i49 <= -i23 + i24 + i29 + i43 - i44 and i51 <= i28 + i29 + i30 + i31 - i48 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i28 + 16i29 + 16i30 + 16i31 - 16i48 - 16i49 - 16i50 and i22 <= i21 and i40 >= -i23 + i24 + i29 + i34 - i35 and i40 >= i29 and i39 >= -i25 + i26 + i28 + i36 - i37 and i39 >= i28 and 16i41 >= -i21 + i22 + 16i30 + i32 - i33 and i41 >= i30 and i42 >= i28 + i29 + i30 + i31 - i39 - i40 - i41 and i50 >= i19 and i49 <= -i12 + i13 + i18 + i43 - i44 and i49 <= i18 and i48 <= -i14 + i15 + i17 + i45 - i46 and i48 <= i17 and i51 <= i17 + i18 + i20 - i48 - i49 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i47 = i16 and i38 = i27 and i47 = i27 and i27 = i16 and i46 = i3 - i12 - i13 - i14 - i15 - i21 - i22 - i23 - i24 - i25 - i26 - i32 - i33 - i34 - i35 - i36 - i37 - i43 - i44 - i45 and i50 = i2 - i16 - i17 - i18 - i19 - i27 - i28 - i29 - i30 - i38 - i39 - i40 - i41 - i47 - i48 - i49 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i27 = i16 and i47 = i27 and i38 = i27 and i47 = i16 and i22 >= i21 and i30 >= i19 and i29 >= -i12 + i13 + i18 + i23 - i24 and i29 >= i18 and i28 >= -i14 + i15 + i17 + i25 - i26 and i28 >= i17 and i31 >= i17 + i18 + i19 + i20 - i28 - i29 - i30 and 16i50 >= -i21 + i22 + 16i30 and i49 >= i29 and i48 >= -i25 + i26 + i28 + i45 - i46 and i48 >= i28 and i49 >= -i23 + i24 + i29 + i43 - i44 and i51 >= i28 + i29 + i30 + i31 - i48 - i49 - i50 and 16i51 >= 15i21 - 15i22 + 16i28 + 16i29 + 16i30 + 16i31 - 16i48 - 16i49 - 16i50 and i40 <= -i23 + i24 + i29 + i34 - i35 and i40 <= i29 and i39 <= -i25 + i26 + i28 + i36 - i37 and i39 <= i28 and 16i41 <= -i21 + i22 + 16i30 + i32 - i33 and i41 <= i30 and i42 <= i28 + i29 + i30 + i31 - i39 - i40 - i41 and i50 <= i19 and i49 >= -i12 + i13 + i18 + i43 - i44 and i49 >= i18 and i48 >= -i14 + i15 + i17 + i45 - i46 and i48 >= i17 and i51 >= i17 + i18 + i20 - i48 - i49 and i30 <= i19 and i29 <= -i12 + i13 + i18 + i23 - i24 and i29 <= i18 and i28 <= -i14 + i15 + i17 + i25 - i26 and i28 <= i17 and i31 <= i17 + i18 + i19 + i20 - i28 - i29 - i30 and 16i50 <= -i21 + i22 + 16i30 and i49 <= i29 and i48 <= -i25 + i26 + i28 + i45 - i46 and i48 <= i28 and i49 <= -i23 + i24 + i29 + i43 - i44 and i51 <= i28 + i29 + i30 + i31 - i48 - i49 - i50 and 16i51 <= 15i21 - 15i22 + 16i28 + 16i29 + 16i30 + 16i31 - 16i48 - 16i49 - 16i50 and i22 <= i21 and i40 >= -i23 + i24 + i29 + i34 - i35 and i40 >= i29 and i39 >= -i25 + i26 + i28 + i36 - i37 and i39 >= i28 and 16i41 >= -i21 + i22 + 16i30 + i32 - i33 and i41 >= i30 and i42 >= i28 + i29 + i30 + i31 - i39 - i40 - i41 and i50 >= i19 and i49 <= -i12 + i13 + i18 + i43 - i44 and i49 <= i18 and i48 <= -i14 + i15 + i17 + i45 - i46 and i48 <= i17 and i51 <= i17 + i18 + i20 - i48 - i49 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39, i40, i41, i42, i43, i44, i45, i46, i47, i48, i49, i50, i51] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 0 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 and i40 = 0 and i41 = 0 and i42 = 0 and i43 = 0 and i44 = 0 and i45 = 0 and i46 = 0 and i47 = 0 and i48 = 0 and i49 = 0 and i50 = 0 and i51 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39] : i35 = i5 - i6 + i24 and i6 = i5 and i35 = i24 and i34 = i4 - i18 - i19 - i20 - i21 - i22 - i23 - i29 - i30 - i31 - i32 - i33 and i38 = i3 - i24 - i25 - i26 - i27 - i35 - i36 - i37 and i13 = 100000 - i0 and i12 = i1 - i5 - i6 - i7 - i8 - i9 - i10 - i11 and i17 = 1 + i15 and i16 = 1 + i14 and i35 = i24 and i35 = i24 and i35 = i24 and i37 <= -i20 + i21 + i26 + i31 - i32 and i37 <= i26 and i36 <= -i22 + i23 + i25 + i33 - i34 and i36 <= i25 and 16i38 <= -i18 + i19 + 16i27 + i29 - i30 and i38 <= i27 and i39 <= -i13 + i25 + i26 + i27 + i28 - i36 - i37 - i38 and i37 >= -i20 + i21 + i26 + i31 - i32 and i37 >= i26 and i36 >= -i22 + i23 + i25 + i33 - i34 and i36 >= i25 and 16i38 >= -i18 + i19 + 16i27 + i29 - i30 and i38 >= i27 and i39 >= -i14 + i25 + i26 + i27 + i28 - i36 - i37 - i38 and i37 >= -i20 + i21 + i26 + i31 - i32 and i37 >= i26 and i36 >= -i22 + i23 + i25 + i33 - i34 and i36 >= i25 and 16i38 >= -i18 + i19 + 16i27 + i29 - i30 and i38 >= i27 and i39 >= -i15 + i25 + i26 + i27 + i28 - i36 - i37 - i38 and 1024i17 <= 48000 - 1024i16 and i16 > 0 and i17 > 0 and i19 >= i18 and i37 <= -i20 + i21 + i26 + i31 - i32 and i37 <= i26 and i36 <= -i22 + i23 + i25 + i33 - i34 and i36 <= i25 and 16i38 <= -i18 + i19 + 16i27 + i29 - i30 and i38 <= i27 and i39 <= i25 + i26 + i27 + i28 - i36 - i37 - i38 and i8 >= i7 and i10 >= i9 and i12 >= i11 and i19 <= i2 - i7 + i8 - i9 + i10 - 17i11 + 17i12 + i18 and i37 >= i9 - i10 - i20 + i21 + i26 + i31 - i32 and i37 >= i9 - i10 + i26 and i36 >= i7 - i8 - i22 + i23 + i25 + i33 - i34 and i36 >= i7 - i8 + i25 and 16i38 >= 16i11 - 16i12 - i18 + i19 + 16i27 + i29 - i30 and i38 >= i11 - i12 + i27 and i39 >= -i2 + i7 - i8 + i9 - i10 + i11 - i12 + i25 + i26 + i27 + i28 - i36 - i37 - i38 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23, i24, i25, i26, i27, i28, i29, i30, i31, i32, i33, i34, i35, i36, i37, i38, i39] : i0 = 99978 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 11 and i6 = 11 and i7 = -22 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 22 and i14 = 22 and i15 = 22 and i16 = 23 and i17 = 23 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 and i24 = 0 and i25 = 0 and i26 = 0 and i27 = 0 and i28 = 22 and i29 = 0 and i30 = 0 and i31 = 0 and i32 = 0 and i33 = 0 and i34 = 0 and i35 = 0 and i36 = 0 and i37 = 0 and i38 = 0 and i39 = 0 }
sol:
[1,99978,0,22,0,2,0,0,0,0,0,0,0,0,22,22,22,23,23,0,1,0,0,0,0,0,0,0,0,22,0,1,0,0,0,0,0,0,0,0,0]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i19 = i14 and i5 = i4 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i19 = i14 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i20 <= i15 and i21 <= i16 and i22 <= i17 and i23 <= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and i7 >= i6 and i9 >= i8 and i11 >= i10 and 22i13 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i12 and i20 >= i15 and i21 >= i16 and i22 >= i17 and i23 >= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i19 = i4 - i5 + i14 and i5 = i4 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i19 = i14 and 22i13 >= 22i12 and i13 >= i12 and i20 <= i15 and i21 <= i16 and i22 <= i17 and i23 <= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and i7 >= i6 and i9 >= i8 and i11 >= i10 and 22i13 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i12 and i20 >= i6 - i7 + i15 and i21 >= i8 - i9 + i16 and i22 >= i10 - i11 + i17 and i23 >= -i1 + i6 - i7 + i8 - i9 + i10 - i11 - 22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[1,0,22,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i19 = i14 and i5 = i4 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i19 = i14 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i20 <= i15 and i21 <= i16 and i22 <= i17 and i23 <= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and i7 >= i6 and i9 >= i8 and i11 >= i10 and 22i13 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i12 and i20 >= i15 and i21 >= i16 and i22 >= i17 and i23 >= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i19 = i4 - i5 + i14 and i5 = i4 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i19 = i14 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i20 <= i15 and i21 <= i16 and i22 <= i17 and i23 <= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and i7 >= i6 and i9 >= i8 and i11 >= i10 and 22i13 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i12 and i20 >= i6 - i7 + i15 and i21 >= i8 - i9 + i16 and i22 >= i10 - i11 + i17 and i23 >= -i1 + i6 - i7 + i8 - i9 + i10 - i11 - 22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i19 = i14 and i5 = i4 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i19 = i14 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i20 >= i15 and i21 >= i16 and 16i22 >= -i12 + i13 + 16i17 and i23 >= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 16i23 >= -337i12 + 337i13 + 16i15 + 16i16 + 16i17 + 16i18 - 16i20 - 16i21 - 16i22 and i7 >= i6 and i9 >= i8 and i11 >= i10 and 22i13 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i12 and i20 <= i15 and i21 <= i16 and 16i22 <= -i12 + i13 + 16i17 and i23 <= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 16i23 <= -337i12 + 337i13 + 16i15 + 16i16 + 16i17 + 16i18 - 16i20 - 16i21 - 16i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i19 = -i4 + i5 + i14 and i5 = i4 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i19 = i14 and 22i13 >= 22i12 and i13 >= i12 and i20 >= i15 and i21 >= i16 and 16i22 >= -i12 + i13 + 16i17 and i23 >= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 16i23 >= -337i12 + 337i13 + 16i15 + 16i16 + 16i17 + 16i18 - 16i20 - 16i21 - 16i22 and i7 >= i6 and i9 >= i8 and i11 >= i10 and 22i13 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i12 and i20 <= -i6 + i7 + i15 and i21 <= -i8 + i9 + i16 and 16i22 <= -16i10 + 16i11 - i12 + i13 + 16i17 and i23 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 - 22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 16i23 <= 16i1 - 16i6 + 16i7 - 16i8 + 16i9 - 16i10 + 16i11 - 337i12 + 337i13 + 16i15 + 16i16 + 16i17 + 16i18 - 16i20 - 16i21 - 16i22 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[1,0,352,1,16,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,1,351]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i19 = i14 and i5 = i4 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i19 = i14 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i20 >= i15 and i21 >= i16 and 16i22 >= -i12 + i13 + 16i17 and i23 >= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 16i23 >= -337i12 + 337i13 + 16i15 + 16i16 + 16i17 + 16i18 - 16i20 - 16i21 - 16i22 and i7 >= i6 and i9 >= i8 and i11 >= i10 and 22i13 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i12 and i20 <= i15 and i21 <= i16 and 16i22 <= -i12 + i13 + 16i17 and i23 <= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 16i23 <= -337i12 + 337i13 + 16i15 + 16i16 + 16i17 + 16i18 - 16i20 - 16i21 - 16i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
setup lp:
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i19 = -i4 + i5 + i14 and i5 = i4 and i13 = i3 - i12 and i22 = i2 - i14 - i15 - i16 - i17 - i19 - i20 - i21 and i11 = i0 - i4 - i5 - i6 - i7 - i8 - i9 - i10 and i19 = i14 and 22i13 >= 22i12 and i13 >= i12 and 22i13 >= 22i12 and i20 >= i15 and i21 >= i16 and 16i22 >= -i12 + i13 + 16i17 and i23 >= -22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 16i23 >= -337i12 + 337i13 + 16i15 + 16i16 + 16i17 + 16i18 - 16i20 - 16i21 - 16i22 and i7 >= i6 and i9 >= i8 and i11 >= i10 and 22i13 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 + 22i12 and i13 <= i1 - i6 + i7 - i8 + i9 - 17i10 + 17i11 + i12 and i20 <= -i6 + i7 + i15 and i21 <= -i8 + i9 + i16 and 16i22 <= -16i10 + 16i11 - i12 + i13 + 16i17 and i23 <= i1 - i6 + i7 - i8 + i9 - i10 + i11 - 22i12 + 22i13 + i15 + i16 + i17 + i18 - i20 - i21 - i22 and 16i23 <= 16i1 - 16i6 + 16i7 - 16i8 + 16i9 - 16i10 + 16i11 - 337i12 + 337i13 + 16i15 + 16i16 + 16i17 + 16i18 - 16i20 - 16i21 - 16i22 and 22i13 <= 22i12 }
is_empty: 0
{ [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13, i14, i15, i16, i17, i18, i19, i20, i21, i22, i23] : i0 = 0 and i1 = 0 and i2 = 0 and i3 = 0 and i4 = 0 and i5 = 0 and i6 = 0 and i7 = 0 and i8 = 0 and i9 = 0 and i10 = 0 and i11 = 0 and i12 = 0 and i13 = 0 and i14 = 0 and i15 = 0 and i16 = 0 and i17 = 0 and i18 = 0 and i19 = 0 and i20 = 0 and i21 = 0 and i22 = 0 and i23 = 0 }
sol:
[]
New Schedule:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
child:
  schedule: "[P0, P1, P2, P3] -> [{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)] }, { RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)] }]"
  permutable: 1
  coincident: [ 1, 1 ]
  child:
    sequence:
    - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
    - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
      child:
        schedule: "[P0, P1, P2, P3] -> [{ RS2_affine_parallel[i0, i1, i2, i3] -> [(22 + i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
        permutable: 1
        coincident: [ 1 ]
        child:
          sequence:
          - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
          - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
    - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
New Schedule Prepared for GPU:
domain: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; RS2_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS1_affine_parallel[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; RS3_affine_parallel[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1 }"
child:
  mark: "grid_parallel"
  child:
    schedule: "[P0, P1, P2, P3] -> [{ RS0_affine_parallel[i0, i1, i2] -> [(i1)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i1)]; RS3_affine_parallel[i0, i1, i2] -> [(i1)] }, { RS0_affine_parallel[i0, i1, i2] -> [(i0)]; RS2_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i0)]; RS3_affine_parallel[i0, i1, i2] -> [(i0)] }]"
    permutable: 1
    coincident: [ 1, 1 ]
    child:
      sequence:
      - filter: "[P0, P1, P2, P3] -> { RS0_affine_parallel[i0, i1, i2] }"
      - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3]; RS1_affine_parallel[i0, i1, i2, i3] }"
        child:
          schedule: "[P0, P1, P2, P3] -> [{ RS2_affine_parallel[i0, i1, i2, i3] -> [(22 + i3)]; RS1_affine_parallel[i0, i1, i2, i3] -> [(i3)] }]"
          permutable: 1
          coincident: [ 1 ]
          child:
            sequence:
            - filter: "[P0, P1, P2, P3] -> { RS2_affine_parallel[i0, i1, i2, i3] }"
            - filter: "[P0, P1, P2, P3] -> { RS1_affine_parallel[i0, i1, i2, i3] }"
      - filter: "[P0, P1, P2, P3] -> { RS3_affine_parallel[i0, i1, i2] }"
New AST:
mark: grid_parallel@0x2
node:
  iterator:
    id: c0
  init:
    val: 0
  cond:
    op: lt
    args:
    - id: c0
    - id: P1@0x3b7115d0
  inc:
    val: 1
  body:
    iterator:
      id: c1
    init:
      val: 0
    cond:
      op: lt
      args:
      - id: c1
      - id: P2@0x3b7116c0
    inc:
      val: 1
    body:
    - user:
        op: call
        args:
        - id: RS0_affine_parallel@0x3b75ac60
        - id: c1
        - id: c0
        - val: 0
    - iterator:
        id: c2
      init:
        val: 0
      cond:
        op: le
        args:
        - id: c2
        - op: min
          args:
          - val: 21
          - op: fdiv_q
            args:
            - op: sub
              args:
              - id: P3@0x3b74f660
              - val: 1
            - val: 16
      inc:
        val: 1
      body:
        user:
          op: call
          args:
          - id: RS1_affine_parallel@0x3b70d870
          - id: c1
          - id: c0
          - val: 0
          - id: c2
    - iterator:
        id: c2
      init:
        val: 22
      cond:
        op: le
        args:
        - id: c2
        - op: add
          args:
          - op: fdiv_q
            args:
            - op: sub
              args:
              - id: P3@0x3b74f660
              - val: 1
            - val: 16
          - val: 22
      inc:
        val: 1
      body:
      - user:
          op: call
          args:
          - id: RS2_affine_parallel@0x3b724700
          - id: c1
          - id: c0
          - val: 0
          - op: sub
            args:
            - id: c2
            - val: 22
      - guard:
          op: ge
          args:
          - id: P3@0x3b74f660
          - op: add
            args:
            - op: mul
              args:
              - val: 16
              - id: c2
            - val: 1
        then:
          user:
            op: call
            args:
            - id: RS1_affine_parallel@0x3b70d870
            - id: c1
            - id: c0
            - val: 0
            - id: c2
    - user:
        op: call
        args:
        - id: RS3_affine_parallel@0x3b724460
        - id: c1
        - id: c0
        - val: 0
New func:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %5 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %6 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %7 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
  %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
  %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S10_memref_alloca"} : () -> memref<16x16x1xf32, 16>
  %11 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %12 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %13 = "arith.index_cast"(%6) : (index) -> i64
  %14 = "arith.index_cast"(%11) : (i64) -> index
  %15 = "arith.index_cast"(%13) : (i64) -> index
  %16 = "arith.index_cast"(%12) : (i64) -> index
  %17 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %18 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %19 = "arith.index_cast"(%7) : (index) -> i64
  %20 = "arith.index_cast"(%17) : (i64) -> index
  %21 = "arith.index_cast"(%19) : (i64) -> index
  %22 = "arith.index_cast"(%18) : (i64) -> index
  "scf.parallel"(%14, %20, %15, %21, %16, %22) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %23 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg30: index, %arg31: index, %arg32: index):
      "affine.store"(%0, %10, %arg30, %arg31, %arg32) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S11_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    %24 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %25 = "arith.constant"() <{value = 21 : i64}> : () -> i64
    %26 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %27 = "arith.index_cast"(%5) : (index) -> i64
    %28 = "arith.subi"(%27, %26) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %29 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %30 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %31 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %32 = "arith.subi"(%28, %29) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %33 = "arith.addi"(%32, %30) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %34 = "arith.cmpi"(%28, %31) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %35 = "arith.select"(%34, %33, %28) : (i1, i64, i64) -> i64
    %36 = "arith.divsi"(%35, %29) : (i64, i64) -> i64
    %37 = "arith.minsi"(%36, %25) : (i64, i64) -> i64
    %38 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %39 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %40 = "arith.addi"(%37, %39) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%24, %40, %38) ({
    ^bb0(%arg26: i64):
      %81 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg27: index, %arg28: index, %arg29: index):
        %82 = "affine.vector_load"(%2, %arg28, %arg27, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%82, %8, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %83 = "affine.vector_load"(%1, %arg28, %arg27, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%83, %9, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %41 = "arith.constant"() <{value = 22 : i64}> : () -> i64
    %42 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %43 = "arith.index_cast"(%5) : (index) -> i64
    %44 = "arith.subi"(%43, %42) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %45 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %46 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %47 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %48 = "arith.subi"(%44, %45) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %49 = "arith.addi"(%48, %46) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %50 = "arith.cmpi"(%44, %47) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %51 = "arith.select"(%50, %49, %44) : (i1, i64, i64) -> i64
    %52 = "arith.divsi"(%51, %45) : (i64, i64) -> i64
    %53 = "arith.constant"() <{value = 22 : i64}> : () -> i64
    %54 = "arith.addi"(%52, %53) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %55 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %56 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %57 = "arith.addi"(%54, %56) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%41, %57, %55) ({
    ^bb0(%arg17: i64):
      %61 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %62 = "arith.constant"() <{value = 22 : i64}> : () -> i64
      %63 = "arith.subi"(%arg17, %62) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg21: index, %arg22: index, %arg23: index):
        %73 = "affine.load"(%10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S18_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
        %74 = "affine.for"(%73) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg24: index, %arg25: f32):
          %75 = "affine.vector_load"(%8, %arg22, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %76 = "llvm.bitcast"(%75) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %77 = "affine.vector_load"(%9, %arg24, %arg21) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %78 = "llvm.bitcast"(%77) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %79 = "llvm.fmul"(%76, %78) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %80 = "llvm.fadd"(%arg25, %79) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%80) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "affine.store"(%74, %10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S27_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S28_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"} : () -> ()
      %64 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %65 = "arith.muli"(%64, %arg17) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %66 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %67 = "arith.addi"(%65, %66) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %68 = "arith.index_cast"(%5) : (index) -> i64
      %69 = "arith.cmpi"(%68, %67) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%69) ({
        %70 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
        ^bb0(%arg18: index, %arg19: index, %arg20: index):
          %71 = "affine.vector_load"(%2, %arg19, %arg18, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%71, %8, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %72 = "affine.vector_load"(%1, %arg19, %arg18, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%72, %9, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
        }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %58 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %59 = "affine.load"(%10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S30_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
      %60 = "llvm.bitcast"(%59) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%60, %3, %arg13, %arg14, %arg15, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S33_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
/scr/ivan/src/transformer-llvm-project/polly/lib/External/isl/isl_ctx.c:295: isl_ctx not freed as some objects still reference it
gpu-affine-opt: After opt:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %1 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %2 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %3 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %4 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %5 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %6 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %7 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
  %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
  %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S10_memref_alloca"} : () -> memref<16x16x1xf32, 16>
  %11 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %12 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %13 = "arith.index_cast"(%6) : (index) -> i64
  %14 = "arith.index_cast"(%11) : (i64) -> index
  %15 = "arith.index_cast"(%13) : (i64) -> index
  %16 = "arith.index_cast"(%12) : (i64) -> index
  %17 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %18 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %19 = "arith.index_cast"(%7) : (index) -> i64
  %20 = "arith.index_cast"(%17) : (i64) -> index
  %21 = "arith.index_cast"(%19) : (i64) -> index
  %22 = "arith.index_cast"(%18) : (i64) -> index
  "scf.parallel"(%14, %20, %15, %21, %16, %22) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %23 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg30: index, %arg31: index, %arg32: index):
      "affine.store"(%0, %10, %arg30, %arg31, %arg32) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S11_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    %24 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %25 = "arith.constant"() <{value = 21 : i64}> : () -> i64
    %26 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %27 = "arith.index_cast"(%5) : (index) -> i64
    %28 = "arith.subi"(%27, %26) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %29 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %30 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %31 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %32 = "arith.subi"(%28, %29) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %33 = "arith.addi"(%32, %30) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %34 = "arith.cmpi"(%28, %31) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %35 = "arith.select"(%34, %33, %28) : (i1, i64, i64) -> i64
    %36 = "arith.divsi"(%35, %29) : (i64, i64) -> i64
    %37 = "arith.minsi"(%36, %25) : (i64, i64) -> i64
    %38 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %39 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %40 = "arith.addi"(%37, %39) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%24, %40, %38) ({
    ^bb0(%arg26: i64):
      %81 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg27: index, %arg28: index, %arg29: index):
        %82 = "affine.vector_load"(%2, %arg28, %arg27, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%82, %8, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %83 = "affine.vector_load"(%1, %arg28, %arg27, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%83, %9, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %41 = "arith.constant"() <{value = 22 : i64}> : () -> i64
    %42 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %43 = "arith.index_cast"(%5) : (index) -> i64
    %44 = "arith.subi"(%43, %42) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %45 = "arith.constant"() <{value = 16 : i64}> : () -> i64
    %46 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %47 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    %48 = "arith.subi"(%44, %45) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %49 = "arith.addi"(%48, %46) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %50 = "arith.cmpi"(%44, %47) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %51 = "arith.select"(%50, %49, %44) : (i1, i64, i64) -> i64
    %52 = "arith.divsi"(%51, %45) : (i64, i64) -> i64
    %53 = "arith.constant"() <{value = 22 : i64}> : () -> i64
    %54 = "arith.addi"(%52, %53) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %55 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %56 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %57 = "arith.addi"(%54, %56) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%41, %57, %55) ({
    ^bb0(%arg17: i64):
      %61 = "arith.constant"() <{value = 0 : i64}> : () -> i64
      %62 = "arith.constant"() <{value = 22 : i64}> : () -> i64
      %63 = "arith.subi"(%arg17, %62) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg21: index, %arg22: index, %arg23: index):
        %73 = "affine.load"(%10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S18_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
        %74 = "affine.for"(%73) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg24: index, %arg25: f32):
          %75 = "affine.vector_load"(%8, %arg22, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %76 = "llvm.bitcast"(%75) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %77 = "affine.vector_load"(%9, %arg24, %arg21) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %78 = "llvm.bitcast"(%77) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %79 = "llvm.fmul"(%76, %78) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %80 = "llvm.fadd"(%arg25, %79) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%80) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "affine.store"(%74, %10, %arg21, %arg22, %arg23) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S27_affine_store"} : (f32, memref<16x16x1xf32, 16>, index, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S28_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"} : () -> ()
      %64 = "arith.constant"() <{value = 16 : i64}> : () -> i64
      %65 = "arith.muli"(%64, %arg17) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %66 = "arith.constant"() <{value = 1 : i64}> : () -> i64
      %67 = "arith.addi"(%65, %66) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %68 = "arith.index_cast"(%5) : (index) -> i64
      %69 = "arith.cmpi"(%68, %67) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%69) ({
        %70 = "arith.constant"() <{value = 0 : i64}> : () -> i64
        "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
        ^bb0(%arg18: index, %arg19: index, %arg20: index):
          %71 = "affine.vector_load"(%2, %arg19, %arg18, %arg13, %arg12, %5) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%71, %8, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %72 = "affine.vector_load"(%1, %arg19, %arg18, %arg12, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%72, %9, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
        }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %58 = "arith.constant"() <{value = 0 : i64}> : () -> i64
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %59 = "affine.load"(%10, %arg14, %arg15, %arg16) <{map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>}> {polymer.stmt.name = "S30_affine_load"} : (memref<16x16x1xf32, 16>, index, index, index) -> f32
      %60 = "llvm.bitcast"(%59) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%60, %3, %arg13, %arg14, %arg15, %arg13, %4) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S33_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
gpu-affine-opt: After rar:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 1 : index}> : () -> index
  %1 = "arith.constant"() <{value = 0 : index}> : () -> index
  %2 = "arith.constant"() <{value = 22 : i64}> : () -> i64
  %3 = "arith.constant"() <{value = 16 : i64}> : () -> i64
  %4 = "arith.constant"() <{value = 21 : i64}> : () -> i64
  %5 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %6 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %7 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %8 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %9 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %10 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %11 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %12 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %13 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %14 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %15 = "arith.index_cast"(%13) : (index) -> i64
  %16 = "arith.index_cast"(%15) : (i64) -> index
  %17 = "arith.index_cast"(%14) : (index) -> i64
  %18 = "arith.index_cast"(%17) : (i64) -> index
  "scf.parallel"(%1, %1, %16, %18, %0, %0) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %19 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
    %20 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
    %21 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<f32>
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg30: index, %arg31: index, %arg32: index):
      "memref.store"(%7, %21) <{nontemporal = false}> : (f32, memref<f32>) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    %22 = "arith.index_cast"(%12) : (index) -> i64
    %23 = "arith.subi"(%22, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %24 = "arith.subi"(%23, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %25 = "arith.addi"(%24, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %26 = "arith.cmpi"(%23, %6) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %27 = "arith.select"(%26, %25, %23) : (i1, i64, i64) -> i64
    %28 = "arith.divsi"(%27, %3) : (i64, i64) -> i64
    %29 = "arith.minsi"(%28, %4) : (i64, i64) -> i64
    %30 = "arith.addi"(%29, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%6, %30, %5) ({
    ^bb0(%arg26: i64):
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg27: index, %arg28: index, %arg29: index):
        %56 = "affine.vector_load"(%9, %arg28, %arg27, %arg13, %arg12, %12) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%56, %19, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %57 = "affine.vector_load"(%8, %arg28, %arg27, %arg12, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%57, %20, %arg28, %arg27) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    %31 = "arith.index_cast"(%12) : (index) -> i64
    %32 = "arith.subi"(%31, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %33 = "arith.subi"(%32, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %34 = "arith.addi"(%33, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %35 = "arith.cmpi"(%32, %6) <{predicate = 2 : i64}> : (i64, i64) -> i1
    %36 = "arith.select"(%35, %34, %32) : (i1, i64, i64) -> i64
    %37 = "arith.divsi"(%36, %3) : (i64, i64) -> i64
    %38 = "arith.addi"(%37, %2) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %39 = "arith.addi"(%38, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    "scf.for"(%2, %39, %5) ({
    ^bb0(%arg17: i64):
      "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
      ^bb0(%arg21: index, %arg22: index, %arg23: index):
        %48 = "memref.load"(%21) <{nontemporal = false}> : (memref<f32>) -> f32
        %49 = "affine.for"(%48) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg24: index, %arg25: f32):
          %50 = "affine.vector_load"(%19, %arg22, %arg24) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %51 = "llvm.bitcast"(%50) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %52 = "affine.vector_load"(%20, %arg24, %arg21) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %53 = "llvm.bitcast"(%52) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %54 = "llvm.fmul"(%51, %53) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %55 = "llvm.fadd"(%arg25, %54) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%55) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "memref.store"(%49, %21) <{nontemporal = false}> : (f32, memref<f32>) -> ()
        "affine.yield"() {polymer.stmt.name = "S28_affine_yield"} : () -> ()
      }) {gpu.par.block, polymer.stmt.name = "RS2_affine_parallel"} : () -> ()
      %42 = "arith.muli"(%arg17, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %43 = "arith.addi"(%42, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %44 = "arith.index_cast"(%12) : (index) -> i64
      %45 = "arith.cmpi"(%44, %43) <{predicate = 5 : i64}> : (i64, i64) -> i1
      "scf.if"(%45) ({
        "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
        ^bb0(%arg18: index, %arg19: index, %arg20: index):
          %46 = "affine.vector_load"(%9, %arg19, %arg18, %arg13, %arg12, %12) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%46, %19, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %47 = "affine.vector_load"(%8, %arg19, %arg18, %arg12, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%47, %20, %arg19, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "affine.yield"() {polymer.stmt.name = "S17_affine_yield"} : () -> ()
        }) {gpu.par.block, polymer.stmt.async.copy, polymer.stmt.name = "RS1_affine_parallel"} : () -> ()
        "scf.yield"() : () -> ()
      }, {
      }) : (i1) -> ()
      "scf.yield"() : () -> ()
    }) : (i64, i64, i64) -> ()
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      %40 = "memref.load"(%21) <{nontemporal = false}> : (memref<f32>) -> f32
      %41 = "llvm.bitcast"(%40) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%41, %10, %arg13, %arg14, %arg15, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S33_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS3_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
gpu-affine-opt: After gpuify:
"llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{}, {}, {}, {}, {}, {}, {}, {llvm.nocapture, llvm.noundef, llvm.writeonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.nocapture, llvm.noundef, llvm.readonly}, {llvm.noundef}, {llvm.noundef}], comdat = @__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii, function_type = !llvm.func<void (i64, i64, i64, i64, i64, i64, i32, ptr, ptr, ptr, i32, i32)>, linkage = #llvm.linkage<private>, sym_name = "__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764", sym_visibility = "private", unnamed_addr = 1 : i64, visibility_ = 0 : i64}> ({
^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: !llvm.ptr, %arg10: i32, %arg11: i32):
  %0 = "arith.constant"() <{value = 1 : index}> : () -> index
  %1 = "arith.constant"() <{value = 0 : index}> : () -> index
  %2 = "arith.constant"() <{value = 22 : i64}> : () -> i64
  %3 = "arith.constant"() <{value = 16 : i64}> : () -> i64
  %4 = "arith.constant"() <{value = 21 : i64}> : () -> i64
  %5 = "arith.constant"() <{value = 1 : i64}> : () -> i64
  %6 = "arith.constant"() <{value = 0 : i64}> : () -> i64
  %7 = "llvm.mlir.constant"() <{value = 0.000000e+00 : f32}> {polymer.stmt.name = "S0_llvm_mlir_constant"} : () -> f32
  %8 = "memref.ataddr"(%arg9) {polymer.stmt.name = "S1_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %9 = "memref.ataddr"(%arg8) {polymer.stmt.name = "S2_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %10 = "memref.ataddr"(%arg7) {polymer.stmt.name = "S3_memref_ataddr"} : (!llvm.ptr) -> memref<?xi8>
  %11 = "arith.index_cast"(%arg11) {polymer.stmt.name = "S4_arith_index_cast"} : (i32) -> index
  %12 = "arith.index_cast"(%arg10) {polymer.stmt.name = "S5_arith_index_cast"} : (i32) -> index
  %13 = "arith.index_cast"(%arg1) {polymer.stmt.name = "S6_arith_index_cast"} : (i64) -> index
  %14 = "arith.index_cast"(%arg0) {polymer.stmt.name = "S7_arith_index_cast"} : (i64) -> index
  %15 = "arith.index_cast"(%13) : (index) -> i64
  %16 = "arith.index_cast"(%15) : (i64) -> index
  %17 = "arith.index_cast"(%14) : (index) -> i64
  %18 = "arith.index_cast"(%17) : (i64) -> index
  "scf.parallel"(%1, %1, %16, %18, %0, %0) <{operandSegmentSizes = array<i32: 2, 2, 2, 0>}> ({
  ^bb0(%arg12: index, %arg13: index):
    %19 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S8_memref_alloca"} : () -> memref<1024xi8, 3>
    %20 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> {polymer.stmt.name = "S9_memref_alloca"} : () -> memref<1024xi8, 3>
    %21 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<f32>
    "affine.parallel"() <{lowerBoundsGroups = dense<1> : tensor<3xi32>, lowerBoundsMap = affine_map<() -> (0, 0, 0)>, reductions = [], steps = [1, 1, 1], upperBoundsGroups = dense<1> : tensor<3xi32>, upperBoundsMap = affine_map<() -> (16, 16, 1)>}> ({
    ^bb0(%arg14: index, %arg15: index, %arg16: index):
      "memref.store"(%7, %21) <{nontemporal = false}> : (f32, memref<f32>) -> ()
      "nvvm.barrier0"() : () -> ()
      %22 = "arith.index_cast"(%12) : (index) -> i64
      %23 = "arith.subi"(%22, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %24 = "arith.subi"(%23, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %25 = "arith.addi"(%24, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %26 = "arith.cmpi"(%23, %6) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %27 = "arith.select"(%26, %25, %23) : (i1, i64, i64) -> i64
      %28 = "arith.divsi"(%27, %3) : (i64, i64) -> i64
      %29 = "arith.minsi"(%28, %4) : (i64, i64) -> i64
      %30 = "arith.addi"(%29, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "scf.for"(%6, %30, %5) ({
      ^bb0(%arg20: i64):
        %65 = "affine.vector_load"(%9, %arg15, %arg14, %arg13, %arg12, %12) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%65, %19, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        %66 = "affine.vector_load"(%8, %arg15, %arg14, %arg12, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
        "affine.vector_store"(%66, %20, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (i64, i64, i64) -> ()
      "nvvm.barrier0"() : () -> ()
      %31 = "arith.index_cast"(%12) : (index) -> i64
      %32 = "arith.subi"(%31, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %33 = "arith.subi"(%32, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %34 = "arith.addi"(%33, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %35 = "arith.cmpi"(%32, %6) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %36 = "arith.select"(%35, %34, %32) : (i1, i64, i64) -> i64
      %37 = "arith.divsi"(%36, %3) : (i64, i64) -> i64
      %38 = "arith.addi"(%37, %2) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %39 = "arith.addi"(%38, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      "scf.for"(%2, %39, %5) ({
      ^bb0(%arg17: i64):
        %51 = "memref.load"(%21) <{nontemporal = false}> : (memref<f32>) -> f32
        %52 = "affine.for"(%51) <{lowerBoundMap = affine_map<() -> (0)>, operandSegmentSizes = array<i32: 0, 0, 1>, step = 1 : index, upperBoundMap = affine_map<() -> (16)>}> ({
        ^bb0(%arg18: index, %arg19: f32):
          %59 = "affine.vector_load"(%19, %arg15, %arg18) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S20_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %60 = "llvm.bitcast"(%59) {polymer.stmt.name = "S21_llvm_bitcast"} : (vector<4xi8>) -> f32
          %61 = "affine.vector_load"(%20, %arg18, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S22_affine_vector_load"} : (memref<1024xi8, 3>, index, index) -> vector<4xi8>
          %62 = "llvm.bitcast"(%61) {polymer.stmt.name = "S23_llvm_bitcast"} : (vector<4xi8>) -> f32
          %63 = "llvm.fmul"(%60, %62) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S24_llvm_fmul"} : (f32, f32) -> f32
          %64 = "llvm.fadd"(%arg19, %63) <{fastmathFlags = #llvm.fastmath<contract>}> {polymer.stmt.name = "S25_llvm_fadd"} : (f32, f32) -> f32
          "affine.yield"(%64) {polymer.stmt.name = "S26_affine_yield"} : (f32) -> ()
        }) : (f32) -> f32
        "memref.store"(%52, %21) <{nontemporal = false}> : (f32, memref<f32>) -> ()
        "nvvm.barrier0"() : () -> ()
        %53 = "arith.muli"(%arg17, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
        %54 = "arith.addi"(%53, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
        %55 = "arith.index_cast"(%12) : (index) -> i64
        %56 = "arith.cmpi"(%55, %54) <{predicate = 5 : i64}> : (i64, i64) -> i1
        "scf.if"(%56) ({
          %57 = "affine.vector_load"(%9, %arg15, %arg14, %arg13, %arg12, %12) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S13_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%57, %19, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S14_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          %58 = "affine.vector_load"(%8, %arg15, %arg14, %arg12, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> ((d0 * s0) * 4 + d1 * 4 + d3 * 64 + (d2 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S15_affine_vector_load"} : (memref<?xi8>, index, index, index, index, index) -> vector<4xi8>
          "affine.vector_store"(%58, %20, %arg15, %arg14) <{map = affine_map<(d0, d1) -> (d0 * 64 + d1 * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S16_affine_vector_store"} : (vector<4xi8>, memref<1024xi8, 3>, index, index) -> ()
          "scf.yield"() : () -> ()
        }, {
        }) : (i1) -> ()
        "scf.yield"() : () -> ()
      }) : (i64, i64, i64) -> ()
      "nvvm.barrier0"() : () -> ()
      %40 = "arith.index_cast"(%12) : (index) -> i64
      %41 = "arith.subi"(%40, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %42 = "arith.subi"(%41, %3) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %43 = "arith.addi"(%42, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %44 = "arith.cmpi"(%41, %6) <{predicate = 2 : i64}> : (i64, i64) -> i1
      %45 = "arith.select"(%44, %43, %41) : (i1, i64, i64) -> i64
      %46 = "arith.divsi"(%45, %3) : (i64, i64) -> i64
      %47 = "arith.addi"(%46, %2) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %48 = "arith.addi"(%47, %5) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
      %49 = "memref.load"(%21) <{nontemporal = false}> : (memref<f32>) -> f32
      %50 = "llvm.bitcast"(%49) {polymer.stmt.name = "S31_llvm_bitcast"} : (f32) -> vector<4xi8>
      "affine.vector_store"(%50, %10, %arg13, %arg14, %arg15, %arg13, %11) <{map = affine_map<(d0, d1, d2, d3)[s0] -> (d0 * 64 + d1 * 4 + (d2 * s0) * 4 + (d3 * (s0 * 16)) * 4)>}> {polymer.access.type = f32, polymer.stmt.name = "S32_affine_vector_store"} : (vector<4xi8>, memref<?xi8>, index, index, index, index, index) -> ()
      "affine.yield"() {polymer.stmt.name = "S12_affine_yield"} : () -> ()
    }) {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"} : () -> ()
    "scf.reduce"() : () -> ()
  }) {gpu.par.grid} : (index, index, index, index, index, index) -> ()
  "llvm.return"() {polymer.stmt.name = "S35_llvm_return"} : () -> ()
}) {gpu.par.kernel} : () -> ()
gpu-affine-opt: After lower affine:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c22_i64 = arith.constant 22 : i64
  %c16_i64 = arith.constant 16 : i64
  %c21_i64 = arith.constant 21 : i64
  %c1_i64 = arith.constant 1 : i64
  %c0_i64 = arith.constant 0 : i64
  %0 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
  %1 = arith.index_cast %arg11 {polymer.stmt.name = "S4_arith_index_cast"} : i32 to index
  %2 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
  %3 = arith.index_cast %arg1 {polymer.stmt.name = "S6_arith_index_cast"} : i64 to index
  %4 = arith.index_cast %arg0 {polymer.stmt.name = "S7_arith_index_cast"} : i64 to index
  %5 = arith.index_cast %3 : index to i64
  %6 = arith.index_cast %5 : i64 to index
  %7 = arith.index_cast %4 : index to i64
  %8 = arith.index_cast %7 : i64 to index
  scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%6, %8) step (%c1, %c1) {
    %9 = llvm.mlir.constant(1024 : index) : i64
    %10 = llvm.alloca %9 x i8 : (i64) -> !llvm.ptr<3>
    %11 = llvm.mlir.constant(1024 : index) : i64
    %12 = llvm.alloca %11 x i8 : (i64) -> !llvm.ptr<3>
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.alloca %13 x f32 : (i64) -> !llvm.ptr
    %c0_0 = arith.constant 0 : index
    %c16 = arith.constant 16 : index
    %c0_1 = arith.constant 0 : index
    %c16_2 = arith.constant 16 : index
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %c1_5 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    scf.parallel (%arg14, %arg15, %arg16) = (%c0_0, %c0_1, %c0_3) to (%c16, %c16_2, %c1_4) step (%c1_5, %c1_6, %c1_7) {
      %15 = llvm.getelementptr %14[] : (!llvm.ptr) -> !llvm.ptr, f32
      llvm.store %0, %15 : f32, !llvm.ptr
      nvvm.barrier0
      %16 = arith.index_cast %2 : index to i64
      %17 = arith.subi %16, %c1_i64 : i64
      %18 = arith.subi %17, %c16_i64 : i64
      %19 = arith.addi %18, %c1_i64 : i64
      %20 = arith.cmpi slt, %17, %c0_i64 : i64
      %21 = arith.select %20, %19, %17 : i64
      %22 = arith.divsi %21, %c16_i64 : i64
      %23 = arith.minsi %22, %c21_i64 : i64
      %24 = arith.addi %23, %c1_i64 : i64
      scf.for %arg17 = %c0_i64 to %24 step %c1_i64  : i64 {
        %57 = arith.muli %arg15, %2 : index
        %c4_11 = arith.constant 4 : index
        %58 = arith.muli %57, %c4_11 : index
        %c4_12 = arith.constant 4 : index
        %59 = arith.muli %arg14, %c4_12 : index
        %60 = arith.addi %58, %59 : index
        %c64_13 = arith.constant 64 : index
        %61 = arith.muli %arg12, %c64_13 : index
        %62 = arith.addi %60, %61 : index
        %c16_14 = arith.constant 16 : index
        %63 = arith.muli %2, %c16_14 : index
        %64 = arith.muli %arg13, %63 : index
        %c4_15 = arith.constant 4 : index
        %65 = arith.muli %64, %c4_15 : index
        %66 = arith.addi %62, %65 : index
        %67 = llvm.load %arg8 : !llvm.ptr -> f32
        %68 = llvm.bitcast %67 : f32 to vector<4xi8>
        %c64_16 = arith.constant 64 : index
        %69 = arith.muli %arg15, %c64_16 : index
        %c4_17 = arith.constant 4 : index
        %70 = arith.muli %arg14, %c4_17 : index
        %71 = arith.addi %69, %70 : index
        %72 = llvm.bitcast %68 : vector<4xi8> to f32
        llvm.store %72, %10 : f32, !llvm.ptr<3>
        %73 = arith.muli %arg15, %1 : index
        %c4_18 = arith.constant 4 : index
        %74 = arith.muli %73, %c4_18 : index
        %c4_19 = arith.constant 4 : index
        %75 = arith.muli %arg14, %c4_19 : index
        %76 = arith.addi %74, %75 : index
        %c64_20 = arith.constant 64 : index
        %77 = arith.muli %arg13, %c64_20 : index
        %78 = arith.addi %76, %77 : index
        %c16_21 = arith.constant 16 : index
        %79 = arith.muli %1, %c16_21 : index
        %80 = arith.muli %arg12, %79 : index
        %c4_22 = arith.constant 4 : index
        %81 = arith.muli %80, %c4_22 : index
        %82 = arith.addi %78, %81 : index
        %83 = llvm.load %arg9 : !llvm.ptr -> f32
        %84 = llvm.bitcast %83 : f32 to vector<4xi8>
        %c64_23 = arith.constant 64 : index
        %85 = arith.muli %arg15, %c64_23 : index
        %c4_24 = arith.constant 4 : index
        %86 = arith.muli %arg14, %c4_24 : index
        %87 = arith.addi %85, %86 : index
        %88 = llvm.bitcast %84 : vector<4xi8> to f32
        llvm.store %88, %12 : f32, !llvm.ptr<3>
      }
      nvvm.barrier0
      %25 = arith.index_cast %2 : index to i64
      %26 = arith.subi %25, %c1_i64 : i64
      %27 = arith.subi %26, %c16_i64 : i64
      %28 = arith.addi %27, %c1_i64 : i64
      %29 = arith.cmpi slt, %26, %c0_i64 : i64
      %30 = arith.select %29, %28, %26 : i64
      %31 = arith.divsi %30, %c16_i64 : i64
      %32 = arith.addi %31, %c22_i64 : i64
      %33 = arith.addi %32, %c1_i64 : i64
      scf.for %arg17 = %c22_i64 to %33 step %c1_i64  : i64 {
        %57 = llvm.getelementptr %14[] : (!llvm.ptr) -> !llvm.ptr, f32
        %58 = llvm.load %57 : !llvm.ptr -> f32
        %c0_11 = arith.constant 0 : index
        %c16_12 = arith.constant 16 : index
        %c1_13 = arith.constant 1 : index
        %59 = scf.for %arg18 = %c0_11 to %c16_12 step %c1_13 iter_args(%arg19 = %58) -> (f32) {
          %c64_14 = arith.constant 64 : index
          %65 = arith.muli %arg15, %c64_14 : index
          %c4_15 = arith.constant 4 : index
          %66 = arith.muli %arg18, %c4_15 : index
          %67 = arith.addi %65, %66 : index
          %68 = llvm.load %10 : !llvm.ptr<3> -> f32
          %69 = llvm.bitcast %68 : f32 to vector<4xi8>
          %70 = llvm.bitcast %69 {polymer.stmt.name = "S21_llvm_bitcast"} : vector<4xi8> to f32
          %c64_16 = arith.constant 64 : index
          %71 = arith.muli %arg18, %c64_16 : index
          %c4_17 = arith.constant 4 : index
          %72 = arith.muli %arg14, %c4_17 : index
          %73 = arith.addi %71, %72 : index
          %74 = llvm.load %12 : !llvm.ptr<3> -> f32
          %75 = llvm.bitcast %74 : f32 to vector<4xi8>
          %76 = llvm.bitcast %75 {polymer.stmt.name = "S23_llvm_bitcast"} : vector<4xi8> to f32
          %77 = llvm.fmul %70, %76  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
          %78 = llvm.fadd %arg19, %77  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
          scf.yield %78 : f32
        }
        %60 = llvm.getelementptr %14[] : (!llvm.ptr) -> !llvm.ptr, f32
        llvm.store %59, %60 : f32, !llvm.ptr
        nvvm.barrier0
        %61 = arith.muli %arg17, %c16_i64 : i64
        %62 = arith.addi %61, %c1_i64 : i64
        %63 = arith.index_cast %2 : index to i64
        %64 = arith.cmpi sge, %63, %62 : i64
        scf.if %64 {
          %65 = arith.muli %arg15, %2 : index
          %c4_14 = arith.constant 4 : index
          %66 = arith.muli %65, %c4_14 : index
          %c4_15 = arith.constant 4 : index
          %67 = arith.muli %arg14, %c4_15 : index
          %68 = arith.addi %66, %67 : index
          %c64_16 = arith.constant 64 : index
          %69 = arith.muli %arg12, %c64_16 : index
          %70 = arith.addi %68, %69 : index
          %c16_17 = arith.constant 16 : index
          %71 = arith.muli %2, %c16_17 : index
          %72 = arith.muli %arg13, %71 : index
          %c4_18 = arith.constant 4 : index
          %73 = arith.muli %72, %c4_18 : index
          %74 = arith.addi %70, %73 : index
          %75 = llvm.load %arg8 : !llvm.ptr -> f32
          %76 = llvm.bitcast %75 : f32 to vector<4xi8>
          %c64_19 = arith.constant 64 : index
          %77 = arith.muli %arg15, %c64_19 : index
          %c4_20 = arith.constant 4 : index
          %78 = arith.muli %arg14, %c4_20 : index
          %79 = arith.addi %77, %78 : index
          %80 = llvm.bitcast %76 : vector<4xi8> to f32
          llvm.store %80, %10 : f32, !llvm.ptr<3>
          %81 = arith.muli %arg15, %1 : index
          %c4_21 = arith.constant 4 : index
          %82 = arith.muli %81, %c4_21 : index
          %c4_22 = arith.constant 4 : index
          %83 = arith.muli %arg14, %c4_22 : index
          %84 = arith.addi %82, %83 : index
          %c64_23 = arith.constant 64 : index
          %85 = arith.muli %arg13, %c64_23 : index
          %86 = arith.addi %84, %85 : index
          %c16_24 = arith.constant 16 : index
          %87 = arith.muli %1, %c16_24 : index
          %88 = arith.muli %arg12, %87 : index
          %c4_25 = arith.constant 4 : index
          %89 = arith.muli %88, %c4_25 : index
          %90 = arith.addi %86, %89 : index
          %91 = llvm.load %arg9 : !llvm.ptr -> f32
          %92 = llvm.bitcast %91 : f32 to vector<4xi8>
          %c64_26 = arith.constant 64 : index
          %93 = arith.muli %arg15, %c64_26 : index
          %c4_27 = arith.constant 4 : index
          %94 = arith.muli %arg14, %c4_27 : index
          %95 = arith.addi %93, %94 : index
          %96 = llvm.bitcast %92 : vector<4xi8> to f32
          llvm.store %96, %12 : f32, !llvm.ptr<3>
        }
      }
      nvvm.barrier0
      %34 = arith.index_cast %2 : index to i64
      %35 = arith.subi %34, %c1_i64 : i64
      %36 = arith.subi %35, %c16_i64 : i64
      %37 = arith.addi %36, %c1_i64 : i64
      %38 = arith.cmpi slt, %35, %c0_i64 : i64
      %39 = arith.select %38, %37, %35 : i64
      %40 = arith.divsi %39, %c16_i64 : i64
      %41 = arith.addi %40, %c22_i64 : i64
      %42 = arith.addi %41, %c1_i64 : i64
      %43 = llvm.getelementptr %14[] : (!llvm.ptr) -> !llvm.ptr, f32
      %44 = llvm.load %43 : !llvm.ptr -> f32
      %45 = llvm.bitcast %44 {polymer.stmt.name = "S31_llvm_bitcast"} : f32 to vector<4xi8>
      %c64 = arith.constant 64 : index
      %46 = arith.muli %arg13, %c64 : index
      %c4 = arith.constant 4 : index
      %47 = arith.muli %arg14, %c4 : index
      %48 = arith.addi %46, %47 : index
      %49 = arith.muli %arg15, %1 : index
      %c4_8 = arith.constant 4 : index
      %50 = arith.muli %49, %c4_8 : index
      %51 = arith.addi %48, %50 : index
      %c16_9 = arith.constant 16 : index
      %52 = arith.muli %1, %c16_9 : index
      %53 = arith.muli %arg13, %52 : index
      %c4_10 = arith.constant 4 : index
      %54 = arith.muli %53, %c4_10 : index
      %55 = arith.addi %51, %54 : index
      %56 = llvm.bitcast %45 : vector<4xi8> to f32
      llvm.store %56, %arg7 : f32, !llvm.ptr
      scf.reduce 
    } {gpu.par.block, polymer.stmt.name = "RS0_affine_parallel"}
    scf.reduce 
  } {gpu.par.grid}
  llvm.return {polymer.stmt.name = "S35_llvm_return"}
}
gpu-affine-opt: Canonicalized:
llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
  %c23_i64 = arith.constant 23 : i64
  %c-16_i64 = arith.constant -16 : i64
  %c16 = arith.constant 16 : index
  %0 = llvm.mlir.constant(1 : index) : i64
  %1 = llvm.mlir.constant(1024 : index) : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c22_i64 = arith.constant 22 : i64
  %c16_i64 = arith.constant 16 : i64
  %c21_i64 = arith.constant 21 : i64
  %c1_i64 = arith.constant 1 : i64
  %c0_i64 = arith.constant 0 : i64
  %2 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
  %3 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
  %4 = arith.index_cast %arg1 : i64 to index
  %5 = arith.index_cast %arg0 : i64 to index
  scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%4, %5) step (%c1, %c1) {
    %6 = llvm.alloca %1 x i8 : (i64) -> !llvm.ptr<3>
    %7 = llvm.alloca %1 x i8 : (i64) -> !llvm.ptr<3>
    %8 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
    scf.parallel (%arg14, %arg15) = (%c0, %c0) to (%c16, %c16) step (%c1, %c1) {
      %9 = llvm.getelementptr %8[] : (!llvm.ptr) -> !llvm.ptr, f32
      llvm.store %2, %9 : f32, !llvm.ptr
      nvvm.barrier0
      %10 = arith.index_cast %3 : index to i64
      %11 = arith.subi %10, %c1_i64 : i64
      %12 = arith.addi %10, %c-16_i64 : i64
      %13 = arith.cmpi slt, %11, %c0_i64 : i64
      %14 = arith.select %13, %12, %11 : i64
      %15 = arith.divsi %14, %c16_i64 : i64
      %16 = arith.minsi %15, %c21_i64 : i64
      %17 = arith.addi %16, %c1_i64 : i64
      scf.for %arg16 = %c0_i64 to %17 step %c1_i64  : i64 {
        %20 = llvm.load %arg8 : !llvm.ptr -> f32
        llvm.store %20, %6 : f32, !llvm.ptr<3>
        %21 = llvm.load %arg9 : !llvm.ptr -> f32
        llvm.store %21, %7 : f32, !llvm.ptr<3>
      }
      nvvm.barrier0
      %18 = arith.addi %15, %c23_i64 : i64
      scf.for %arg16 = %c22_i64 to %18 step %c1_i64  : i64 {
        %20 = llvm.load %9 : !llvm.ptr -> f32
        %21 = scf.for %arg17 = %c0 to %c16 step %c1 iter_args(%arg18 = %20) -> (f32) {
          %25 = llvm.load %6 : !llvm.ptr<3> -> f32
          %26 = llvm.load %7 : !llvm.ptr<3> -> f32
          %27 = llvm.fmul %25, %26  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
          %28 = llvm.fadd %arg18, %27  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
          scf.yield %28 : f32
        }
        llvm.store %21, %9 : f32, !llvm.ptr
        nvvm.barrier0
        %22 = arith.muli %arg16, %c16_i64 : i64
        %23 = arith.addi %22, %c1_i64 : i64
        %24 = arith.cmpi sge, %10, %23 : i64
        scf.if %24 {
          %25 = llvm.load %arg8 : !llvm.ptr -> f32
          llvm.store %25, %6 : f32, !llvm.ptr<3>
          %26 = llvm.load %arg9 : !llvm.ptr -> f32
          llvm.store %26, %7 : f32, !llvm.ptr<3>
        }
      }
      nvvm.barrier0
      %19 = llvm.load %9 : !llvm.ptr -> f32
      llvm.store %19, %arg7 : f32, !llvm.ptr
      scf.reduce 
    }
    scf.reduce 
  } {gpu.par.grid}
  llvm.return {polymer.stmt.name = "S35_llvm_return"}
}
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi64>>, #dlti.dl_entry<i128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi64>>, #dlti.dl_entry<i64, dense<64> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f128, dense<128> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi64>>, #dlti.dl_entry<f16, dense<16> : vector<2xi64>>, #dlti.dl_entry<f64, dense<64> : vector<2xi64>>, #dlti.dl_entry<i16, dense<16> : vector<2xi64>>, #dlti.dl_entry<i32, dense<32> : vector<2xi64>>, #dlti.dl_entry<i1, dense<8> : vector<2xi64>>, #dlti.dl_entry<i8, dense<8> : vector<2xi64>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi64>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i64>, #dlti.dl_entry<"dlti.endianness", "little">>, gpu.container_module} {
  gpu.module @__mlir_gpu_module [#nvvm.target<chip = "sm_80">]  {
    llvm.comdat @__llvm_global_comdat {
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As any
      llvm.comdat_selector @_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs any
      llvm.comdat_selector @_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii any
      llvm.comdat_selector @_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii any
    }
    llvm.func private local_unnamed_addr @__mlir.par.kernel._Z13MatrixMulCUDAILi16EEvPfS0_S0_ii_32764(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i32, %arg7: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.writeonly}, %arg8: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg9: !llvm.ptr {llvm.nocapture, llvm.noundef, llvm.readonly}, %arg10: i32 {llvm.noundef}, %arg11: i32 {llvm.noundef}) comdat(@__llvm_global_comdat::@_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii) attributes {gpu.par.kernel, sym_visibility = "private"} {
      %c23_i64 = arith.constant 23 : i64
      %c-16_i64 = arith.constant -16 : i64
      %c16 = arith.constant 16 : index
      %0 = llvm.mlir.constant(1 : index) : i64
      %1 = llvm.mlir.constant(1024 : index) : i64
      %c1 = arith.constant 1 : index
      %c0 = arith.constant 0 : index
      %c22_i64 = arith.constant 22 : i64
      %c16_i64 = arith.constant 16 : i64
      %c21_i64 = arith.constant 21 : i64
      %c1_i64 = arith.constant 1 : i64
      %c0_i64 = arith.constant 0 : i64
      %2 = llvm.mlir.constant(0.000000e+00 : f32) {polymer.stmt.name = "S0_llvm_mlir_constant"} : f32
      %3 = arith.index_cast %arg10 {polymer.stmt.name = "S5_arith_index_cast"} : i32 to index
      %4 = arith.index_cast %arg1 : i64 to index
      %5 = arith.index_cast %arg0 : i64 to index
      scf.parallel (%arg12, %arg13) = (%c0, %c0) to (%4, %5) step (%c1, %c1) {
        %6 = llvm.alloca %1 x i8 : (i64) -> !llvm.ptr<3>
        %7 = llvm.alloca %1 x i8 : (i64) -> !llvm.ptr<3>
        %8 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
        scf.parallel (%arg14, %arg15) = (%c0, %c0) to (%c16, %c16) step (%c1, %c1) {
          %9 = llvm.getelementptr %8[] : (!llvm.ptr) -> !llvm.ptr, f32
          llvm.store %2, %9 : f32, !llvm.ptr
          nvvm.barrier0
          %10 = arith.index_cast %3 : index to i64
          %11 = arith.subi %10, %c1_i64 : i64
          %12 = arith.addi %10, %c-16_i64 : i64
          %13 = arith.cmpi slt, %11, %c0_i64 : i64
          %14 = arith.select %13, %12, %11 : i64
          %15 = arith.divsi %14, %c16_i64 : i64
          %16 = arith.minsi %15, %c21_i64 : i64
          %17 = arith.addi %16, %c1_i64 : i64
          scf.for %arg16 = %c0_i64 to %17 step %c1_i64  : i64 {
            %20 = llvm.load %arg8 : !llvm.ptr -> f32
            llvm.store %20, %6 : f32, !llvm.ptr<3>
            %21 = llvm.load %arg9 : !llvm.ptr -> f32
            llvm.store %21, %7 : f32, !llvm.ptr<3>
          }
          nvvm.barrier0
          %18 = arith.addi %15, %c23_i64 : i64
          scf.for %arg16 = %c22_i64 to %18 step %c1_i64  : i64 {
            %20 = llvm.load %9 : !llvm.ptr -> f32
            %21 = scf.for %arg17 = %c0 to %c16 step %c1 iter_args(%arg18 = %20) -> (f32) {
              %25 = llvm.load %6 : !llvm.ptr<3> -> f32
              %26 = llvm.load %7 : !llvm.ptr<3> -> f32
              %27 = llvm.fmul %25, %26  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S24_llvm_fmul"} : f32
              %28 = llvm.fadd %arg18, %27  {fastmathFlags = #llvm.fastmath<contract>, polymer.stmt.name = "S25_llvm_fadd"} : f32
              scf.yield %28 : f32
            }
            llvm.store %21, %9 : f32, !llvm.ptr
            nvvm.barrier0
            %22 = arith.muli %arg16, %c16_i64 : i64
            %23 = arith.addi %22, %c1_i64 : i64
            %24 = arith.cmpi sge, %10, %23 : i64
            scf.if %24 {
              %25 = llvm.load %arg8 : !llvm.ptr -> f32
              llvm.store %25, %6 : f32, !llvm.ptr<3>
              %26 = llvm.load %arg9 : !llvm.ptr -> f32
              llvm.store %26, %7 : f32, !llvm.ptr<3>
            }
          }
          nvvm.barrier0
          %19 = llvm.load %9 : !llvm.ptr -> f32
          llvm.store %19, %arg7 : f32, !llvm.ptr
          scf.reduce 
        }
        scf.reduce 
      } {gpu.par.grid}
      llvm.return {polymer.stmt.name = "S35_llvm_return"}
    }
  }
}

Eliminated dead instances: [P0, P1, P2, P3] -> { S4_arith_index_cast[]; S1_memref_ataddr[]; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S0_llvm_mlir_constant[] }
Eliminated dead instances: [P0, P1, P2, P3] -> { S4_arith_index_cast[]; S1_memref_ataddr[]; S9_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S8_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S5_arith_index_cast[]; S3_memref_ataddr[]; S6_arith_index_cast[]; S2_memref_ataddr[]; S29_affine_yield[i0, i1, 0, i3] : 0 <= i0 < P2 and 0 <= i1 < P1 and i3 >= 0 and 16i3 < P3; S7_arith_index_cast[]; S34_affine_yield[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S10_memref_alloca[i0, i1, 0] : 0 <= i0 < P2 and 0 <= i1 < P1; S0_llvm_mlir_constant[] }
